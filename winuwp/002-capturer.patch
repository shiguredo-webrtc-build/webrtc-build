diff --git a/BUILD.gn b/BUILD.gn
index eb06453dea..0f453d27f5 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -260,6 +260,10 @@ config("common_config") {
     defines += [ "WEBRTC_INCLUDE_INTERNAL_AUDIO_DEVICE" ]
   }
 
+  if (rtc_win_video_capture_winrt) {
+    defines += [ "WEBRTC_VIDEO_CAPTURE_WINRT" ]
+  }
+
   if (rtc_libvpx_build_vp9) {
     defines += [ "RTC_ENABLE_VP9" ]
   }
diff --git a/common_video/libyuv/include/webrtc_libyuv.h b/common_video/libyuv/include/webrtc_libyuv.h
index 905219b6a6..b0b2262de3 100644
--- a/common_video/libyuv/include/webrtc_libyuv.h
+++ b/common_video/libyuv/include/webrtc_libyuv.h
@@ -32,15 +32,18 @@ enum class VideoType {
   kI420,
   kIYUV,
   kRGB24,
   kBGR24,
   kARGB,
   kABGR,
+  kARGB4444,
   kRGB565,
+  kARGB1555,
   kYUY2,
   kYV12,
   kUYVY,
   kMJPEG,
   kBGRA,
+  kNV21,
   kNV12,
 };
 
diff --git a/common_video/libyuv/webrtc_libyuv.cc b/common_video/libyuv/webrtc_libyuv.cc
index 2e10a60776..ffadee3472 100644
--- a/common_video/libyuv/webrtc_libyuv.cc
+++ b/common_video/libyuv/webrtc_libyuv.cc
@@ -25,6 +25,7 @@ size_t CalcBufferSize(VideoType type, int width, int height) {
   switch (type) {
     case VideoType::kI420:
     case VideoType::kIYUV:
     case VideoType::kYV12:
+    case VideoType::kNV21:
     case VideoType::kNV12: {
       int half_width = (width + 1) >> 1;
@@ -32,6 +33,8 @@ size_t CalcBufferSize(VideoType type, int width, int height) {
       return width * height + half_width * half_height * 2;
     }
+    case VideoType::kARGB4444:
     case VideoType::kRGB565:
+    case VideoType::kARGB1555:
     case VideoType::kYUY2:
     case VideoType::kUYVY:
       return width * height * 2;
@@ -105,11 +108,17 @@ int ConvertVideoType(VideoType video_type) {
     case VideoType::kMJPEG:
       return libyuv::FOURCC_MJPG;
     case VideoType::kARGB:
       return libyuv::FOURCC_ARGB;
     case VideoType::kBGRA:
       return libyuv::FOURCC_BGRA;
+    case VideoType::kARGB4444:
+      return libyuv::FOURCC_R444;
+    case VideoType::kARGB1555:
+      return libyuv::FOURCC_RGBO;
+    case VideoType::kNV21:
+      return libyuv::FOURCC_NV21;
     case VideoType::kNV12:
       return libyuv::FOURCC_NV12;
   }
   RTC_DCHECK_NOTREACHED() << "Unexpected pixel format " << video_type;
   return libyuv::FOURCC_ANY;
diff --git a/modules/video_capture/BUILD.gn b/modules/video_capture/BUILD.gn
index ad2d85e3fe..1cecd294d7 100644
--- a/modules/video_capture/BUILD.gn
+++ b/modules/video_capture/BUILD.gn
@@ -103,33 +103,51 @@ if (!build_with_chromium || is_linux || is_chromeos) {
       }
     }
     if (is_win) {
-      sources += [
-        "windows/device_info_ds.cc",
-        "windows/device_info_ds.h",
-        "windows/help_functions_ds.cc",
-        "windows/help_functions_ds.h",
-        "windows/sink_filter_ds.cc",
-        "windows/sink_filter_ds.h",
-        "windows/video_capture_ds.cc",
-        "windows/video_capture_ds.h",
-        "windows/video_capture_factory_windows.cc",
-      ]
-
-      libs = [
-        "ole32.lib",
-        "oleaut32.lib",
-        "strmiids.lib",
-        "user32.lib",
-      ]
+      if (rtc_win_video_capture_winrt) {
+        sources += [
+          "winuwp/device_info_winrt.cc",
+          "winuwp/device_info_winrt.h",
+          "winuwp/help_functions_winrt.cc",
+          "winuwp/help_functions_winrt.h",
+          "winuwp/mrc_video_effect_definition_impl.cc",
+          "winuwp/mrc_video_effect_definition_impl.h",
+          "winuwp/mrc_video_effect_definition.h",
+          "winuwp/video_capture_winrt.cc",
+          "winuwp/video_capture_winrt.h",
+        ]
+        libs = [ "windowsapp.lib" ] 
+      } else {
+        defines = [ "WEBRTC_VIDEO_CAPTURE_DSHOW" ]
+        sources += [
+          "windows/device_info_ds.cc",
+          "windows/device_info_ds.h",
+          "windows/help_functions_ds.cc",
+          "windows/help_functions_ds.h",
+          "windows/sink_filter_ds.cc",
+          "windows/sink_filter_ds.h",
+          "windows/video_capture_ds.cc",
+          "windows/video_capture_ds.h",
+        ]
 
-      if (build_with_mozilla) {
-        sources += [
-          "windows/BaseFilter.cpp",
-          "windows/BaseInputPin.cpp",
-          "windows/BasePin.cpp",
-          "windows/MediaType.cpp",
+        libs = [
+          "ole32.lib",
+          "oleaut32.lib",
+          "strmiids.lib",
+          "user32.lib",
         ]
+
+        if (build_with_mozilla) {
+          sources += [
+            "windows/BaseFilter.cpp",
+            "windows/BaseInputPin.cpp",
+            "windows/BasePin.cpp",
+            "windows/MediaType.cpp",
+          ]
+        }
       }
+      sources += [
+        "windows/video_capture_factory_windows.cc",
+      ] 
     }
     if (is_fuchsia) {
       sources += [ "video_capture_factory_null.cc" ]
diff --git a/modules/video_capture/video_capture_defines.h b/modules/video_capture/video_capture_defines.h
index 63534600a9..7d9a0a83aa 100644
--- a/modules/video_capture/video_capture_defines.h
+++ b/modules/video_capture/video_capture_defines.h
@@ -11,8 +11,13 @@
 #ifndef MODULES_VIDEO_CAPTURE_VIDEO_CAPTURE_DEFINES_H_
 #define MODULES_VIDEO_CAPTURE_VIDEO_CAPTURE_DEFINES_H_
 
+#if defined(WEBRTC_VIDEO_CAPTURE_WINRT)
+#include <wrl/client.h>
+#endif  // WEBRTC_VIDEO_CAPTURE_WINRT
+
 #include "api/video/video_frame.h"
 #include "common_video/libyuv/include/webrtc_libyuv.h"
+#include "modules/video_capture/winuwp/mrc_video_effect_definition.h"
 
 namespace webrtc {
 
@@ -28,14 +33,26 @@ struct VideoCaptureCapability {
   int32_t maxFPS;
   VideoType videoType;
   bool interlaced;
+#if defined(WEBRTC_VIDEO_CAPTURE_WINRT)
+  std::wstring profile_id;
+  ::Microsoft::WRL::ComPtr<::IUnknown> media_capture_video_profile;
+  ::Microsoft::WRL::ComPtr<::IUnknown> record_media_description;
+  std::shared_ptr<MrcVideoEffectDefinition> mrc_video_effect_definition;
+#endif  // WEBRTC_VIDEO_CAPTURE_WINRT
+
+  VideoCaptureCapability()
+      : width(0),
+        height(0),
+        maxFPS(0),
+        videoType(VideoType::kUnknown),
+        interlaced(false)
+#if defined(WEBRTC_VIDEO_CAPTURE_WINRT)
+        , profile_id(L"")
+        , media_capture_video_profile(nullptr)
+        , record_media_description(nullptr)
+#endif  // WEBRTC_VIDEO_CAPTURE_WINRT
+  {}
 
-  VideoCaptureCapability() {
-    width = 0;
-    height = 0;
-    maxFPS = 0;
-    videoType = VideoType::kUnknown;
-    interlaced = false;
-  }
   bool operator!=(const VideoCaptureCapability& other) const {
     if (width != other.width)
       return true;
@@ -47,6 +64,18 @@ struct VideoCaptureCapability {
       return true;
     if (interlaced != other.interlaced)
       return true;
+#if defined(WEBRTC_VIDEO_CAPTURE_WINRT)
+    if (profile_id != other.profile_id)
+      return true;
+    if (media_capture_video_profile.Get() !=
+        other.media_capture_video_profile.Get())
+      return true;
+    if (record_media_description.Get() != other.record_media_description.Get())
+      return true;
+    if (mrc_video_effect_definition != other.mrc_video_effect_definition)
+      return true;
+#endif  // WEBRTC_VIDEO_CAPTURE_WINRT
+
     return false;
   }
   bool operator==(const VideoCaptureCapability& other) const {
diff --git a/modules/video_capture/video_capture_impl.cc b/modules/video_capture/video_capture_impl.cc
index 428253bf23..eea8ebd2a9 100644
--- a/modules/video_capture/video_capture_impl.cc
+++ b/modules/video_capture/video_capture_impl.cc
@@ -14,6 +14,7 @@
 #include <string.h>
 
 #include "api/video/i420_buffer.h"
+#include "api/video/nv12_buffer.h"
 #include "api/video/video_frame_buffer.h"
 #include "common_video/libyuv/include/webrtc_libyuv.h"
 #include "modules/video_capture/video_capture_config.h"
@@ -139,9 +139,17 @@ void VideoCaptureImpl::DeliverRawFrame(uint8_t* videoFrame,
 }
 
 int32_t VideoCaptureImpl::IncomingFrame(uint8_t* videoFrame,
+                                        int32_t stride_y,
+                                        uint8_t* plane_uv,
+                                        int32_t stride_uv,
                                         size_t videoFrameLength,
                                         const VideoCaptureCapability& frameInfo,
                                         int64_t captureTime /*=0*/) {
+  RTC_LOG(LS_INFO) << "[hololens2-debug] webrtc::VideoType=" << (int)frameInfo.videoType;
+  if (frameInfo.videoType == VideoType::kNV12) {
+    return IncomingFrameNV12(videoFrame, stride_y, plane_uv, stride_uv, videoFrameLength, frameInfo, captureTime);
+  }
+
   RTC_CHECK_RUNS_SERIALIZED(&capture_checker_);
   MutexLock lock(&api_lock_);
 
@@ -155,22 +163,8 @@ int32_t VideoCaptureImpl::IncomingFrame(uint8_t* videoFrame,
     return 0;
   }
 
-  // Not encoded, convert to I420.
-  if (frameInfo.videoType != VideoType::kMJPEG) {
-    // Allow buffers larger than expected. On linux gstreamer allocates buffers
-    // page-aligned and v4l2loopback passes us the buffer size verbatim which
-    // for most cases is larger than expected.
-    // See https://github.com/umlaeute/v4l2loopback/issues/190.
-    if (auto size = CalcBufferSize(frameInfo.videoType, width, abs(height));
-        videoFrameLength < size) {
-      RTC_LOG(LS_ERROR) << "Wrong incoming frame length. Expected " << size
-                        << ", Got " << videoFrameLength << ".";
-      return -1;
-    }
-  }
-
-  int stride_y = width;
-  int stride_uv = (width + 1) / 2;
+  int dst_stride_y = width;
+  int dst_stride_uv = (width + 1) / 2;
   int target_width = width;
   int target_height = abs(height);
 
@@ -187,7 +181,7 @@ int32_t VideoCaptureImpl::IncomingFrame(uint8_t* videoFrame,
   // In Windows, the image starts bottom left, instead of top left.
   // Setting a negative source height, inverts the image (within LibYuv).
   rtc::scoped_refptr<I420Buffer> buffer = I420Buffer::Create(
-      target_width, target_height, stride_y, stride_uv, stride_uv);
+      target_width, target_height, dst_stride_y, dst_stride_uv, dst_stride_uv);
 
   libyuv::RotationMode rotation_mode = libyuv::kRotate0;
   if (apply_rotation_) {
@@ -208,10 +202,11 @@ int32_t VideoCaptureImpl::IncomingFrame(uint8_t* videoFrame,
   }
 
   const int conversionResult = libyuv::ConvertToI420(
-      videoFrame, videoFrameLength, buffer.get()->MutableDataY(),
-      buffer.get()->StrideY(), buffer.get()->MutableDataU(),
-      buffer.get()->StrideU(), buffer.get()->MutableDataV(),
-      buffer.get()->StrideV(), 0, 0,  // No Cropping
+      videoFrame, videoFrameLength, stride_y, plane_uv, stride_uv,
+      buffer.get()->MutableDataY(), buffer.get()->StrideY(),
+      buffer.get()->MutableDataU(), buffer.get()->StrideU(),
+      buffer.get()->MutableDataV(), buffer.get()->StrideV(), 0,
+      0,  // No Cropping
       width, height, target_width, target_height, rotation_mode,
       ConvertVideoType(frameInfo.videoType));
   if (conversionResult != 0) {
@@ -234,6 +229,40 @@ int32_t VideoCaptureImpl::IncomingFrame(uint8_t* videoFrame,
   return 0;
 }
 
+int32_t VideoCaptureImpl::IncomingFrameNV12(uint8_t* plane_y,
+                                        int32_t stride_y,
+                                        uint8_t* plane_uv,
+                                        int32_t stride_uv,
+                                        size_t videoFrameLength,
+                                        const VideoCaptureCapability& frameInfo,
+                                        int64_t captureTime /*=0*/) {
+  MutexLock lock(&api_lock_);
+
+  const int32_t width = frameInfo.width;
+  const int32_t height = frameInfo.height;
+
+  TRACE_EVENT1("webrtc", "VC::IncomingFrameNV12", "capture_time", captureTime);
+
+  rtc::scoped_refptr<NV12Buffer> buffer = NV12Buffer::Create(
+      width, height, stride_y, stride_uv);
+
+  std::memcpy(buffer->MutableDataY(), plane_y, stride_y * buffer->height());
+  std::memcpy(buffer->MutableDataUV(), plane_uv, stride_uv * buffer->ChromaHeight());
+
+  VideoFrame captureFrame =
+      VideoFrame::Builder()
+          .set_video_frame_buffer(buffer)
+          .set_timestamp_rtp(0)
+          .set_timestamp_ms(rtc::TimeMillis())
+          .set_rotation(_rotateFrame)
+          .build();
+  captureFrame.set_ntp_time_ms(captureTime);
+
+  DeliverCapturedFrame(captureFrame);
+
+  return 0;
+}
+
 int32_t VideoCaptureImpl::StartCapture(
     const VideoCaptureCapability& capability) {
   RTC_DCHECK_RUN_ON(&api_checker_);
diff --git a/modules/video_capture/video_capture_impl.h b/modules/video_capture/video_capture_impl.h
index 1f7aa89883..c186806ae5 100644
--- a/modules/video_capture/video_capture_impl.h
+++ b/modules/video_capture/video_capture_impl.h
@@ -72,6 +72,17 @@ class RTC_EXPORT VideoCaptureImpl : public VideoCaptureModule {
 
   // `capture_time` must be specified in NTP time format in milliseconds.
   int32_t IncomingFrame(uint8_t* videoFrame,
+                        int32_t stride_y,
+                        uint8_t* plane_uv,
+                        int32_t stride_uv,
+                        size_t videoFrameLength,
+                        const VideoCaptureCapability& frameInfo,
+                        int64_t captureTime = 0);
+
+  int32_t IncomingFrameNV12(uint8_t* plane_y,
+                        int32_t stride_y,
+                        uint8_t* plane_uv,
+                        int32_t stride_uv,
                         size_t videoFrameLength,
                         const VideoCaptureCapability& frameInfo,
                         int64_t captureTime = 0);

diff --git a/modules/video_capture/windows/sink_filter_ds.cc b/modules/video_capture/windows/sink_filter_ds.cc
index 15f947a921..3390592ffa 100644
--- a/modules/video_capture/windows/sink_filter_ds.cc
+++ b/modules/video_capture/windows/sink_filter_ds.cc
@@ -920,7 +920,10 @@ void CaptureSinkFilter::ProcessCapturedFrame(
     size_t length,
     const VideoCaptureCapability& frame_info) {
   // Called on the capture thread.
-  capture_observer_->IncomingFrame(buffer, length, frame_info);
+  capture_observer_->IncomingFrame(
+      buffer, frame_info.width,
+      buffer + (static_cast<size_t>(frame_info.width) * frame_info.height),
+      frame_info.width, length, frame_info);
 }
 
 void CaptureSinkFilter::NotifyEvent(long code,
diff --git a/modules/video_capture/windows/video_capture_factory_windows.cc b/modules/video_capture/windows/video_capture_factory_windows.cc
index 481326c1d2..d299c7e175 100644
--- a/modules/video_capture/windows/video_capture_factory_windows.cc
+++ b/modules/video_capture/windows/video_capture_factory_windows.cc
@@ -9,15 +9,24 @@
  */
 
 #include "api/scoped_refptr.h"
+
+#if defined(WEBRTC_VIDEO_CAPTURE_WINRT)
+#include "modules/video_capture/winuwp/device_info_winrt.h"
+#include "modules/video_capture/winuwp/video_capture_winrt.h"
+#else
 #include "modules/video_capture/windows/video_capture_ds.h"
+#endif
 
 namespace webrtc {
 namespace videocapturemodule {
 
 // static
 VideoCaptureModule::DeviceInfo* VideoCaptureImpl::CreateDeviceInfo() {
-  // TODO(tommi): Use the Media Foundation version on Vista and up.
+#if defined(WEBRTC_VIDEO_CAPTURE_WINRT)
+  return DeviceInfoWinRT::Create();
+#else
   return DeviceInfoDS::Create();
+#endif  // WEBRTC_VIDEO_CAPTURE_WINRT
 }
 
 rtc::scoped_refptr<VideoCaptureModule> VideoCaptureImpl::Create(
@@ -25,8 +34,11 @@ rtc::scoped_refptr<VideoCaptureModule> VideoCaptureImpl::Create(
   if (device_id == nullptr)
     return nullptr;
 
-  // TODO(tommi): Use Media Foundation implementation for Vista and up.
+#if defined(WEBRTC_VIDEO_CAPTURE_WINRT)
+  auto capture = rtc::make_ref_counted<VideoCaptureWinRT>();
+#else
   auto capture = rtc::make_ref_counted<VideoCaptureDS>();
+#endif  // WEBRTC_VIDEO_CAPTURE_WINRT
   if (capture->Init(device_id) != 0) {
     return nullptr;
   }
diff --git a/webrtc.gni b/webrtc.gni
index 992c75c0e2..f89c4dd550 100644
--- a/webrtc.gni
+++ b/webrtc.gni
@@ -268,6 +268,15 @@ declare_args() {
 
   # When true, include the Perfetto library.
   rtc_use_perfetto = false
+
+  # Defines which API should be used by the video capture module on Windows.
+  # The following are the current options:
+  # False: It uses DirectShow APIs. DirectShow should be used on builds
+  #        that need to be compatible with old versions of Windows (Vista/7).
+  # True:  It uses the Windows::Media APIs. This option is recommended for
+  #        Windows 10. It is ok to use this option with any API family
+  #        (desktop (Win32), app (Store), ...).
+  rtc_win_video_capture_winrt = false
 }
 
 if (!build_with_mozilla) {
diff --git a/third_party/libyuv/include/libyuv/convert.h b/third_party/libyuv/include/libyuv/convert.h
index 93e7550b..e86f283d 100644
--- a/third_party/libyuv/include/libyuv/convert.h
+++ b/third_party/libyuv/include/libyuv/convert.h
@@ -837,6 +837,9 @@ int MJPGSize(const uint8_t* sample,
 LIBYUV_API
 int ConvertToI420(const uint8_t* sample,
                   size_t sample_size,
+                  int src_stride_y,
+                  const uint8_t* src_uv,
+                  int src_stride_uv,
                   uint8_t* dst_y,
                   int dst_stride_y,
                   uint8_t* dst_u,
diff --git a/third_party/libyuv/source/convert_to_i420.cc b/third_party/libyuv/source/convert_to_i420.cc
index 5869ecd7..ef1cb868 100644
--- a/third_party/libyuv/source/convert_to_i420.cc
+++ b/third_party/libyuv/source/convert_to_i420.cc
@@ -27,6 +27,9 @@ extern "C" {
 LIBYUV_API
 int ConvertToI420(const uint8_t* sample,
                   size_t sample_size,
+                  int src_stride_y,
+                  const uint8_t* src_uv,
+                  int src_stride_uv,
                   uint8_t* dst_y,
                   int dst_stride_y,
                   uint8_t* dst_u,
@@ -44,7 +47,7 @@ int ConvertToI420(const uint8_t* sample,
   uint32_t format = CanonicalFourCC(fourcc);
   int aligned_src_width = (src_width + 1) & ~1;
   const uint8_t* src;
-  const uint8_t* src_uv;
+  const uint8_t* src_uv_cropped;
   const int abs_src_height = (src_height < 0) ? -src_height : src_height;
   const int abs_crop_height = (crop_height < 0) ? -crop_height : crop_height;
   int r = 0;
@@ -171,19 +174,17 @@ int ConvertToI420(const uint8_t* sample,
       break;
     // Biplanar formats
     case FOURCC_NV12:
-      src = sample + (src_width * crop_y + crop_x);
-      src_uv = sample + (src_width * abs_src_height) +
-               ((crop_y / 2) * aligned_src_width) + ((crop_x / 2) * 2);
-      r = NV12ToI420Rotate(src, src_width, src_uv, aligned_src_width, dst_y,
+      src = sample + (src_stride_y * crop_y + crop_x);
+      src_uv_cropped = src_uv + ((crop_y / 2) * src_stride_uv) + ((crop_x / 2) * 2);
+      r = NV12ToI420Rotate(src, src_stride_y, src_uv_cropped, src_stride_uv, dst_y,
                            dst_stride_y, dst_u, dst_stride_u, dst_v,
                            dst_stride_v, crop_width, inv_crop_height, rotation);
       break;
     case FOURCC_NV21:
-      src = sample + (src_width * crop_y + crop_x);
-      src_uv = sample + (src_width * abs_src_height) +
-               ((crop_y / 2) * aligned_src_width) + ((crop_x / 2) * 2);
+      src = sample + (src_stride_y * crop_y + crop_x);
+      src_uv_cropped = src_uv + ((crop_y / 2) * src_stride_uv) + ((crop_x / 2) * 2);
       // Call NV12 but with dst_u and dst_v parameters swapped.
-      r = NV12ToI420Rotate(src, src_width, src_uv, aligned_src_width, dst_y,
+      r = NV12ToI420Rotate(src, src_stride_y, src_uv_cropped, src_stride_uv, dst_y,
                            dst_stride_y, dst_v, dst_stride_v, dst_u,
                            dst_stride_u, crop_width, inv_crop_height, rotation);
       break;
