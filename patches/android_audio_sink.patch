diff --git a/sdk/android/BUILD.gn b/sdk/android/BUILD.gn
index dcdd999bf6..2e5c032f60 100644
--- a/sdk/android/BUILD.gn
+++ b/sdk/android/BUILD.gn
@@ -287,6 +287,7 @@ if (is_android) {
     visibility = [ "*" ]
     sources = [
       "api/org/webrtc/AddIceObserver.java",
+      "api/org/webrtc/AudioTrackSink.java",
       "api/org/webrtc/AudioProcessingFactory.java",
       "api/org/webrtc/AudioSource.java",
       "api/org/webrtc/AudioTrack.java",
@@ -787,6 +788,7 @@ if (current_os == "linux" || is_android) {
       "src/jni/pc/add_ice_candidate_observer.cc",
       "src/jni/pc/add_ice_candidate_observer.h",
       "src/jni/pc/android_network_monitor.h",
+      "src/jni/audio_track_sink.cc",
       "src/jni/pc/audio_track.cc",
       "src/jni/pc/call_session_file_rotating_log_sink.cc",
       "src/jni/pc/crypto_options.cc",
@@ -905,6 +907,7 @@ if (current_os == "linux" || is_android) {
       "../../rtc_base:ssl",
       "../../rtc_base:stringutils",
       "../../rtc_base:threading",
+      "../../rtc_base/synchronization:mutex",
       "../../stats:rtc_stats",
       "../../system_wrappers:field_trial",
       "//third_party/abseil-cpp/absl/memory",
@@ -1534,6 +1537,7 @@ if (current_os == "linux" || is_android) {
   generate_jni("generated_peerconnection_jni") {
     sources = [
       "api/org/webrtc/AddIceObserver.java",
+      "api/org/webrtc/AudioTrackSink.java",
       "api/org/webrtc/AudioTrack.java",
       "api/org/webrtc/CallSessionFileRotatingLogSink.java",
       "api/org/webrtc/CandidatePairChangeEvent.java",
diff --git a/sdk/android/api/org/webrtc/AudioTrack.java b/sdk/android/api/org/webrtc/AudioTrack.java
index ca745db634..d1c253ec28 100644
--- a/sdk/android/api/org/webrtc/AudioTrack.java
+++ b/sdk/android/api/org/webrtc/AudioTrack.java
@@ -10,12 +10,51 @@
 
 package org.webrtc;
 
-/** Java wrapper for a C++ AudioTrackInterface */
+import java.util.IdentityHashMap;
+
+/**
+ * Java wrapper for a C++ AudioTrackInterface
+ *
+ * NOTE: addSink, removeSink, dispose の実装は VideoTrack の実装を真似しています。
+ */
 public class AudioTrack extends MediaStreamTrack {
+  private final IdentityHashMap<AudioTrackSink, Long> sinks = new IdentityHashMap<>();
+
   public AudioTrack(long nativeTrack) {
     super(nativeTrack);
   }
 
+  /** この AudioTrack から PCM データを受け取るための AudioTrackSink を追加する */
+  public void addSink(AudioTrackSink sink) {
+    if (sink == null) {
+      throw new IllegalArgumentException("AudioTrackSink must not be null");
+    }
+    if (!sinks.containsKey(sink)) {
+      final long nativeSink = nativeWrapSink(sink, this);
+      sinks.put(sink, nativeSink);
+      nativeAddSink(getNativeAudioTrack(), nativeSink);
+    }
+  }
+
+  /** AudioTrackSink の登録を解除する */
+  public void removeSink(AudioTrackSink sink) {
+    final Long nativeSink = sinks.remove(sink);
+    if (nativeSink != null) {
+      nativeRemoveSink(getNativeAudioTrack(), nativeSink);
+      nativeFreeSink(nativeSink);
+    }
+  }
+
+  @Override
+  public void dispose() {
+    for (long nativeSink : sinks.values()) {
+      nativeRemoveSink(getNativeAudioTrack(), nativeSink);
+      nativeFreeSink(nativeSink);
+    }
+    sinks.clear();
+    super.dispose();
+  }
+
   /** Sets the volume for the underlying MediaSource. Volume is a gain value in the range
    *  0 to 10.
    */
@@ -29,4 +68,8 @@ public class AudioTrack extends MediaStreamTrack {
   }
 
   private static native void nativeSetVolume(long track, double volume);
+  private static native void nativeAddSink(long audioTrackHandle, long sinkHandle);
+  private static native long nativeWrapSink(AudioTrackSink sink, Object track);
+  private static native void nativeRemoveSink(long audioTrackHandle, long sinkHandle);
+  private static native void nativeFreeSink(long sink);
 }
diff --git a/sdk/android/api/org/webrtc/AudioTrackSink.java b/sdk/android/api/org/webrtc/AudioTrackSink.java
new file mode 100644
index 0000000000..ccc3d6acb4
--- /dev/null
+++ b/sdk/android/api/org/webrtc/AudioTrackSink.java
@@ -0,0 +1,27 @@
+package org.webrtc;
+
+import java.nio.ByteBuffer;
+
+/** AudioTrack から PCM オーディオを受け取るためのインターフェース。 */
+public interface AudioTrackSink {
+  /**
+   * ネイティブのオーディオスレッドから PCM16 データとともに呼び出されます。
+   * このコールバック内の処理はバックグラウンドスレッドにオフロードするようにしてください。
+   *
+   * @param audioTrack 呼び出し元の AudioTrack。
+   * @param audioData リトルエンディアンの PCM16 サンプルが格納された ByteBuffer。
+   * @param bitsPerSample サンプル当たりのビット数 (例: 16)。
+   * @param sampleRate サンプルレート (単位: Hz)。
+   * @param numberOfChannels チャンネル数。
+   * @param numberOfFrames {@code audioData} に含まれるフレーム数。
+   */
+  @CalledByNative
+  void onData(AudioTrack audioTrack, ByteBuffer audioData, int bitsPerSample, int sampleRate,
+      int numberOfChannels, int numberOfFrames);
+
+  /** チャンネル数。-1 は指定なしを意味します。 */
+  @CalledByNative
+  default int getPreferredNumberOfChannels() {
+    return -1;
+  }
+}
diff --git a/sdk/android/src/jni/audio_track_sink.cc b/sdk/android/src/jni/audio_track_sink.cc
new file mode 100644
index 0000000000..4a4fd4d6ec
--- /dev/null
+++ b/sdk/android/src/jni/audio_track_sink.cc
@@ -0,0 +1,91 @@
+#include "sdk/android/src/jni/audio_track_sink.h"
+
+#include <cstring>
+#include <limits>
+
+#include "rtc_base/checks.h"
+#include "sdk/android/generated_peerconnection_jni/AudioTrackSink_jni.h"
+#include "sdk/android/native_api/jni/jvm.h"
+
+namespace webrtc {
+namespace jni {
+
+namespace {
+
+// AudioTrackSink::OnData が必要とする direct ByteBuffer の生成手続きを集約しておくことで、
+// 呼び出し側は「毎回新しい direct ByteBuffer を受け取る」前提の単純な実装にできる。
+// 併せて ByteBuffer クラスと allocateDirect メソッドを静的にキャッシュし、高頻度のコールでも
+// JNI シンボル探索を繰り返さずに済む。戻り値は direct ByteBuffer なので
+// GetDirectBufferAddress から PCM 書き込み用のポインタを安全に取得できる。
+ScopedJavaLocalRef<jobject> CreateDirectByteBuffer(JNIEnv* env,
+                                                    size_t capacity_bytes) {
+  // allocateDirect(int) の引数は int なので、サイズが 32bit を超えないことを確認。
+  RTC_CHECK_LE(capacity_bytes,
+               static_cast<size_t>(std::numeric_limits<jint>::max()));
+
+  static jclass byte_buffer_class = nullptr;
+  static jmethodID allocate_direct_method = nullptr;
+
+  if (!byte_buffer_class) {
+    // 初回のみクラス参照とメソッド ID を解決し、静的変数にキャッシュする。
+    // java.nio.ByteBuffer を解決し、次回以降も使えるようグローバル参照を保持する。
+    jclass local_class = env->FindClass("java/nio/ByteBuffer");
+    RTC_CHECK(local_class);
+    byte_buffer_class =
+        static_cast<jclass>(env->NewGlobalRef(local_class));
+    env->DeleteLocalRef(local_class);
+    RTC_CHECK(byte_buffer_class);
+    // ByteBuffer#allocateDirect(int) のメソッド ID を初期化時のみ取得。
+    allocate_direct_method = env->GetStaticMethodID(
+        byte_buffer_class, "allocateDirect", "(I)Ljava/nio/ByteBuffer;");
+    RTC_CHECK(allocate_direct_method);
+  }
+
+  // Java 側で direct ByteBuffer を確保し、JNI 経由で受け取る。
+  ScopedJavaLocalRef<jobject> buffer(
+      env,
+      env->CallStaticObjectMethod(byte_buffer_class, allocate_direct_method,
+                                  static_cast<jint>(capacity_bytes)));
+  // buffer を返す前に例外が発生していないかチェック
+  RTC_CHECK(!env->ExceptionCheck());
+  RTC_CHECK(buffer.obj());
+  return buffer;
+}
+
+}  // namespace
+
+// Java 側の AudioTrackSink インターフェースと AudioTrack を橋渡しするラッパー。
+// AudioTrackSourceInterface から提供される PCM データを JNI 経由で AudioTrackSink#onData に引き渡す。
+AudioTrackSinkWrapper::AudioTrackSinkWrapper(
+    JNIEnv* env,
+    const JavaRef<jobject>& j_sink,
+    const JavaRef<jobject>& j_track)
+    : j_sink_(env, j_sink), j_track_(env, j_track) {}
+
+AudioTrackSinkWrapper::~AudioTrackSinkWrapper() = default;
+
+void AudioTrackSinkWrapper::OnData(const void* audio_data,
+                                   int bits_per_sample,
+                                   int sample_rate,
+                                   size_t number_of_channels,
+                                   size_t number_of_frames) {
+  JNIEnv* env = AttachCurrentThreadIfNeeded();
+  const size_t byte_size =
+      number_of_frames * number_of_channels * (bits_per_sample / 8);
+
+  ScopedJavaLocalRef<jobject> buffer = CreateDirectByteBuffer(env, byte_size);
+  void* direct_ptr = env->GetDirectBufferAddress(buffer.obj());
+  RTC_CHECK(direct_ptr);
+  std::memcpy(direct_ptr, audio_data, byte_size);
+  Java_AudioTrackSink_onData(env, j_sink_, j_track_, buffer, bits_per_sample,
+                            sample_rate, static_cast<int>(number_of_channels),
+                            static_cast<int>(number_of_frames));
+}
+
+int AudioTrackSinkWrapper::NumPreferredChannels() const {
+  JNIEnv* env = AttachCurrentThreadIfNeeded();
+  return Java_AudioTrackSink_getPreferredNumberOfChannels(env, j_sink_);
+}
+
+}  // namespace jni
+}  // namespace webrtc
diff --git a/sdk/android/src/jni/audio_track_sink.h b/sdk/android/src/jni/audio_track_sink.h
new file mode 100644
index 0000000000..1f92478826
--- /dev/null
+++ b/sdk/android/src/jni/audio_track_sink.h
@@ -0,0 +1,38 @@
+#ifndef SDK_ANDROID_SRC_JNI_AUDIO_TRACK_SINK_H_
+#define SDK_ANDROID_SRC_JNI_AUDIO_TRACK_SINK_H_
+
+#include <cstddef>
+#include <cstdint>
+
+#include "api/media_stream_interface.h"
+#include "sdk/android/native_api/jni/scoped_java_ref.h"
+
+namespace webrtc {
+namespace jni {
+
+// JNI ブリッジで AudioTrackSinkInterface のコールバックを
+// Java 側の org.webrtc.AudioTrackSink に転送する
+class AudioTrackSinkWrapper : public AudioTrackSinkInterface {
+ public:
+  AudioTrackSinkWrapper(JNIEnv* env,
+                        const JavaRef<jobject>& j_sink,
+                        const JavaRef<jobject>& j_track);
+  ~AudioTrackSinkWrapper() override;
+
+  void OnData(const void* audio_data,
+              int bits_per_sample,
+              int sample_rate,
+              size_t number_of_channels,
+              size_t number_of_frames) override;
+
+  int NumPreferredChannels() const override;
+
+ private:
+  ScopedJavaGlobalRef<jobject> j_sink_;
+  ScopedJavaGlobalRef<jobject> j_track_;
+};
+
+}  // namespace jni
+}  // namespace webrtc
+
+#endif  // SDK_ANDROID_SRC_JNI_AUDIO_TRACK_SINK_H_
diff --git a/sdk/android/src/jni/pc/audio_track.cc b/sdk/android/src/jni/pc/audio_track.cc
index 1ec0f44e95..1cf7888b10 100644
--- a/sdk/android/src/jni/pc/audio_track.cc
+++ b/sdk/android/src/jni/pc/audio_track.cc
@@ -13,6 +13,9 @@
 #include "api/media_stream_interface.h"
 #include "api/scoped_refptr.h"
 #include "sdk/android/generated_peerconnection_jni/AudioTrack_jni.h"
+#include "sdk/android/native_api/jni/scoped_java_ref.h"
+#include "sdk/android/src/jni/jni_helpers.h"
+#include "sdk/android/src/jni/audio_track_sink.h"
 
 namespace webrtc {
 namespace jni {
@@ -23,5 +26,30 @@ static void JNI_AudioTrack_SetVolume(JNIEnv*, jlong j_p, jdouble volume) {
   source->SetVolume(volume);
 }
 
+static void JNI_AudioTrack_AddSink(JNIEnv*,
+                                   jlong native_track,
+                                   jlong native_sink) {
+  reinterpret_cast<AudioTrackInterface*>(native_track)
+      ->AddSink(reinterpret_cast<AudioTrackSinkWrapper*>(native_sink));
+}
+
+static void JNI_AudioTrack_RemoveSink(JNIEnv*,
+                                      jlong native_track,
+                                      jlong native_sink) {
+  reinterpret_cast<AudioTrackInterface*>(native_track)
+      ->RemoveSink(reinterpret_cast<AudioTrackSinkWrapper*>(native_sink));
+}
+
+static jlong JNI_AudioTrack_WrapSink(
+    JNIEnv* env,
+    const JavaParamRef<jobject>& j_sink,
+    const JavaParamRef<jobject>& j_track) {
+  return jlongFromPointer(new AudioTrackSinkWrapper(env, j_sink, j_track));
+}
+
+static void JNI_AudioTrack_FreeSink(JNIEnv*, jlong native_sink) {
+  delete reinterpret_cast<AudioTrackSinkWrapper*>(native_sink);
+}
+
 }  // namespace jni
 }  // namespace webrtc
