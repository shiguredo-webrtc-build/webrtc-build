diff --git a/api/video_codecs/simulcast_stream.h b/api/video_codecs/simulcast_stream.h
index 4dbee5bd4b..29b13ed96b 100644
--- a/api/video_codecs/simulcast_stream.h
+++ b/api/video_codecs/simulcast_stream.h
@@ -14,6 +14,7 @@
 #include <optional>
 
 #include "api/video_codecs/scalability_mode.h"
+#include "api/video_codecs/sdp_video_format.h"
 #include "rtc_base/system/rtc_export.h"
 
 namespace webrtc {
@@ -41,6 +42,7 @@ struct RTC_EXPORT SimulcastStream {
   unsigned int minBitrate = 0;     // kilobits/sec.
   unsigned int qpMax = 0;          // minimum quality
   bool active = false;             // encoded and sent.
+  SdpVideoFormat format = SdpVideoFormat("Unset");
 };
 
 }  // namespace webrtc
diff --git a/call/rtp_config.cc b/call/rtp_config.cc
index 02cc0f40b1..16911297ef 100644
--- a/call/rtp_config.cc
+++ b/call/rtp_config.cc
@@ -239,4 +239,31 @@ std::optional<std::string> RtpConfig::GetRidForSsrc(uint32_t ssrc) const {
   return std::nullopt;
 }
 
+RtpStreamConfig RtpConfig::GetStreamConfig(size_t index) const {
+  // GetStreamConfig function usually returns stream_configs[index], but if
+  // stream_configs is not initialized (i.e., index >= stream_configs.size()),
+  // it creates and returns an RtpStreamConfig using fields such as ssrcs, rids,
+  // payload_name, and payload_type from RtpConfig.
+  RTC_DCHECK_LT(index, ssrcs.size());
+  if (index < stream_configs.size()) {
+    return stream_configs[index];
+  }
+  RtpStreamConfig stream_config;
+  stream_config.ssrc = ssrcs[index];
+  if (index < rids.size()) {
+    stream_config.rid = rids[index];
+  }
+  stream_config.payload_name = payload_name;
+  stream_config.payload_type = payload_type;
+  stream_config.raw_payload = raw_payload;
+  if (!rtx.ssrcs.empty()) {
+    RTC_DCHECK_EQ(ssrcs.size(), rtx.ssrcs.size());
+    auto& stream_config_rtx = stream_config.rtx.emplace();
+    stream_config_rtx.ssrc = rtx.ssrcs[index];
+    stream_config_rtx.payload_type = rtx.payload_type;
+  }
+
+  return stream_config;
+}
+
 }  // namespace webrtc
diff --git a/call/rtp_config.h b/call/rtp_config.h
index 6b79e55f40..d77289febc 100644
--- a/call/rtp_config.h
+++ b/call/rtp_config.h
@@ -193,6 +193,9 @@ struct RtpConfig {
   uint32_t GetMediaSsrcAssociatedWithRtxSsrc(uint32_t rtx_ssrc) const;
   uint32_t GetMediaSsrcAssociatedWithFlexfecSsrc(uint32_t flexfec_ssrc) const;
   std::optional<std::string> GetRidForSsrc(uint32_t ssrc) const;
+
+  // Returns send config for RTP stream by provided simulcast `index`.
+  RtpStreamConfig GetStreamConfig(size_t index) const;
 };
 }  // namespace webrtc
 #endif  // CALL_RTP_CONFIG_H_
diff --git a/call/rtp_video_sender.cc b/call/rtp_video_sender.cc
index be56eac626..8964e4b6bc 100644
--- a/call/rtp_video_sender.cc
+++ b/call/rtp_video_sender.cc
@@ -330,11 +330,13 @@ std::vector<RtpStreamSender> CreateRtpStreamSenders(
   return rtp_streams;
 }
 
-std::optional<VideoCodecType> GetVideoCodecType(const RtpConfig& config) {
-  if (config.raw_payload) {
+std::optional<VideoCodecType> GetVideoCodecType(const RtpConfig& config,
+                                                size_t simulcast_index) {
+  auto stream_config = config.GetStreamConfig(simulcast_index);
+  if (stream_config.raw_payload) {
     return std::nullopt;
   }
-  return PayloadStringToCodecType(config.payload_name);
+  return PayloadStringToCodecType(stream_config.payload_name);
 }
 bool TransportSeqNumExtensionConfigured(const RtpConfig& config) {
   return absl::c_any_of(config.extensions, [](const RtpExtension& ext) {
@@ -421,7 +423,6 @@ RtpVideoSender::RtpVideoSender(
                                           crypto_options,
                                           std::move(frame_transformer))),
       rtp_config_(rtp_config),
-      codec_type_(GetVideoCodecType(rtp_config)),
       transport_(transport),
       independent_frame_ids_(
           !env.field_trials().IsDisabled(
@@ -470,12 +471,14 @@ RtpVideoSender::RtpVideoSender(
   }
 
   bool fec_enabled = false;
-  for (const RtpStreamSender& stream : rtp_streams_) {
+  for (size_t i = 0; i < rtp_streams_.size(); i++) {
+    const RtpStreamSender& stream = rtp_streams_[i];
     // Simulcast has one module for each layer. Set the CNAME on all modules.
     stream.rtp_rtcp->SetCNAME(rtp_config_.c_name.c_str());
     stream.rtp_rtcp->SetMaxRtpPacketSize(rtp_config_.max_packet_size);
-    stream.rtp_rtcp->RegisterSendPayloadFrequency(rtp_config_.payload_type,
-                                                  kVideoPayloadTypeFrequency);
+    stream.rtp_rtcp->RegisterSendPayloadFrequency(
+        rtp_config_.GetStreamConfig(i).payload_type,
+        kVideoPayloadTypeFrequency);
     if (stream.fec_generator != nullptr) {
       fec_enabled = true;
     }
@@ -576,7 +579,7 @@ EncodedImageCallback::Result RtpVideoSender::OnEncodedImage(
   // knowledge of the offset to a single place.
   if (!rtp_streams_[simulcast_index].rtp_rtcp->OnSendingRtpFrame(
           encoded_image.RtpTimestamp(), encoded_image.capture_time_ms_,
-          rtp_config_.payload_type,
+          rtp_config_.GetStreamConfig(simulcast_index).payload_type,
           encoded_image._frameType == VideoFrameType::kVideoFrameKey)) {
     // The payload router could be active but this module isn't sending.
     return Result(Result::ERROR_SEND_FAILED);
@@ -616,7 +619,9 @@ EncodedImageCallback::Result RtpVideoSender::OnEncodedImage(
 
   bool send_result =
       rtp_streams_[simulcast_index].sender_video->SendEncodedImage(
-          rtp_config_.payload_type, codec_type_, rtp_timestamp, encoded_image,
+          rtp_config_.GetStreamConfig(simulcast_index).payload_type,
+          GetVideoCodecType(rtp_config_, simulcast_index), rtp_timestamp,
+          encoded_image,
           params_[simulcast_index].GetRtpVideoHeader(
               encoded_image, codec_specific_info, frame_id),
           expected_retransmission_time);
@@ -754,9 +759,12 @@ void RtpVideoSender::ConfigureSsrcs(
 
   // Configure RTX payload types.
   RTC_DCHECK_GE(rtp_config_.rtx.payload_type, 0);
-  for (const RtpStreamSender& stream : rtp_streams_) {
-    stream.rtp_rtcp->SetRtxSendPayloadType(rtp_config_.rtx.payload_type,
-                                           rtp_config_.payload_type);
+  for (size_t i = 0; i < rtp_streams_.size(); ++i) {
+    const RtpStreamSender& stream = rtp_streams_[i];
+    RtpStreamConfig stream_config = rtp_config_.GetStreamConfig(i);
+    RTC_DCHECK(stream_config.rtx);
+    stream.rtp_rtcp->SetRtxSendPayloadType(stream_config.rtx->payload_type,
+                                           stream_config.payload_type);
     stream.rtp_rtcp->SetRtxSendStatus(kRtxRetransmitted |
                                       kRtxRedundantPayloads);
   }
@@ -948,7 +956,7 @@ int RtpVideoSender::ProtectionRequest(const FecProtectionParams* delta_params,
 void RtpVideoSender::SetRetransmissionMode(int retransmission_mode) {
   MutexLock lock(&mutex_);
   for (const RtpStreamSender& stream : rtp_streams_) {
-      stream.sender_video->SetRetransmissionSetting(retransmission_mode);
+    stream.sender_video->SetRetransmissionSetting(retransmission_mode);
   }
 }
 
diff --git a/call/rtp_video_sender_unittest.cc b/call/rtp_video_sender_unittest.cc
index b35b332fbf..2fbed29506 100644
--- a/call/rtp_video_sender_unittest.cc
+++ b/call/rtp_video_sender_unittest.cc
@@ -84,6 +84,7 @@ using ::testing::SaveArg;
 using ::testing::SizeIs;
 
 const int8_t kPayloadType = 96;
+const int8_t kPayloadType2 = 98;
 const uint32_t kSsrc1 = 12345;
 const uint32_t kSsrc2 = 23456;
 const uint32_t kRtxSsrc1 = 34567;
@@ -133,7 +134,8 @@ VideoSendStream::Config CreateVideoSendStreamConfig(
     Transport* transport,
     const std::vector<uint32_t>& ssrcs,
     const std::vector<uint32_t>& rtx_ssrcs,
-    int payload_type) {
+    int payload_type,
+    rtc::ArrayView<const int> payload_types) {
   VideoSendStream::Config config(transport);
   config.rtp.ssrcs = ssrcs;
   config.rtp.rtx.ssrcs = rtx_ssrcs;
@@ -145,6 +147,20 @@ VideoSendStream::Config CreateVideoSendStreamConfig(
   config.rtp.extensions.emplace_back(RtpDependencyDescriptorExtension::Uri(),
                                      kDependencyDescriptorExtensionId);
   config.rtp.extmap_allow_mixed = true;
+
+  if (!payload_types.empty()) {
+    RTC_CHECK_EQ(payload_types.size(), ssrcs.size());
+    for (size_t i = 0; i < ssrcs.size(); ++i) {
+      auto& stream_config = config.rtp.stream_configs.emplace_back();
+      stream_config.ssrc = ssrcs[i];
+      stream_config.payload_type = payload_types[i];
+      if (i < rtx_ssrcs.size()) {
+        auto& rtx = stream_config.rtx.emplace();
+        rtx.ssrc = rtx_ssrcs[i];
+        rtx.payload_type = payload_types[i] + 1;
+      }
+    }
+  }
   return config;
 }
 
@@ -157,6 +173,7 @@ class RtpVideoSenderTestFixture {
       const std::map<uint32_t, RtpPayloadState>& suspended_payload_states,
       FrameCountObserver* frame_count_observer,
       rtc::scoped_refptr<FrameTransformerInterface> frame_transformer,
+      const std::vector<int>& payload_types,
       const FieldTrialsView* field_trials = nullptr)
       : time_controller_(Timestamp::Millis(1000000)),
         env_(CreateEnvironment(&field_trials_,
@@ -166,7 +183,8 @@ class RtpVideoSenderTestFixture {
         config_(CreateVideoSendStreamConfig(&transport_,
                                             ssrcs,
                                             rtx_ssrcs,
-                                            payload_type)),
+                                            payload_type,
+                                            payload_types)),
         bitrate_config_(GetBitrateConfig()),
         transport_controller_(
             RtpTransportConfig{.env = env_, .bitrate_config = bitrate_config_}),
@@ -188,6 +206,22 @@ class RtpVideoSenderTestFixture {
         std::make_unique<FecControllerDefault>(env_), nullptr, CryptoOptions{},
         frame_transformer);
   }
+  RtpVideoSenderTestFixture(
+      const std::vector<uint32_t>& ssrcs,
+      const std::vector<uint32_t>& rtx_ssrcs,
+      int payload_type,
+      const std::map<uint32_t, RtpPayloadState>& suspended_payload_states,
+      FrameCountObserver* frame_count_observer,
+      rtc::scoped_refptr<FrameTransformerInterface> frame_transformer,
+      const FieldTrialsView* field_trials = nullptr)
+      : RtpVideoSenderTestFixture(ssrcs,
+                                  rtx_ssrcs,
+                                  payload_type,
+                                  suspended_payload_states,
+                                  frame_count_observer,
+                                  frame_transformer,
+                                  /*payload_types=*/{},
+                                  field_trials) {}
 
   RtpVideoSenderTestFixture(
       const std::vector<uint32_t>& ssrcs,
@@ -202,6 +236,7 @@ class RtpVideoSenderTestFixture {
                                   suspended_payload_states,
                                   frame_count_observer,
                                   /*frame_transformer=*/nullptr,
+                                  /*payload_types=*/{},
                                   field_trials) {}
 
   RtpVideoSenderTestFixture(
@@ -216,6 +251,7 @@ class RtpVideoSenderTestFixture {
                                   suspended_payload_states,
                                   /*frame_count_observer=*/nullptr,
                                   /*frame_transformer=*/nullptr,
+                                  /*payload_types=*/{},
                                   field_trials) {}
 
   ~RtpVideoSenderTestFixture() { SetSending(false); }
@@ -953,6 +989,79 @@ TEST(RtpVideoSenderTest,
   EXPECT_EQ(dd_s1.frame_number(), 1002);
 }
 
+TEST(RtpVideoSenderTest, MixedCodecSimulcastPayloadType) {
+  // When multiple payload types are set, verify that the payload type switches
+  // corresponding to the simulcast index.
+  RtpVideoSenderTestFixture test({kSsrc1, kSsrc2}, {kRtxSsrc1, kRtxSsrc2},
+                                 kPayloadType, {}, nullptr, nullptr,
+                                 {kPayloadType, kPayloadType2});
+  test.SetSending(true);
+
+  std::vector<uint16_t> rtp_sequence_numbers;
+  std::vector<RtpPacket> sent_packets;
+  EXPECT_CALL(test.transport(), SendRtp)
+      .Times(3)
+      .WillRepeatedly([&](rtc::ArrayView<const uint8_t> packet,
+                          const PacketOptions& options) -> bool {
+        RtpPacket& rtp_packet = sent_packets.emplace_back();
+        EXPECT_TRUE(rtp_packet.Parse(packet));
+        rtp_sequence_numbers.push_back(rtp_packet.SequenceNumber());
+        return true;
+      });
+
+  const uint8_t kPayload[1] = {'a'};
+  EncodedImage encoded_image;
+  encoded_image.SetEncodedData(
+      EncodedImageBuffer::Create(kPayload, sizeof(kPayload)));
+
+  CodecSpecificInfo codec_specific;
+  codec_specific.codecType = VideoCodecType::kVideoCodecVP8;
+
+  encoded_image.SetSimulcastIndex(0);
+  ASSERT_EQ(test.router()->OnEncodedImage(encoded_image, &codec_specific).error,
+            EncodedImageCallback::Result::OK);
+  ASSERT_EQ(test.router()->OnEncodedImage(encoded_image, &codec_specific).error,
+            EncodedImageCallback::Result::OK);
+  encoded_image.SetSimulcastIndex(1);
+  ASSERT_EQ(test.router()->OnEncodedImage(encoded_image, &codec_specific).error,
+            EncodedImageCallback::Result::OK);
+
+  test.AdvanceTime(TimeDelta::Millis(33));
+  ASSERT_THAT(sent_packets, SizeIs(3));
+  EXPECT_EQ(sent_packets[0].PayloadType(), kPayloadType);
+  EXPECT_EQ(sent_packets[1].PayloadType(), kPayloadType);
+  EXPECT_EQ(sent_packets[2].PayloadType(), kPayloadType2);
+
+  // Verify that NACK is sent to the RTX payload type corresponding to the
+  // payload type.
+  rtcp::Nack nack1, nack2;
+  nack1.SetMediaSsrc(kSsrc1);
+  nack2.SetMediaSsrc(kSsrc2);
+  nack1.SetPacketIds({rtp_sequence_numbers[0], rtp_sequence_numbers[1]});
+  nack2.SetPacketIds({rtp_sequence_numbers[2]});
+  rtc::Buffer nack_buffer1 = nack1.Build();
+  rtc::Buffer nack_buffer2 = nack2.Build();
+
+  std::vector<RtpPacket> sent_rtx_packets;
+  EXPECT_CALL(test.transport(), SendRtp)
+      .Times(3)
+      .WillRepeatedly([&](rtc::ArrayView<const uint8_t> packet,
+                          const PacketOptions& options) {
+        RtpPacket& rtp_packet = sent_rtx_packets.emplace_back();
+        EXPECT_TRUE(rtp_packet.Parse(packet));
+        return true;
+      });
+  test.router()->DeliverRtcp(nack_buffer1.data(), nack_buffer1.size());
+  test.router()->DeliverRtcp(nack_buffer2.data(), nack_buffer2.size());
+
+  test.AdvanceTime(TimeDelta::Millis(33));
+
+  ASSERT_THAT(sent_rtx_packets, SizeIs(3));
+  EXPECT_EQ(sent_rtx_packets[0].PayloadType(), kPayloadType + 1);
+  EXPECT_EQ(sent_rtx_packets[1].PayloadType(), kPayloadType + 1);
+  EXPECT_EQ(sent_rtx_packets[2].PayloadType(), kPayloadType2 + 1);
+}
+
 TEST(RtpVideoSenderTest,
      SupportsDependencyDescriptorForVp8NotProvidedByEncoder) {
   constexpr uint8_t kPayload[1] = {'a'};
diff --git a/media/base/media_engine.cc b/media/base/media_engine.cc
index 0ce26ff9b6..1f327753d2 100644
--- a/media/base/media_engine.cc
+++ b/media/base/media_engine.cc
@@ -208,14 +208,14 @@ webrtc::RTCError CheckRtpParametersValues(
       }
     }
 
-    if (!field_trials.IsEnabled("WebRTC-MixedCodecSimulcast")) {
-      if (i > 0 && rtp_parameters.encodings[i - 1].codec !=
-                       rtp_parameters.encodings[i].codec) {
-        LOG_AND_RETURN_ERROR(RTCErrorType::UNSUPPORTED_OPERATION,
-                             "Attempted to use different codec values for "
-                             "different encodings.");
-      }
-    }
+    //if (!field_trials.IsEnabled("WebRTC-MixedCodecSimulcast")) {
+    //  if (i > 0 && rtp_parameters.encodings[i - 1].codec !=
+    //                   rtp_parameters.encodings[i].codec) {
+    //    LOG_AND_RETURN_ERROR(RTCErrorType::UNSUPPORTED_OPERATION,
+    //                         "Attempted to use different codec values for "
+    //                         "different encodings.");
+    //  }
+    //}
   }
 
   if (has_scale_resolution_down_to &&
diff --git a/media/engine/simulcast_encoder_adapter.cc b/media/engine/simulcast_encoder_adapter.cc
index f0d7bf9fd1..48f51480ae 100644
--- a/media/engine/simulcast_encoder_adapter.cc
+++ b/media/engine/simulcast_encoder_adapter.cc
@@ -307,6 +307,10 @@ int SimulcastEncoderAdapter::Release() {
 
   inited_.store(0);
 
+  // サイマルキャストマルチコーデック下で Reconfigure
+  // された時にうまく動かなくなるのでキャッシュは使わない
+  DestroyStoredEncoders();
+
   return WEBRTC_VIDEO_CODEC_OK;
 }
 
@@ -342,7 +346,8 @@ int SimulcastEncoderAdapter::InitEncode(
   std::unique_ptr<EncoderContext> encoder_context = FetchOrCreateEncoderContext(
       /*is_lowest_quality_stream=*/(
           is_legacy_singlecast ||
-          codec_.simulcastStream[lowest_quality_stream_idx].active));
+          codec_.simulcastStream[lowest_quality_stream_idx].active),
+      codec_.simulcastStream[0].format);
   if (encoder_context == nullptr) {
     return WEBRTC_VIDEO_CODEC_MEMORY;
   }
@@ -357,6 +362,19 @@ int SimulcastEncoderAdapter::InitEncode(
   //   and configures each to produce a single stream.
 
   int active_streams_count = CountActiveStreams(*codec_settings);
+  bool is_mixed_codec = std::invoke([this]() -> bool {
+    if (codec_.numberOfSimulcastStreams >= 2) {
+      for (size_t i = 0; i < codec_.numberOfSimulcastStreams - 1; i++) {
+        for (size_t j = i + 1; j < codec_.numberOfSimulcastStreams; j++) {
+          if (!codec_.simulcastStream[i].format.IsSameCodec(
+                  codec_.simulcastStream[j].format)) {
+            return true;
+          }
+        }
+      }
+    }
+    return false;
+  });
   // If we only have a single active layer it is better to create an encoder
   // with only one configured layer than creating it with all-but-one disabled
   // layers because that way we control scaling.
@@ -364,6 +382,7 @@ int SimulcastEncoderAdapter::InitEncode(
   // forces the use of SEA with separate encoders to support per-layer
   // handling of PLIs.
   bool separate_encoders_needed =
+      is_mixed_codec ||
       !encoder_context->encoder().GetEncoderInfo().supports_simulcast ||
       active_streams_count == 1 || per_layer_pli_;
   RTC_LOG(LS_INFO) << "[SEA] InitEncode: total_streams_count: "
@@ -409,10 +428,23 @@ int SimulcastEncoderAdapter::InitEncode(
       continue;
     }
 
-    if (encoder_context == nullptr) {
-      encoder_context = FetchOrCreateEncoderContext(
-          /*is_lowest_quality_stream=*/stream_idx == lowest_quality_stream_idx);
-    }
+    // サイマルキャストマルチコーデック下では事前に作られた encoder_context と
+    // ここで本来生成するべき encoder_context
+    // のクラスが異なってる可能性があるため 毎回生成し直す必要がある。
+    //
+    // 例えば r0.codec==H264 && r0.active==false && r1.codec==VP8 &&
+    // r1.active==true の場合に問題が起きる。
+    //
+    // なので encoder_context == nullptr という条件を削除する。
+    //
+    // if (encoder_context == nullptr) {
+    //   encoder_context = FetchOrCreateEncoderContext(
+    //       /*is_lowest_quality_stream=*/stream_idx ==
+    //       lowest_quality_stream_idx);
+    // }
+    encoder_context = FetchOrCreateEncoderContext(
+        /*is_lowest_quality_stream=*/stream_idx == lowest_quality_stream_idx,
+        codec_.simulcastStream[stream_idx].format);
     if (encoder_context == nullptr) {
       Release();
       return WEBRTC_VIDEO_CODEC_MEMORY;
@@ -729,7 +761,8 @@ void SimulcastEncoderAdapter::DestroyStoredEncoders() {
 
 std::unique_ptr<SimulcastEncoderAdapter::EncoderContext>
 SimulcastEncoderAdapter::FetchOrCreateEncoderContext(
-    bool is_lowest_quality_stream) const {
+    bool is_lowest_quality_stream,
+    const SdpVideoFormat& format) const {
   RTC_DCHECK_RUN_ON(&encoder_queue_);
   bool prefer_temporal_support = fallback_encoder_factory_ != nullptr &&
                                  is_lowest_quality_stream &&
@@ -751,11 +784,11 @@ SimulcastEncoderAdapter::FetchOrCreateEncoderContext(
     cached_encoder_contexts_.erase(encoder_context_iter);
   } else {
     std::unique_ptr<VideoEncoder> primary_encoder =
-        primary_encoder_factory_->Create(env_, video_format_);
+        primary_encoder_factory_->Create(env_, format);
 
     std::unique_ptr<VideoEncoder> fallback_encoder;
     if (fallback_encoder_factory_ != nullptr) {
-      fallback_encoder = fallback_encoder_factory_->Create(env_, video_format_);
+      fallback_encoder = fallback_encoder_factory_->Create(env_, format);
     }
 
     std::unique_ptr<VideoEncoder> encoder;
@@ -774,14 +807,14 @@ SimulcastEncoderAdapter::FetchOrCreateEncoderContext(
             prefer_temporal_support);
       }
     } else if (fallback_encoder != nullptr) {
-      RTC_LOG(LS_WARNING) << "Failed to create primary " << video_format_.name
+      RTC_LOG(LS_WARNING) << "Failed to create primary " << format.name
                           << " encoder. Use fallback encoder.";
       fallback_info = fallback_encoder->GetEncoderInfo();
       primary_info = fallback_info;
       encoder = std::move(fallback_encoder);
     } else {
       RTC_LOG(LS_ERROR) << "Failed to create primary and fallback "
-                        << video_format_.name << " encoders.";
+                        << format.name << " encoders.";
       return nullptr;
     }
 
@@ -804,6 +837,7 @@ webrtc::VideoCodec SimulcastEncoderAdapter::MakeStreamCodec(
   webrtc::VideoCodec codec_params = codec;
   const SimulcastStream& stream_params = codec.simulcastStream[stream_idx];
 
+  codec_params.codecType = PayloadStringToCodecType(stream_params.format.name);
   codec_params.numberOfSimulcastStreams = 0;
   codec_params.width = stream_params.width;
   codec_params.height = stream_params.height;
@@ -921,7 +955,7 @@ VideoEncoder::EncoderInfo SimulcastEncoderAdapter::GetEncoderInfo() const {
     // Create one encoder and query it.
 
     std::unique_ptr<SimulcastEncoderAdapter::EncoderContext> encoder_context =
-        FetchOrCreateEncoderContext(/*is_lowest_quality_stream=*/true);
+        nullptr;
     if (encoder_context == nullptr) {
       return encoder_info;
     }
diff --git a/media/engine/simulcast_encoder_adapter.h b/media/engine/simulcast_encoder_adapter.h
index 92d10a4ab8..8806a7f607 100644
--- a/media/engine/simulcast_encoder_adapter.h
+++ b/media/engine/simulcast_encoder_adapter.h
@@ -153,7 +153,8 @@ class RTC_EXPORT SimulcastEncoderAdapter : public VideoEncoder {
   // `cached_encoder_contexts_`. It's const because it's used from
   // const GetEncoderInfo().
   std::unique_ptr<EncoderContext> FetchOrCreateEncoderContext(
-      bool is_lowest_quality_stream) const;
+      bool is_lowest_quality_stream,
+      const SdpVideoFormat& format) const;
 
   webrtc::VideoCodec MakeStreamCodec(const webrtc::VideoCodec& codec,
                                      int stream_idx,
diff --git a/media/engine/webrtc_video_engine.cc b/media/engine/webrtc_video_engine.cc
index 781e997cc4..19c648596c 100644
--- a/media/engine/webrtc_video_engine.cc
+++ b/media/engine/webrtc_video_engine.cc
@@ -400,15 +400,15 @@ static bool ValidateStreamParams(const StreamParams& sp) {
 }
 
 // Returns true if the given codec is disallowed from doing simulcast.
-bool IsCodecDisabledForSimulcast(bool legacy_scalability_mode,
-                                 webrtc::VideoCodecType codec_type) {
-  if (legacy_scalability_mode && (codec_type == webrtc::kVideoCodecVP9 ||
-                                  codec_type == webrtc::kVideoCodecAV1)) {
-    return true;
-  }
-
-  return false;
-}
+// bool IsCodecDisabledForSimulcast(bool legacy_scalability_mode,
+//                                 webrtc::VideoCodecType codec_type) {
+//  if (legacy_scalability_mode && (codec_type == webrtc::kVideoCodecVP9 ||
+//                                  codec_type == webrtc::kVideoCodecAV1)) {
+//    return true;
+//  }
+//
+//  return false;
+//}
 
 bool IsLayerActive(const webrtc::RtpEncodingParameters& layer) {
   return layer.active &&
@@ -1290,6 +1290,9 @@ bool WebRtcVideoSendChannel::ApplyChangedParams(
   if (changed_params.send_codecs)
     send_codecs_ = *changed_params.send_codecs;
 
+  if (changed_params.send_codecs)
+    send_codecs_ = *changed_params.send_codecs;
+
   if (changed_params.extmap_allow_mixed) {
     SetExtmapAllowMixed(*changed_params.extmap_allow_mixed);
   }
@@ -1421,28 +1424,50 @@ webrtc::RTCError WebRtcVideoSendChannel::SetRtpSendParameters(
         break;
     }
 
-    // Since we validate that all layers have the same value, we can just check
-    // the first layer.
-    // TODO(orphis): Support mixed-codec simulcast
-    if (parameters.encodings[0].codec && send_codec_ &&
-        !IsSameRtpCodec(send_codec_->codec, *parameters.encodings[0].codec)) {
-      RTC_LOG(LS_VERBOSE) << "Trying to change codec to "
-                          << parameters.encodings[0].codec->name;
-      auto matched_codec =
-          absl::c_find_if(negotiated_codecs_, [&](auto negotiated_codec) {
-            return IsSameRtpCodec(negotiated_codec.codec,
-                                  *parameters.encodings[0].codec);
-          });
-      if (matched_codec == negotiated_codecs_.end()) {
-        return webrtc::InvokeSetParametersCallback(
-            callback, webrtc::RTCError(
-                          webrtc::RTCErrorType::INVALID_MODIFICATION,
-                          "Attempted to use an unsupported codec for layer 0"));
+    if (send_codec_ &&
+        std::any_of(parameters.encodings.begin(), parameters.encodings.end(),
+                    [](const auto& e) { return e.codec; })) {
+      std::vector<VideoCodecSettings> send_codecs;
+
+      for (size_t i = 0; i < parameters.encodings.size(); i++) {
+        const auto& codec = parameters.encodings[i].codec;
+        std::optional<VideoCodecSettings> found_codec;
+        if (!codec) {
+          found_codec = *send_codec_;
+        } else if (i < send_codecs_.size()) {
+          const auto& send_codec = send_codecs_[i];
+          if (IsSameRtpCodec(send_codec.codec, *codec)) {
+            found_codec = send_codec;
+          }
+        }
+        if (!found_codec) {
+          RTC_DCHECK(codec);
+          auto matched_codec =
+              absl::c_find_if(negotiated_codecs_, [&](auto negotiated_codec) {
+                return IsSameRtpCodec(negotiated_codec.codec, *codec);
+              });
+          if (matched_codec == negotiated_codecs_.end()) {
+            return webrtc::InvokeSetParametersCallback(
+                callback,
+                webrtc::RTCError(
+                    webrtc::RTCErrorType::INVALID_MODIFICATION,
+                    "Attempted to use an unsupported codec for layer " +
+                        std::to_string(i)));
+          }
+          found_codec = *matched_codec;
+        }
+        RTC_DCHECK(found_codec);
+        send_codecs.push_back(*found_codec);
       }
 
-      ChangedSenderParameters params;
-      params.send_codec = *matched_codec;
-      ApplyChangedParams(params);
+      if (send_codecs_ != send_codecs) {
+        ChangedSenderParameters params;
+        if (!send_codecs.empty()) {
+          params.send_codec = send_codecs[0];
+        }
+        params.send_codecs = send_codecs;
+        ApplyChangedParams(params);
+      }
     }
 
     SetPreferredDscp(new_dscp);
@@ -2008,6 +2033,32 @@ void WebRtcVideoSendChannel::WebRtcVideoSendStream::SetCodec(
   }
   parameters_.codec_settings_list = codec_settings_list;
 
+  // Settings for mixed-codec simulcast
+  if (!codec_settings_list.empty()) {
+    RTC_DCHECK_EQ(parameters_.config.rtp.ssrcs.size(),
+                  codec_settings_list.size());
+    parameters_.config.rtp.stream_configs.resize(
+        parameters_.config.rtp.ssrcs.size());
+    for (size_t i = 0; i < codec_settings_list.size(); i++) {
+      auto& stream_config = parameters_.config.rtp.stream_configs[i];
+      const auto& cs = codec_settings_list[i];
+      stream_config.ssrc = parameters_.config.rtp.ssrcs[i];
+      if (i < parameters_.config.rtp.rids.size()) {
+        stream_config.rid = parameters_.config.rtp.rids[i];
+      }
+      stream_config.payload_name = cs.codec.name;
+      stream_config.payload_type = cs.codec.id;
+      stream_config.raw_payload =
+          cs.codec.packetization == kPacketizationParamRaw;
+      if (i < parameters_.config.rtp.rtx.ssrcs.size()) {
+        auto& rtx = stream_config.rtx.emplace();
+        rtx.ssrc = parameters_.config.rtp.rtx.ssrcs[i];
+        rtx.payload_type = cs.rtx_payload_type;
+      }
+    }
+  }
+  parameters_.codec_settings_list = codec_settings_list;
+
   // TODO(bugs.webrtc.org/8830): Avoid recreation, it should be enough to call
   // ReconfigureEncoder.
   RTC_LOG(LS_INFO) << "RecreateWebRtcStream (send) because of SetCodec.";
@@ -2226,25 +2277,25 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::CreateVideoEncoderConfig(
   // number of negotiated ssrcs but this may be capped below depending on the
   // `legacy_scalability_mode` and codec used.
   encoder_config.number_of_streams = parameters_.config.rtp.ssrcs.size();
-  bool legacy_scalability_mode = true;
-  for (const webrtc::RtpEncodingParameters& encoding :
-       rtp_parameters_.encodings) {
-    if (encoding.scalability_mode.has_value() &&
-        (encoding.scale_resolution_down_by.has_value() ||
-         encoding.scale_resolution_down_to.has_value())) {
-      legacy_scalability_mode = false;
-      break;
-    }
-  }
+  // bool legacy_scalability_mode = true;
+  // for (const webrtc::RtpEncodingParameters& encoding :
+  //      rtp_parameters_.encodings) {
+  //   if (encoding.scalability_mode.has_value() &&
+  //       (encoding.scale_resolution_down_by.has_value() ||
+  //        encoding.scale_resolution_down_to.has_value())) {
+  //     legacy_scalability_mode = false;
+  //     break;
+  //   }
+  // }
   // Maybe limit the number of simulcast layers depending on
   // `legacy_scalability_mode`, codec types (VP9/AV1). This path only exists
   // for backwards compatibility and will one day be deleted. If you want SVC,
   // please specify with the `scalability_mode` API instead amd disabling all
   // but one encoding.
-  if (IsCodecDisabledForSimulcast(legacy_scalability_mode,
-                                  encoder_config.codec_type)) {
-    encoder_config.number_of_streams = 1;
-  }
+  // if (IsCodecDisabledForSimulcast(legacy_scalability_mode,
+  //                                 encoder_config.codec_type)) {
+  //   encoder_config.number_of_streams = 1;
+  // }
 
   // parameters_.max_bitrate comes from the max bitrate set at the SDP
   // (m-section) level with the attribute "b=AS." Note that stream max bitrate
@@ -2312,6 +2363,11 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::CreateVideoEncoderConfig(
       encoder_config.simulcast_layers[i].num_temporal_layers =
           *rtp_parameters_.encodings[i].num_temporal_layers;
     }
+    if (rtp_parameters_.encodings[i].codec) {
+      encoder_config.simulcast_layers[i].video_format = webrtc::SdpVideoFormat(
+          rtp_parameters_.encodings[i].codec->name,
+          rtp_parameters_.encodings[i].codec->parameters);
+    }
     encoder_config.simulcast_layers[i].scale_resolution_down_to =
         rtp_parameters_.encodings[i].scale_resolution_down_to;
   }
diff --git a/media/engine/webrtc_video_engine.h b/media/engine/webrtc_video_engine.h
index 5224929838..7ad52cb7ac 100644
--- a/media/engine/webrtc_video_engine.h
+++ b/media/engine/webrtc_video_engine.h
@@ -834,6 +834,7 @@ class WebRtcVideoReceiveChannel : public MediaChannelUtil,
   std::optional<VideoCodecSettings> send_codec_ RTC_GUARDED_BY(thread_checker_);
   std::vector<VideoCodecSettings> negotiated_codecs_
       RTC_GUARDED_BY(thread_checker_);
+  std::vector<VideoCodecSettings> send_codecs_ RTC_GUARDED_BY(thread_checker_);
 
   std::vector<webrtc::RtpExtension> send_rtp_extensions_
       RTC_GUARDED_BY(thread_checker_);
diff --git a/modules/video_coding/utility/simulcast_rate_allocator.cc b/modules/video_coding/utility/simulcast_rate_allocator.cc
index dd054030f1..a336c48d0e 100644
--- a/modules/video_coding/utility/simulcast_rate_allocator.cc
+++ b/modules/video_coding/utility/simulcast_rate_allocator.cc
@@ -175,8 +175,28 @@ void SimulcastRateAllocator::DistributeAllocationToSimulcastLayers(
       min_bitrate = std::min(hysteresis_factor * min_bitrate, target_bitrate);
     }
     if (left_in_stable_allocation < min_bitrate) {
-      allocated_bitrates->set_bw_limited(true);
-      break;
+      bool is_mixed_codec = std::invoke([this]() {
+        if (codec_.numberOfSimulcastStreams >= 2) {
+          for (size_t i = 0; i < codec_.numberOfSimulcastStreams - 1; i++) {
+            for (size_t j = i + 1; j < codec_.numberOfSimulcastStreams; j++) {
+              if (!codec_.simulcastStream[i].format.IsSameCodec(
+                      codec_.simulcastStream[j].format)) {
+                return true;
+              }
+            }
+          }
+        }
+        return false;
+      });
+
+      if (is_mixed_codec) {
+        // トータルのビットレートが低すぎると、高いレイヤーにビットレートを割り当てることができなくなるのだけど、
+        // サイマルキャストマルチコーデックでそれをされると困るので、トータルのビットレートを超えても無理やり出力する
+        left_in_stable_allocation = left_in_total_allocation = min_bitrate;
+      } else {
+        allocated_bitrates->set_bw_limited(true);
+        break;
+      }
     }
 
     // We are allocating to this layer so it is the current active allocation.
@@ -336,10 +356,11 @@ const VideoCodec& webrtc::SimulcastRateAllocator::GetCodec() const {
 
 int SimulcastRateAllocator::NumTemporalStreams(size_t simulcast_id) const {
   return std::max<uint8_t>(
-      1,
-      codec_.codecType == kVideoCodecVP8 && codec_.numberOfSimulcastStreams == 0
-          ? codec_.VP8().numberOfTemporalLayers
-          : codec_.simulcastStream[simulcast_id].numberOfTemporalLayers);
+      1, codec_.simulcastStream[simulcast_id].format.IsSameCodec(
+             webrtc::SdpVideoFormat::VP8()) &&
+                 codec_.numberOfSimulcastStreams == 0
+             ? codec_.VP8().numberOfTemporalLayers
+             : codec_.simulcastStream[simulcast_id].numberOfTemporalLayers);
 }
 
 void SimulcastRateAllocator::SetLegacyConferenceMode(bool enabled) {
diff --git a/modules/video_coding/video_codec_initializer.cc b/modules/video_coding/video_codec_initializer.cc
index 9c2cdc62b8..f30043e54d 100644
--- a/modules/video_coding/video_codec_initializer.cc
+++ b/modules/video_coding/video_codec_initializer.cc
@@ -114,6 +114,7 @@ VideoCodec VideoCodecInitializer::SetupCodec(
     sim_stream->targetBitrate = streams[i].target_bitrate_bps / 1000;
     sim_stream->maxBitrate = streams[i].max_bitrate_bps / 1000;
     sim_stream->qpMax = streams[i].max_qp;
+    sim_stream->format = config.GetSimulcastVideoFormat(i);
 
     int num_temporal_layers =
         streams[i].scalability_mode.has_value()
diff --git a/pc/sdp_offer_answer.cc b/pc/sdp_offer_answer.cc
index 0542910941..2a970c8187 100644
--- a/pc/sdp_offer_answer.cc
+++ b/pc/sdp_offer_answer.cc
@@ -768,7 +768,8 @@ void AddPlanBRtpSenderOptions(
 cricket::MediaDescriptionOptions GetMediaDescriptionOptionsForTransceiver(
     RtpTransceiver* transceiver,
     const std::string& mid,
-    bool is_create_offer) {
+    bool is_create_offer,
+    const std::vector<RidDescription>& receive_rids = {}) {
   // NOTE: a stopping transceiver should be treated as a stopped one in
   // createOffer as specified in
   // https://w3c.github.io/webrtc-pc/#dom-rtcpeerconnection-createoffer.
@@ -811,11 +812,10 @@ cricket::MediaDescriptionOptions GetMediaDescriptionOptionsForTransceiver(
       continue;
     }
     auto send_rid = RidDescription(encoding.rid, RidDirection::kSend);
-    if (encoding.codec) {
-      auto send_codecs = transceiver->sender_internal()->GetSendCodecs();
-      for (const cricket::Codec& codec : send_codecs) {
-        if (codec.MatchesRtpCodec(*encoding.codec)) {
-          send_rid.payload_types.push_back(codec.id);
+    if (!is_create_offer && encoding.codec) {
+      for (const auto& receive_rid : receive_rids) {
+        if (receive_rid.rid == encoding.rid) {
+          send_rid.payload_types = receive_rid.payload_types;
           break;
         }
       }
@@ -4528,7 +4528,8 @@ void SdpOfferAnswerHandler::GetOptionsForUnifiedPlanAnswer(
         session_options->media_description_options.push_back(
             GetMediaDescriptionOptionsForTransceiver(
                 transceiver->internal(), content.name,
-                /*is_create_offer=*/false));
+                /*is_create_offer=*/false,
+                content.media_description()->receive_rids()));
       } else {
         // This should only happen with rejected transceivers.
         RTC_DCHECK(content.rejected);
diff --git a/video/config/encoder_stream_factory.cc b/video/config/encoder_stream_factory.cc
index ec83ebe819..0bcfe88752 100644
--- a/video/config/encoder_stream_factory.cc
+++ b/video/config/encoder_stream_factory.cc
@@ -529,7 +529,24 @@ std::vector<webrtc::Resolution> EncoderStreamFactory::GetStreamResolutions(
       resolutions.push_back({.width = width, .height = height});
     }
   } else {
-    size_t min_num_layers = FindRequiredActiveLayers(encoder_config);
+    bool is_mixed_codec = std::invoke([&]() {
+      if (encoder_config.simulcast_layers.size() >= 2) {
+        for (size_t i = 0; i < encoder_config.simulcast_layers.size() - 1;
+             i++) {
+          for (size_t j = i + 1; j < encoder_config.simulcast_layers.size();
+               j++) {
+            if (!encoder_config.GetSimulcastVideoFormat(i).IsSameCodec(
+                    encoder_config.GetSimulcastVideoFormat(j))) {
+              return true;
+            }
+          }
+        }
+      }
+      return false;
+    });
+    size_t min_num_layers = is_mixed_codec
+                                ? encoder_config.number_of_streams
+                                : FindRequiredActiveLayers(encoder_config);
     size_t max_num_layers =
         !encoder_config.HasScaleResolutionDownTo()
             ? LimitSimulcastLayerCount(
diff --git a/video/config/video_encoder_config.cc b/video/config/video_encoder_config.cc
index 9dc9a52c89..80f72bad99 100644
--- a/video/config/video_encoder_config.cc
+++ b/video/config/video_encoder_config.cc
@@ -155,4 +155,27 @@ void VideoEncoderConfig::Av1EncoderSpecificSettings::FillVideoCodecAv1(
   *av1_settings = specifics_;
 }
 
+VideoCodecType VideoEncoderConfig::GetSimulcastCodecType(
+    size_t stream_index) const {
+  if (stream_index >= simulcast_layers.size()) {
+    return codec_type;
+  }
+  if (!simulcast_layers[stream_index].video_format) {
+    return codec_type;
+  }
+  return PayloadStringToCodecType(
+      simulcast_layers[stream_index].video_format->name);
+}
+
+const SdpVideoFormat& VideoEncoderConfig::GetSimulcastVideoFormat(
+    size_t stream_index) const {
+  if (stream_index >= simulcast_layers.size()) {
+    return video_format;
+  }
+  if (!simulcast_layers[stream_index].video_format) {
+    return video_format;
+  }
+  return *simulcast_layers[stream_index].video_format;
+}
+
 }  // namespace webrtc
diff --git a/video/config/video_encoder_config.h b/video/config/video_encoder_config.h
index 59ee866f53..bff797130e 100644
--- a/video/config/video_encoder_config.h
+++ b/video/config/video_encoder_config.h
@@ -83,6 +83,9 @@ struct VideoStream {
   // e.g. if source only provides lower resolution or
   // if resource adaptation is active.
   std::optional<Resolution> scale_resolution_down_to;
+
+  // このビデオストリームが利用するべきビデオフォーマット
+  std::optional<SdpVideoFormat> video_format;
 };
 
 class VideoEncoderConfig {
@@ -168,6 +171,10 @@ class VideoEncoderConfig {
 
   bool HasScaleResolutionDownTo() const;
 
+  // stream_index 番目のストリームが利用する設定
+  VideoCodecType GetSimulcastCodecType(size_t stream_index) const;
+  const SdpVideoFormat& GetSimulcastVideoFormat(size_t stream_index) const;
+
   // TODO(bugs.webrtc.org/6883): Consolidate on one of these.
   VideoCodecType codec_type;
   SdpVideoFormat video_format;
diff --git a/video/video_stream_encoder.cc b/video/video_stream_encoder.cc
index c62a3e1c90..902e8ea5db 100644
--- a/video/video_stream_encoder.cc
+++ b/video/video_stream_encoder.cc
@@ -936,8 +936,24 @@ void VideoStreamEncoder::ConfigureEncoder(VideoEncoderConfig config,
       frame_cadence_adapter_->SetZeroHertzModeEnabled(std::nullopt);
     }
 
+    bool video_format_changed =
+        encoder_config_.video_format != config.video_format;
+    if (!video_format_changed && encoder_config_.simulcast_layers.size() !=
+                                     config.simulcast_layers.size()) {
+      video_format_changed = true;
+    }
+    if (!video_format_changed) {
+      for (size_t i = 0; i < encoder_config_.simulcast_layers.size(); i++) {
+        if (encoder_config_.GetSimulcastVideoFormat(i) !=
+            config.GetSimulcastVideoFormat(i)) {
+          video_format_changed = true;
+          break;
+        }
+      }
+    }
+
     pending_encoder_creation_ =
-        (!encoder_ || encoder_config_.video_format != config.video_format ||
+        (!encoder_ || video_format_changed ||
          max_data_payload_length_ != max_data_payload_length);
     encoder_config_ = std::move(config);
     max_data_payload_length_ = max_data_payload_length;
@@ -976,6 +992,8 @@ void VideoStreamEncoder::ReconfigureEncoder() {
 
   bool encoder_reset_required = false;
   if (pending_encoder_creation_) {
+    ReleaseEncoder();
+
     // Destroy existing encoder instance before creating a new one. Otherwise
     // attempt to create another instance will fail if encoder factory
     // supports only single instance of encoder of given type.
@@ -2106,8 +2124,7 @@ EncodedImage VideoStreamEncoder::AugmentEncodedImage(
   // TODO(https://crbug.com/webrtc/14891): If we want to support a mix of
   // simulcast and SVC we'll also need to consider the case where we have both
   // simulcast and spatial indices.
-  int stream_idx = encoded_image.SpatialIndex().value_or(
-      encoded_image.SimulcastIndex().value_or(0));
+  int stream_idx = encoded_image.SimulcastIndex().value_or(0);
 
   frame_encode_metadata_writer_.FillMetadataAndTimingInfo(stream_idx,
                                                           &image_copy);
@@ -2150,45 +2167,45 @@ EncodedImageCallback::Result VideoStreamEncoder::OnEncodedImage(
   // need to update on quality convergence.
   unsigned int image_width = image_copy._encodedWidth;
   unsigned int image_height = image_copy._encodedHeight;
-  encoder_queue_->PostTask([this, codec_type, image_width, image_height,
-                            simulcast_index, qp = image_copy.qp_,
-                            is_steady_state_refresh_frame =
-                                image_copy.IsSteadyStateRefreshFrame()] {
-    RTC_DCHECK_RUN_ON(encoder_queue_.get());
-
-    // Check if the encoded image has reached target quality.
-    bool at_target_quality =
-        quality_convergence_controller_.AddSampleAndCheckTargetQuality(
-            simulcast_index, qp, is_steady_state_refresh_frame);
-
-    // Let the frame cadence adapter know about quality convergence.
-    if (frame_cadence_adapter_)
-      frame_cadence_adapter_->UpdateLayerQualityConvergence(simulcast_index,
-                                                            at_target_quality);
-
-    // Currently, the internal quality scaler is used for VP9 instead of the
-    // webrtc qp scaler (in the no-svc case or if only a single spatial layer is
-    // encoded). It has to be explicitly detected and reported to adaptation
-    // metrics.
-    if (codec_type == VideoCodecType::kVideoCodecVP9 &&
-        send_codec_.VP9()->automaticResizeOn) {
-      unsigned int expected_width = send_codec_.width;
-      unsigned int expected_height = send_codec_.height;
-      int num_active_layers = 0;
-      for (int i = 0; i < send_codec_.VP9()->numberOfSpatialLayers; ++i) {
-        if (send_codec_.spatialLayers[i].active) {
-          ++num_active_layers;
-          expected_width = send_codec_.spatialLayers[i].width;
-          expected_height = send_codec_.spatialLayers[i].height;
+  encoder_queue_->PostTask(
+      [this, codec_type, image_width, image_height, simulcast_index,
+       qp = image_copy.qp_,
+       is_steady_state_refresh_frame = image_copy.IsSteadyStateRefreshFrame()] {
+        RTC_DCHECK_RUN_ON(encoder_queue_.get());
+
+        // Check if the encoded image has reached target quality.
+        bool at_target_quality =
+            quality_convergence_controller_.AddSampleAndCheckTargetQuality(
+                simulcast_index, qp, is_steady_state_refresh_frame);
+
+        // Let the frame cadence adapter know about quality convergence.
+        if (frame_cadence_adapter_)
+          frame_cadence_adapter_->UpdateLayerQualityConvergence(
+              simulcast_index, at_target_quality);
+
+        // Currently, the internal quality scaler is used for VP9 instead of the
+        // webrtc qp scaler (in the no-svc case or if only a single spatial
+        // layer is encoded). It has to be explicitly detected and reported to
+        // adaptation metrics.
+        if (codec_type == VideoCodecType::kVideoCodecVP9 &&
+            send_codec_.VP9()->automaticResizeOn) {
+          unsigned int expected_width = send_codec_.width;
+          unsigned int expected_height = send_codec_.height;
+          int num_active_layers = 0;
+          for (int i = 0; i < send_codec_.VP9()->numberOfSpatialLayers; ++i) {
+            if (send_codec_.spatialLayers[i].active) {
+              ++num_active_layers;
+              expected_width = send_codec_.spatialLayers[i].width;
+              expected_height = send_codec_.spatialLayers[i].height;
+            }
+          }
+          RTC_DCHECK_LE(num_active_layers, 1)
+              << "VP9 quality scaling is enabled for "
+                 "SVC with several active layers.";
+          encoder_stats_observer_->OnEncoderInternalScalerUpdate(
+              image_width < expected_width || image_height < expected_height);
         }
-      }
-      RTC_DCHECK_LE(num_active_layers, 1)
-          << "VP9 quality scaling is enabled for "
-             "SVC with several active layers.";
-      encoder_stats_observer_->OnEncoderInternalScalerUpdate(
-          image_width < expected_width || image_height < expected_height);
-    }
-  });
+      });
 
   // Encoded is called on whatever thread the real encoder implementation run
   // on. In the case of hardware encoders, there might be several encoders
