diff --git a/AUTHORS b/AUTHORS
index 48214c53a6..b3fe543c1c 100644
--- a/AUTHORS
+++ b/AUTHORS
@@ -118,6 +118,7 @@ Satender Saroha <ssaroha@yahoo.com>
 Saul Kravitz <Saul.Kravitz@celera.com>
 Sergio Garcia Murillo <sergio.garcia.murillo@gmail.com>
 Shaofan Qi <vshaqi@gmail.com>
+Shigemasa Watanabe <shigemasa7watanabe@gmail.com>
 Shuhai Peng <shuhai.peng@intel.com>
 Seija <doremylover123@gmail.com>
 Silviu Caragea <silviu.cpp@gmail.com>
diff --git a/api/video_codecs/simulcast_stream.h b/api/video_codecs/simulcast_stream.h
index 50ec21e544..3f27f3c730 100644
--- a/api/video_codecs/simulcast_stream.h
+++ b/api/video_codecs/simulcast_stream.h
@@ -13,6 +13,7 @@
 
 #include "absl/types/optional.h"
 #include "api/video_codecs/scalability_mode.h"
+#include "api/video_codecs/sdp_video_format.h"
 #include "rtc_base/system/rtc_export.h"
 
 namespace webrtc {
@@ -40,6 +41,7 @@ struct RTC_EXPORT SimulcastStream {
   unsigned int minBitrate = 0;     // kilobits/sec.
   unsigned int qpMax = 0;          // minimum quality
   bool active = false;             // encoded and sent.
+  SdpVideoFormat format = SdpVideoFormat("Unset");
 };
 
 }  // namespace webrtc
diff --git a/call/rtp_config.cc b/call/rtp_config.cc
index 5457a94696..ba4bab6a11 100644
--- a/call/rtp_config.cc
+++ b/call/rtp_config.cc
@@ -63,6 +63,30 @@ bool UlpfecConfig::operator==(const UlpfecConfig& other) const {
          red_rtx_payload_type == other.red_rtx_payload_type;
 }
 
+std::string RtpStreamConfig::ToString() const {
+  char buf[1024];
+  rtc::SimpleStringBuilder ss(buf);
+  ss << "{ssrc: " << ssrc;
+  ss << ", rid: " << rid;
+  ss << ", payload_name: " << payload_name;
+  ss << ", payload_type: " << payload_type;
+  ss << ", raw_payload: " << (raw_payload ? "true" : "false");
+  if (rtx.has_value()) {
+    ss << ", rtx: " << rtx->ToString();
+  }
+  ss << '}';
+  return ss.str();
+}
+
+std::string RtpStreamConfig::Rtx::ToString() const {
+  char buf[1024];
+  rtc::SimpleStringBuilder ss(buf);
+  ss << "{ssrc: " << ssrc;
+  ss << ", payload_type: " << payload_type;
+  ss << '}';
+  return ss.str();
+}
+
 RtpConfig::RtpConfig() = default;
 RtpConfig::RtpConfig(const RtpConfig&) = default;
 RtpConfig::~RtpConfig() = default;
@@ -107,6 +131,14 @@ std::string RtpConfig::ToString() const {
   ss << ", payload_type: " << payload_type;
   ss << ", raw_payload: " << (raw_payload ? "true" : "false");
 
+  ss << ", stream_configs: [";
+  for (size_t i = 0; i < stream_configs.size(); ++i) {
+    ss << stream_configs[i].ToString();
+    if (i != stream_configs.size() - 1)
+      ss << ", ";
+  }
+  ss << ']';
+
   ss << ", flexfec: {payload_type: " << flexfec.payload_type;
   ss << ", ssrc: " << flexfec.ssrc;
   ss << ", protected_media_ssrcs: [";
@@ -200,4 +232,31 @@ absl::optional<std::string> RtpConfig::GetRidForSsrc(uint32_t ssrc) const {
   return absl::nullopt;
 }
 
+RtpStreamConfig RtpConfig::GetStreamConfig(size_t index) const {
+  // GetStreamConfig function usually returns stream_configs[index], but if
+  // stream_configs is not initialized (i.e., index >= stream_configs.size()),
+  // it creates and returns an RtpStreamConfig using fields such as ssrcs, rids,
+  // payload_name, and payload_type from RtpConfig.
+  RTC_DCHECK_LT(index, ssrcs.size());
+  if (index < stream_configs.size()) {
+    return stream_configs[index];
+  }
+  RtpStreamConfig stream_config;
+  stream_config.ssrc = ssrcs[index];
+  if (index < rids.size()) {
+    stream_config.rid = rids[index];
+  }
+  stream_config.payload_name = payload_name;
+  stream_config.payload_type = payload_type;
+  stream_config.raw_payload = raw_payload;
+  if (!rtx.ssrcs.empty()) {
+    RTC_DCHECK_EQ(ssrcs.size(), rtx.ssrcs.size());
+    auto& stream_config_rtx = stream_config.rtx.emplace();
+    stream_config_rtx.ssrc = rtx.ssrcs[index];
+    stream_config_rtx.payload_type = rtx.payload_type;
+  }
+
+  return stream_config;
+}
+
 }  // namespace webrtc
diff --git a/call/rtp_config.h b/call/rtp_config.h
index ec76d42c01..a8e373b692 100644
--- a/call/rtp_config.h
+++ b/call/rtp_config.h
@@ -68,6 +68,25 @@ struct UlpfecConfig {
   int red_rtx_payload_type;
 };
 
+struct RtpStreamConfig {
+  std::string ToString() const;
+
+  uint32_t ssrc = 0;
+  std::string rid;
+  std::string payload_name;
+  int payload_type = -1;
+  bool raw_payload = false;
+  struct Rtx {
+    std::string ToString() const;
+    // SSRC to use for the RTX stream.
+    uint32_t ssrc = 0;
+
+    // Payload type to use for the RTX stream.
+    int payload_type = -1;
+  };
+  std::optional<Rtx> rtx;
+};
+
 static const size_t kDefaultMaxPacketSize = 1500 - 40;  // TCP over IPv4.
 struct RtpConfig {
   RtpConfig();
@@ -115,6 +134,9 @@ struct RtpConfig {
   // frame descriptor RTP header extension).
   bool raw_payload = false;
 
+  // Configurations for each RTP stream
+  std::vector<RtpStreamConfig> stream_configs;
+
   // See LntfConfig for description.
   LntfConfig lntf;
 
@@ -171,6 +193,9 @@ struct RtpConfig {
   uint32_t GetMediaSsrcAssociatedWithRtxSsrc(uint32_t rtx_ssrc) const;
   uint32_t GetMediaSsrcAssociatedWithFlexfecSsrc(uint32_t flexfec_ssrc) const;
   absl::optional<std::string> GetRidForSsrc(uint32_t ssrc) const;
+
+  // Returns send config for RTP stream by provided simulcast `index`.
+  RtpStreamConfig GetStreamConfig(size_t index) const;
 };
 }  // namespace webrtc
 #endif  // CALL_RTP_CONFIG_H_
diff --git a/call/rtp_video_sender.cc b/call/rtp_video_sender.cc
index 2d9a525643..5c3111e35f 100644
--- a/call/rtp_video_sender.cc
+++ b/call/rtp_video_sender.cc
@@ -298,11 +298,13 @@ std::vector<RtpStreamSender> CreateRtpStreamSenders(
   return rtp_streams;
 }
 
-absl::optional<VideoCodecType> GetVideoCodecType(const RtpConfig& config) {
-  if (config.raw_payload) {
+absl::optional<VideoCodecType> GetVideoCodecType(const RtpConfig& config,
+                                                 size_t simulcast_index) {
+  auto stream_config = config.GetStreamConfig(simulcast_index);
+  if (stream_config.raw_payload) {
     return absl::nullopt;
   }
-  return PayloadStringToCodecType(config.payload_name);
+  return PayloadStringToCodecType(stream_config.payload_name);
 }
 bool TransportSeqNumExtensionConfigured(const RtpConfig& config) {
   return absl::c_any_of(config.extensions, [](const RtpExtension& ext) {
@@ -387,7 +389,6 @@ RtpVideoSender::RtpVideoSender(
                                           crypto_options,
                                           std::move(frame_transformer))),
       rtp_config_(rtp_config),
-      codec_type_(GetVideoCodecType(rtp_config)),
       transport_(transport),
       independent_frame_ids_(
           !env.field_trials().IsDisabled(
@@ -433,12 +434,14 @@ RtpVideoSender::RtpVideoSender(
   }
 
   bool fec_enabled = false;
-  for (const RtpStreamSender& stream : rtp_streams_) {
+  for (size_t i = 0; i < rtp_streams_.size(); i++) {
+    const RtpStreamSender& stream = rtp_streams_[i];
     // Simulcast has one module for each layer. Set the CNAME on all modules.
     stream.rtp_rtcp->SetCNAME(rtp_config_.c_name.c_str());
     stream.rtp_rtcp->SetMaxRtpPacketSize(rtp_config_.max_packet_size);
-    stream.rtp_rtcp->RegisterSendPayloadFrequency(rtp_config_.payload_type,
-                                                  kVideoPayloadTypeFrequency);
+    stream.rtp_rtcp->RegisterSendPayloadFrequency(
+        rtp_config_.GetStreamConfig(i).payload_type,
+        kVideoPayloadTypeFrequency);
     if (stream.fec_generator != nullptr) {
       fec_enabled = true;
     }
@@ -532,7 +535,7 @@ EncodedImageCallback::Result RtpVideoSender::OnEncodedImage(
   // knowledge of the offset to a single place.
   if (!rtp_streams_[simulcast_index].rtp_rtcp->OnSendingRtpFrame(
           encoded_image.RtpTimestamp(), encoded_image.capture_time_ms_,
-          rtp_config_.payload_type,
+          rtp_config_.GetStreamConfig(simulcast_index).payload_type,
           encoded_image._frameType == VideoFrameType::kVideoFrameKey)) {
     // The payload router could be active but this module isn't sending.
     return Result(Result::ERROR_SEND_FAILED);
@@ -572,7 +575,9 @@ EncodedImageCallback::Result RtpVideoSender::OnEncodedImage(
 
   bool send_result =
       rtp_streams_[simulcast_index].sender_video->SendEncodedImage(
-          rtp_config_.payload_type, codec_type_, rtp_timestamp, encoded_image,
+          rtp_config_.GetStreamConfig(simulcast_index).payload_type,
+          GetVideoCodecType(rtp_config_, simulcast_index), rtp_timestamp,
+          encoded_image,
           params_[simulcast_index].GetRtpVideoHeader(
               encoded_image, codec_specific_info, frame_id),
           expected_retransmission_time);
@@ -696,9 +701,12 @@ void RtpVideoSender::ConfigureSsrcs(
 
   // Configure RTX payload types.
   RTC_DCHECK_GE(rtp_config_.rtx.payload_type, 0);
-  for (const RtpStreamSender& stream : rtp_streams_) {
-    stream.rtp_rtcp->SetRtxSendPayloadType(rtp_config_.rtx.payload_type,
-                                           rtp_config_.payload_type);
+  for (size_t i = 0; i < rtp_streams_.size(); ++i) {
+    const RtpStreamSender& stream = rtp_streams_[i];
+    RtpStreamConfig stream_config = rtp_config_.GetStreamConfig(i);
+    RTC_DCHECK(stream_config.rtx);
+    stream.rtp_rtcp->SetRtxSendPayloadType(stream_config.rtx->payload_type,
+                                           stream_config.payload_type);
     stream.rtp_rtcp->SetRtxSendStatus(kRtxRetransmitted |
                                       kRtxRedundantPayloads);
   }
@@ -890,7 +898,7 @@ int RtpVideoSender::ProtectionRequest(const FecProtectionParams* delta_params,
 void RtpVideoSender::SetRetransmissionMode(int retransmission_mode) {
   MutexLock lock(&mutex_);
   for (const RtpStreamSender& stream : rtp_streams_) {
-      stream.sender_video->SetRetransmissionSetting(retransmission_mode);
+    stream.sender_video->SetRetransmissionSetting(retransmission_mode);
   }
 }
 
diff --git a/call/rtp_video_sender_unittest.cc b/call/rtp_video_sender_unittest.cc
index d3959fb5ad..63fd1c0900 100644
--- a/call/rtp_video_sender_unittest.cc
+++ b/call/rtp_video_sender_unittest.cc
@@ -46,6 +46,7 @@ using ::testing::SaveArg;
 using ::testing::SizeIs;
 
 const int8_t kPayloadType = 96;
+const int8_t kPayloadType2 = 98;
 const uint32_t kSsrc1 = 12345;
 const uint32_t kSsrc2 = 23456;
 const uint32_t kRtxSsrc1 = 34567;
@@ -95,7 +96,8 @@ VideoSendStream::Config CreateVideoSendStreamConfig(
     Transport* transport,
     const std::vector<uint32_t>& ssrcs,
     const std::vector<uint32_t>& rtx_ssrcs,
-    int payload_type) {
+    int payload_type,
+    rtc::ArrayView<const int> payload_types) {
   VideoSendStream::Config config(transport);
   config.rtp.ssrcs = ssrcs;
   config.rtp.rtx.ssrcs = rtx_ssrcs;
@@ -107,6 +109,20 @@ VideoSendStream::Config CreateVideoSendStreamConfig(
   config.rtp.extensions.emplace_back(RtpDependencyDescriptorExtension::Uri(),
                                      kDependencyDescriptorExtensionId);
   config.rtp.extmap_allow_mixed = true;
+
+  if (!payload_types.empty()) {
+    RTC_CHECK_EQ(payload_types.size(), ssrcs.size());
+    for (size_t i = 0; i < ssrcs.size(); ++i) {
+      auto& stream_config = config.rtp.stream_configs.emplace_back();
+      stream_config.ssrc = ssrcs[i];
+      stream_config.payload_type = payload_types[i];
+      if (i < rtx_ssrcs.size()) {
+        auto& rtx = stream_config.rtx.emplace();
+        rtx.ssrc = rtx_ssrcs[i];
+        rtx.payload_type = payload_types[i] + 1;
+      }
+    }
+  }
   return config;
 }
 
@@ -119,6 +135,7 @@ class RtpVideoSenderTestFixture {
       const std::map<uint32_t, RtpPayloadState>& suspended_payload_states,
       FrameCountObserver* frame_count_observer,
       rtc::scoped_refptr<FrameTransformerInterface> frame_transformer,
+      const std::vector<int>& payload_types,
       const FieldTrialsView* field_trials = nullptr)
       : time_controller_(Timestamp::Millis(1000000)),
         env_(CreateEnvironment(&field_trials_,
@@ -128,7 +145,8 @@ class RtpVideoSenderTestFixture {
         config_(CreateVideoSendStreamConfig(&transport_,
                                             ssrcs,
                                             rtx_ssrcs,
-                                            payload_type)),
+                                            payload_type,
+                                            payload_types)),
         bitrate_config_(GetBitrateConfig()),
         transport_controller_(
             RtpTransportConfig{.env = env_, .bitrate_config = bitrate_config_}),
@@ -149,6 +167,22 @@ class RtpVideoSenderTestFixture {
         std::make_unique<FecControllerDefault>(env_), nullptr, CryptoOptions{},
         frame_transformer);
   }
+  RtpVideoSenderTestFixture(
+      const std::vector<uint32_t>& ssrcs,
+      const std::vector<uint32_t>& rtx_ssrcs,
+      int payload_type,
+      const std::map<uint32_t, RtpPayloadState>& suspended_payload_states,
+      FrameCountObserver* frame_count_observer,
+      rtc::scoped_refptr<FrameTransformerInterface> frame_transformer,
+      const FieldTrialsView* field_trials = nullptr)
+      : RtpVideoSenderTestFixture(ssrcs,
+                                  rtx_ssrcs,
+                                  payload_type,
+                                  suspended_payload_states,
+                                  frame_count_observer,
+                                  frame_transformer,
+                                  /*payload_types=*/{},
+                                  field_trials) {}
 
   RtpVideoSenderTestFixture(
       const std::vector<uint32_t>& ssrcs,
@@ -163,6 +197,7 @@ class RtpVideoSenderTestFixture {
                                   suspended_payload_states,
                                   frame_count_observer,
                                   /*frame_transformer=*/nullptr,
+                                  /*payload_types=*/{},
                                   field_trials) {}
 
   RtpVideoSenderTestFixture(
@@ -177,6 +212,7 @@ class RtpVideoSenderTestFixture {
                                   suspended_payload_states,
                                   /*frame_count_observer=*/nullptr,
                                   /*frame_transformer=*/nullptr,
+                                  /*payload_types=*/{},
                                   field_trials) {}
 
   ~RtpVideoSenderTestFixture() { SetSending(false); }
@@ -913,6 +949,79 @@ TEST(RtpVideoSenderTest,
   EXPECT_EQ(dd_s1.frame_number(), 1002);
 }
 
+TEST(RtpVideoSenderTest, MixedCodecSimulcastPayloadType) {
+  // When multiple payload types are set, verify that the payload type switches
+  // corresponding to the simulcast index.
+  RtpVideoSenderTestFixture test({kSsrc1, kSsrc2}, {kRtxSsrc1, kRtxSsrc2},
+                                 kPayloadType, {}, nullptr, nullptr,
+                                 {kPayloadType, kPayloadType2});
+  test.SetSending(true);
+
+  std::vector<uint16_t> rtp_sequence_numbers;
+  std::vector<RtpPacket> sent_packets;
+  EXPECT_CALL(test.transport(), SendRtp)
+      .Times(3)
+      .WillRepeatedly([&](rtc::ArrayView<const uint8_t> packet,
+                          const PacketOptions& options) -> bool {
+        RtpPacket& rtp_packet = sent_packets.emplace_back();
+        EXPECT_TRUE(rtp_packet.Parse(packet));
+        rtp_sequence_numbers.push_back(rtp_packet.SequenceNumber());
+        return true;
+      });
+
+  const uint8_t kPayload[1] = {'a'};
+  EncodedImage encoded_image;
+  encoded_image.SetEncodedData(
+      EncodedImageBuffer::Create(kPayload, sizeof(kPayload)));
+
+  CodecSpecificInfo codec_specific;
+  codec_specific.codecType = VideoCodecType::kVideoCodecVP8;
+
+  encoded_image.SetSimulcastIndex(0);
+  ASSERT_EQ(test.router()->OnEncodedImage(encoded_image, &codec_specific).error,
+            EncodedImageCallback::Result::OK);
+  ASSERT_EQ(test.router()->OnEncodedImage(encoded_image, &codec_specific).error,
+            EncodedImageCallback::Result::OK);
+  encoded_image.SetSimulcastIndex(1);
+  ASSERT_EQ(test.router()->OnEncodedImage(encoded_image, &codec_specific).error,
+            EncodedImageCallback::Result::OK);
+
+  test.AdvanceTime(TimeDelta::Millis(33));
+  ASSERT_THAT(sent_packets, SizeIs(3));
+  EXPECT_EQ(sent_packets[0].PayloadType(), kPayloadType);
+  EXPECT_EQ(sent_packets[1].PayloadType(), kPayloadType);
+  EXPECT_EQ(sent_packets[2].PayloadType(), kPayloadType2);
+
+  // Verify that NACK is sent to the RTX payload type corresponding to the
+  // payload type.
+  rtcp::Nack nack1, nack2;
+  nack1.SetMediaSsrc(kSsrc1);
+  nack2.SetMediaSsrc(kSsrc2);
+  nack1.SetPacketIds({rtp_sequence_numbers[0], rtp_sequence_numbers[1]});
+  nack2.SetPacketIds({rtp_sequence_numbers[2]});
+  rtc::Buffer nack_buffer1 = nack1.Build();
+  rtc::Buffer nack_buffer2 = nack2.Build();
+
+  std::vector<RtpPacket> sent_rtx_packets;
+  EXPECT_CALL(test.transport(), SendRtp)
+      .Times(3)
+      .WillRepeatedly([&](rtc::ArrayView<const uint8_t> packet,
+                          const PacketOptions& options) {
+        RtpPacket& rtp_packet = sent_rtx_packets.emplace_back();
+        EXPECT_TRUE(rtp_packet.Parse(packet));
+        return true;
+      });
+  test.router()->DeliverRtcp(nack_buffer1.data(), nack_buffer1.size());
+  test.router()->DeliverRtcp(nack_buffer2.data(), nack_buffer2.size());
+
+  test.AdvanceTime(TimeDelta::Millis(33));
+
+  ASSERT_THAT(sent_rtx_packets, SizeIs(3));
+  EXPECT_EQ(sent_rtx_packets[0].PayloadType(), kPayloadType + 1);
+  EXPECT_EQ(sent_rtx_packets[1].PayloadType(), kPayloadType + 1);
+  EXPECT_EQ(sent_rtx_packets[2].PayloadType(), kPayloadType2 + 1);
+}
+
 TEST(RtpVideoSenderTest,
      SupportsDependencyDescriptorForVp8NotProvidedByEncoder) {
   constexpr uint8_t kPayload[1] = {'a'};
diff --git a/media/base/media_engine.cc b/media/base/media_engine.cc
index c551a58cf9..11ccf44c1c 100644
--- a/media/base/media_engine.cc
+++ b/media/base/media_engine.cc
@@ -18,6 +18,7 @@
 
 #include "absl/algorithm/container.h"
 #include "api/video/video_bitrate_allocation.h"
+#include "api/video_codecs/sdp_video_format.h"
 #include "rtc_base/checks.h"
 #include "rtc_base/string_encode.h"
 
@@ -81,7 +82,10 @@ webrtc::RTCError CheckScalabilityModeValues(
     if (rtp_parameters.encodings[i].codec) {
       bool codecFound = false;
       for (const cricket::Codec& codec : send_codecs) {
-        if (codec.MatchesRtpCodec(*rtp_parameters.encodings[i].codec)) {
+        if (webrtc::SdpVideoFormat(codec.name, codec.params)
+                .IsSameCodec(webrtc::SdpVideoFormat(
+                    rtp_parameters.encodings[i].codec->name,
+                    rtp_parameters.encodings[i].codec->parameters))) {
           codecFound = true;
           send_codec = codec;
           break;
@@ -188,12 +192,12 @@ webrtc::RTCError CheckRtpParametersValues(
                            "requested_resolution simultaniously.");
     }
 
-    if (i > 0 && rtp_parameters.encodings[i - 1].codec !=
-                     rtp_parameters.encodings[i].codec) {
-      LOG_AND_RETURN_ERROR(RTCErrorType::UNSUPPORTED_OPERATION,
-                           "Attempted to use different codec values for "
-                           "different encodings.");
-    }
+    // if (i > 0 && rtp_parameters.encodings[i - 1].codec !=
+    //                  rtp_parameters.encodings[i].codec) {
+    //   LOG_AND_RETURN_ERROR(RTCErrorType::UNSUPPORTED_OPERATION,
+    //                        "Attempted to use different codec values for "
+    //                        "different encodings.");
+    // }
   }
 
   return CheckScalabilityModeValues(rtp_parameters, send_codecs, send_codec);
diff --git a/media/engine/simulcast_encoder_adapter.cc b/media/engine/simulcast_encoder_adapter.cc
index 9bdb4d508f..0cf4a626ae 100644
--- a/media/engine/simulcast_encoder_adapter.cc
+++ b/media/engine/simulcast_encoder_adapter.cc
@@ -305,6 +305,10 @@ int SimulcastEncoderAdapter::Release() {
 
   inited_.store(0);
 
+  // サイマルキャストマルチコーデック下で Reconfigure
+  // された時にうまく動かなくなるのでキャッシュは使わない
+  DestroyStoredEncoders();
+
   return WEBRTC_VIDEO_CODEC_OK;
 }
 
@@ -340,7 +344,8 @@ int SimulcastEncoderAdapter::InitEncode(
   std::unique_ptr<EncoderContext> encoder_context = FetchOrCreateEncoderContext(
       /*is_lowest_quality_stream=*/(
           is_legacy_singlecast ||
-          codec_.simulcastStream[lowest_quality_stream_idx].active));
+          codec_.simulcastStream[lowest_quality_stream_idx].active),
+      codec_.simulcastStream[0].format);
   if (encoder_context == nullptr) {
     return WEBRTC_VIDEO_CODEC_MEMORY;
   }
@@ -355,6 +360,19 @@ int SimulcastEncoderAdapter::InitEncode(
   //   and configures each to produce a single stream.
 
   int active_streams_count = CountActiveStreams(*codec_settings);
+  bool is_mixed_codec = std::invoke([this]() -> bool {
+    if (codec_.numberOfSimulcastStreams >= 2) {
+      for (size_t i = 0; i < codec_.numberOfSimulcastStreams - 1; i++) {
+        for (size_t j = i + 1; j < codec_.numberOfSimulcastStreams; j++) {
+          if (!codec_.simulcastStream[i].format.IsSameCodec(
+                  codec_.simulcastStream[j].format)) {
+            return true;
+          }
+        }
+      }
+    }
+    return false;
+  });
   // If we only have a single active layer it is better to create an encoder
   // with only one configured layer than creating it with all-but-one disabled
   // layers because that way we control scaling.
@@ -362,6 +380,7 @@ int SimulcastEncoderAdapter::InitEncode(
   // forces the use of SEA with separate encoders to support per-layer
   // handling of PLIs.
   bool separate_encoders_needed =
+      is_mixed_codec ||
       !encoder_context->encoder().GetEncoderInfo().supports_simulcast ||
       active_streams_count == 1 || per_layer_pli_;
   RTC_LOG(LS_INFO) << "[SEA] InitEncode: total_streams_count: "
@@ -404,10 +423,23 @@ int SimulcastEncoderAdapter::InitEncode(
       continue;
     }
 
-    if (encoder_context == nullptr) {
-      encoder_context = FetchOrCreateEncoderContext(
-          /*is_lowest_quality_stream=*/stream_idx == lowest_quality_stream_idx);
-    }
+    // サイマルキャストマルチコーデック下では事前に作られた encoder_context と
+    // ここで本来生成するべき encoder_context
+    // のクラスが異なってる可能性があるため 毎回生成し直す必要がある。
+    //
+    // 例えば r0.codec==H264 && r0.active==false && r1.codec==VP8 &&
+    // r1.active==true の場合に問題が起きる。
+    //
+    // なので encoder_context == nullptr という条件を削除する。
+    //
+    // if (encoder_context == nullptr) {
+    //   encoder_context = FetchOrCreateEncoderContext(
+    //       /*is_lowest_quality_stream=*/stream_idx ==
+    //       lowest_quality_stream_idx);
+    // }
+    encoder_context = FetchOrCreateEncoderContext(
+        /*is_lowest_quality_stream=*/stream_idx == lowest_quality_stream_idx,
+        codec_.simulcastStream[stream_idx].format);
     if (encoder_context == nullptr) {
       Release();
       return WEBRTC_VIDEO_CODEC_MEMORY;
@@ -723,7 +755,8 @@ void SimulcastEncoderAdapter::DestroyStoredEncoders() {
 
 std::unique_ptr<SimulcastEncoderAdapter::EncoderContext>
 SimulcastEncoderAdapter::FetchOrCreateEncoderContext(
-    bool is_lowest_quality_stream) const {
+    bool is_lowest_quality_stream,
+    const SdpVideoFormat& format) const {
   RTC_DCHECK_RUN_ON(&encoder_queue_);
   bool prefer_temporal_support = fallback_encoder_factory_ != nullptr &&
                                  is_lowest_quality_stream &&
@@ -745,11 +778,11 @@ SimulcastEncoderAdapter::FetchOrCreateEncoderContext(
     cached_encoder_contexts_.erase(encoder_context_iter);
   } else {
     std::unique_ptr<VideoEncoder> primary_encoder =
-        primary_encoder_factory_->Create(env_, video_format_);
+        primary_encoder_factory_->Create(env_, format);
 
     std::unique_ptr<VideoEncoder> fallback_encoder;
     if (fallback_encoder_factory_ != nullptr) {
-      fallback_encoder = fallback_encoder_factory_->Create(env_, video_format_);
+      fallback_encoder = fallback_encoder_factory_->Create(env_, format);
     }
 
     std::unique_ptr<VideoEncoder> encoder;
@@ -768,14 +801,14 @@ SimulcastEncoderAdapter::FetchOrCreateEncoderContext(
             prefer_temporal_support);
       }
     } else if (fallback_encoder != nullptr) {
-      RTC_LOG(LS_WARNING) << "Failed to create primary " << video_format_.name
+      RTC_LOG(LS_WARNING) << "Failed to create primary " << format.name
                           << " encoder. Use fallback encoder.";
       fallback_info = fallback_encoder->GetEncoderInfo();
       primary_info = fallback_info;
       encoder = std::move(fallback_encoder);
     } else {
       RTC_LOG(LS_ERROR) << "Failed to create primary and fallback "
-                        << video_format_.name << " encoders.";
+                        << format.name << " encoders.";
       return nullptr;
     }
 
@@ -798,6 +831,7 @@ webrtc::VideoCodec SimulcastEncoderAdapter::MakeStreamCodec(
   webrtc::VideoCodec codec_params = codec;
   const SimulcastStream& stream_params = codec.simulcastStream[stream_idx];
 
+  codec_params.codecType = PayloadStringToCodecType(stream_params.format.name);
   codec_params.numberOfSimulcastStreams = 0;
   codec_params.width = stream_params.width;
   codec_params.height = stream_params.height;
@@ -915,7 +949,7 @@ VideoEncoder::EncoderInfo SimulcastEncoderAdapter::GetEncoderInfo() const {
     // Create one encoder and query it.
 
     std::unique_ptr<SimulcastEncoderAdapter::EncoderContext> encoder_context =
-        FetchOrCreateEncoderContext(/*is_lowest_quality_stream=*/true);
+        nullptr;
     if (encoder_context == nullptr) {
       return encoder_info;
     }
diff --git a/media/engine/simulcast_encoder_adapter.h b/media/engine/simulcast_encoder_adapter.h
index d7130437e6..dd7b9aaa89 100644
--- a/media/engine/simulcast_encoder_adapter.h
+++ b/media/engine/simulcast_encoder_adapter.h
@@ -153,7 +153,8 @@ class RTC_EXPORT SimulcastEncoderAdapter : public VideoEncoder {
   // `cached_encoder_contexts_`. It's const because it's used from
   // const GetEncoderInfo().
   std::unique_ptr<EncoderContext> FetchOrCreateEncoderContext(
-      bool is_lowest_quality_stream) const;
+      bool is_lowest_quality_stream,
+      const SdpVideoFormat& format) const;
 
   webrtc::VideoCodec MakeStreamCodec(const webrtc::VideoCodec& codec,
                                      int stream_idx,
diff --git a/media/engine/webrtc_video_engine.cc b/media/engine/webrtc_video_engine.cc
index ac7d0f884a..fc63b17a50 100644
--- a/media/engine/webrtc_video_engine.cc
+++ b/media/engine/webrtc_video_engine.cc
@@ -396,15 +396,15 @@ static bool ValidateStreamParams(const StreamParams& sp) {
 }
 
 // Returns true if the given codec is disallowed from doing simulcast.
-bool IsCodecDisabledForSimulcast(bool legacy_scalability_mode,
-                                 webrtc::VideoCodecType codec_type) {
-  if (legacy_scalability_mode && (codec_type == webrtc::kVideoCodecVP9 ||
-                                  codec_type == webrtc::kVideoCodecAV1)) {
-    return true;
-  }
-
-  return false;
-}
+// bool IsCodecDisabledForSimulcast(bool legacy_scalability_mode,
+//                                 webrtc::VideoCodecType codec_type) {
+//  if (legacy_scalability_mode && (codec_type == webrtc::kVideoCodecVP9 ||
+//                                  codec_type == webrtc::kVideoCodecAV1)) {
+//    return true;
+//  }
+//
+//  return false;
+//}
 
 bool IsLayerActive(const webrtc::RtpEncodingParameters& layer) {
   return layer.active &&
@@ -1110,7 +1110,45 @@ bool WebRtcVideoSendChannel::GetChangedSenderParameters(
     } else if (send_codec() != negotiated_codecs.front()) {
       changed_params->send_codec = negotiated_codecs.front();
     }
-    changed_params->negotiated_codecs = std::move(negotiated_codecs);
+    changed_params->negotiated_codecs = negotiated_codecs;
+  }
+
+  // For mixed-codec simulcast
+  std::vector<VideoCodecSettings> send_codecs;
+  if (!send_streams_.empty() && !negotiated_codecs.empty()) {
+    bool needs_update = false;
+    auto rtp_parameters = send_streams_.begin()->second->GetRtpParameters();
+    for (auto& encoding : rtp_parameters.encodings) {
+      if (encoding.codec) {
+        auto matched_codec =
+            absl::c_find_if(negotiated_codecs, [&](auto negotiated_codec) {
+              // return negotiated_codec.codec.MatchesRtpCodec(*encoding.codec);
+              return webrtc::SdpVideoFormat(negotiated_codec.codec.name,
+                                            negotiated_codec.codec.params)
+                  .IsSameCodec(webrtc::SdpVideoFormat(
+                      encoding.codec->name, encoding.codec->parameters));
+            });
+        if (matched_codec != negotiated_codecs.end()) {
+          send_codecs.push_back(*matched_codec);
+        } else {
+          // The requested codec has been negotiated away, we clear it from the
+          // parameters.
+          encoding.codec.reset();
+          needs_update = true;
+          send_codecs.push_back(negotiated_codecs.front());
+        }
+      } else {
+        send_codecs.push_back(negotiated_codecs.front());
+      }
+    }
+
+    if (needs_update) {
+      send_streams_.begin()->second->SetRtpParameters(rtp_parameters, nullptr);
+    }
+  }
+
+  if (send_codecs_ != send_codecs) {
+    changed_params->send_codecs = send_codecs;
   }
 
   // Handle RTP header extensions.
@@ -1244,6 +1282,9 @@ bool WebRtcVideoSendChannel::ApplyChangedParams(
   if (changed_params.send_codec)
     send_codec() = changed_params.send_codec;
 
+  if (changed_params.send_codecs)
+    send_codecs_ = *changed_params.send_codecs;
+
   if (changed_params.extmap_allow_mixed) {
     SetExtmapAllowMixed(*changed_params.extmap_allow_mixed);
   }
@@ -1375,28 +1416,52 @@ webrtc::RTCError WebRtcVideoSendChannel::SetRtpSendParameters(
         break;
     }
 
-    // Since we validate that all layers have the same value, we can just check
-    // the first layer.
-    // TODO(orphis): Support mixed-codec simulcast
-    if (parameters.encodings[0].codec && send_codec_ &&
-        !send_codec_->codec.MatchesRtpCodec(*parameters.encodings[0].codec)) {
-      RTC_LOG(LS_VERBOSE) << "Trying to change codec to "
-                          << parameters.encodings[0].codec->name;
-      auto matched_codec =
-          absl::c_find_if(negotiated_codecs_, [&](auto negotiated_codec) {
-            return negotiated_codec.codec.MatchesRtpCodec(
-                *parameters.encodings[0].codec);
-          });
-      if (matched_codec == negotiated_codecs_.end()) {
-        return webrtc::InvokeSetParametersCallback(
-            callback, webrtc::RTCError(
-                          webrtc::RTCErrorType::INVALID_MODIFICATION,
-                          "Attempted to use an unsupported codec for layer 0"));
+    if (send_codec_) {
+      std::vector<VideoCodecSettings> send_codecs;
+
+      for (size_t i = 0; i < parameters.encodings.size(); i++) {
+        const auto& codec = parameters.encodings[i].codec;
+        std::optional<VideoCodecSettings> found_codec;
+        if (!codec) {
+          found_codec = *send_codec_;
+        } else if (i >= send_codecs_.size()) {
+        } else {
+          const auto& send_codec = send_codecs_[i];
+          if (!webrtc::SdpVideoFormat(codec->name, codec->parameters)
+                   .IsSameCodec(webrtc::SdpVideoFormat(
+                       send_codec.codec.name, send_codec.codec.params))) {
+            found_codec = send_codec;
+          }
+        }
+        if (!found_codec) {
+          RTC_DCHECK(codec);
+          auto matched_codec =
+              absl::c_find_if(negotiated_codecs_, [&](auto negotiated_codec) {
+                return webrtc::SdpVideoFormat(codec->name, codec->parameters)
+                    .IsSameCodec(
+                        webrtc::SdpVideoFormat(negotiated_codec.codec.name,
+                                               negotiated_codec.codec.params));
+              });
+          if (matched_codec == negotiated_codecs_.end()) {
+            return webrtc::InvokeSetParametersCallback(
+                callback,
+                webrtc::RTCError(
+                    webrtc::RTCErrorType::INVALID_MODIFICATION,
+                    "Attempted to use an unsupported codec for layer " +
+                        std::to_string(i)));
+          }
+          found_codec = *matched_codec;
+        }
+        RTC_DCHECK(found_codec);
+        send_codecs.push_back(*found_codec);
       }
 
-      ChangedSenderParameters params;
-      params.send_codec = *matched_codec;
-      ApplyChangedParams(params);
+      if (send_codecs_ != send_codecs) {
+        ChangedSenderParameters params;
+        params.send_codec = send_codec_;
+        params.send_codecs = send_codecs;
+        ApplyChangedParams(params);
+      }
     }
 
     SetPreferredDscp(new_dscp);
@@ -1498,7 +1563,7 @@ bool WebRtcVideoSendChannel::AddSendStream(const StreamParams& sp) {
   WebRtcVideoSendStream* stream = new WebRtcVideoSendStream(
       call_, sp, std::move(config), default_send_options_,
       video_config_.enable_cpu_adaptation, bitrate_config_.max_bitrate_bps,
-      send_codec(), send_rtp_extensions_, send_params_);
+      send_codec(), send_codecs_, send_rtp_extensions_, send_params_);
 
   uint32_t ssrc = sp.first_ssrc();
   RTC_DCHECK(ssrc != 0);
@@ -1703,7 +1768,8 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::VideoSendStreamParameters::
         webrtc::VideoSendStream::Config config,
         const VideoOptions& options,
         int max_bitrate_bps,
-        const absl::optional<VideoCodecSettings>& codec_settings)
+        const absl::optional<VideoCodecSettings>& codec_settings,
+        const std::vector<VideoCodecSettings>& codec_settings_list)
     : config(std::move(config)),
       options(options),
       max_bitrate_bps(max_bitrate_bps),
@@ -1718,6 +1784,7 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::WebRtcVideoSendStream(
     bool enable_cpu_overuse_detection,
     int max_bitrate_bps,
     const absl::optional<VideoCodecSettings>& codec_settings,
+    const std::vector<VideoCodecSettings>& codec_settings_list,
     const absl::optional<std::vector<webrtc::RtpExtension>>& rtp_extensions,
     // TODO(deadbeef): Don't duplicate information between send_params,
     // rtp_extensions, options, etc.
@@ -1729,7 +1796,11 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::WebRtcVideoSendStream(
       enable_cpu_overuse_detection_(enable_cpu_overuse_detection),
       source_(nullptr),
       stream_(nullptr),
-      parameters_(std::move(config), options, max_bitrate_bps, codec_settings),
+      parameters_(std::move(config),
+                  options,
+                  max_bitrate_bps,
+                  codec_settings,
+                  codec_settings_list),
       rtp_parameters_(CreateRtpParametersWithEncodings(sp)),
       sending_(false),
       disable_automatic_resize_(
@@ -1788,7 +1859,7 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::WebRtcVideoSendStream(
   rtp_parameters_.rtcp.reduced_size = send_params.rtcp.reduced_size;
 
   if (codec_settings) {
-    SetCodec(*codec_settings);
+    SetCodec(*codec_settings, codec_settings_list);
   }
 }
 
@@ -1814,7 +1885,7 @@ bool WebRtcVideoSendChannel::WebRtcVideoSendStream::SetVideoSend(
       // If screen content settings change, we may need to recreate the codec
       // instance so that the correct type is used.
 
-      SetCodec(*parameters_.codec_settings);
+      SetCodec(*parameters_.codec_settings, parameters_.codec_settings_list);
       // Mark screenshare parameter as being updated, then test for any other
       // changes that may require codec reconfiguration.
       old_options.is_screencast = options->is_screencast;
@@ -1889,7 +1960,8 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::GetSsrcs() const {
 }
 
 void WebRtcVideoSendChannel::WebRtcVideoSendStream::SetCodec(
-    const VideoCodecSettings& codec_settings) {
+    const VideoCodecSettings& codec_settings,
+    const std::vector<VideoCodecSettings>& codec_settings_list) {
   RTC_DCHECK_RUN_ON(&thread_checker_);
   FallbackToDefaultScalabilityModeIfNotSupported(
       codec_settings.codec, parameters_.config, rtp_parameters_.encodings);
@@ -1926,6 +1998,32 @@ void WebRtcVideoSendChannel::WebRtcVideoSendStream::SetCodec(
 
   parameters_.codec_settings = codec_settings;
 
+  // Settings for mixed-codec simulcast
+  if (!codec_settings_list.empty()) {
+    RTC_DCHECK_EQ(parameters_.config.rtp.ssrcs.size(),
+                  codec_settings_list.size());
+    parameters_.config.rtp.stream_configs.resize(
+        parameters_.config.rtp.ssrcs.size());
+    for (size_t i = 0; i < codec_settings_list.size(); i++) {
+      auto& stream_config = parameters_.config.rtp.stream_configs[i];
+      const auto& cs = codec_settings_list[i];
+      stream_config.ssrc = parameters_.config.rtp.ssrcs[i];
+      if (i < parameters_.config.rtp.rids.size()) {
+        stream_config.rid = parameters_.config.rtp.rids[i];
+      }
+      stream_config.payload_name = cs.codec.name;
+      stream_config.payload_type = cs.codec.id;
+      stream_config.raw_payload =
+          cs.codec.packetization == kPacketizationParamRaw;
+      if (i < parameters_.config.rtp.rtx.ssrcs.size()) {
+        auto& rtx = stream_config.rtx.emplace();
+        rtx.ssrc = parameters_.config.rtp.rtx.ssrcs[i];
+        rtx.payload_type = cs.rtx_payload_type;
+      }
+    }
+  }
+  parameters_.codec_settings_list = codec_settings_list;
+
   // TODO(bugs.webrtc.org/8830): Avoid recreation, it should be enough to call
   // ReconfigureEncoder.
   RTC_LOG(LS_INFO) << "RecreateWebRtcStream (send) because of SetCodec.";
@@ -1967,10 +2065,11 @@ void WebRtcVideoSendChannel::WebRtcVideoSendStream::SetSenderParameters(
 
   // Set codecs and options.
   if (params.send_codec) {
-    SetCodec(*params.send_codec);
+    SetCodec(*params.send_codec,
+             params.send_codecs.value_or(parameters_.codec_settings_list));
     recreate_stream = false;  // SetCodec has already recreated the stream.
   } else if (params.conference_mode && parameters_.codec_settings) {
-    SetCodec(*parameters_.codec_settings);
+    SetCodec(*parameters_.codec_settings, parameters_.codec_settings_list);
     recreate_stream = false;  // SetCodec has already recreated the stream.
   }
   if (recreate_stream) {
@@ -2010,7 +2109,9 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::SetRtpParameters(
         (new_parameters.encodings[i].requested_resolution !=
          rtp_parameters_.encodings[i].requested_resolution) ||
         (new_parameters.encodings[i].scalability_mode !=
-         rtp_parameters_.encodings[i].scalability_mode)) {
+         rtp_parameters_.encodings[i].scalability_mode) ||
+        (new_parameters.encodings[i].codec !=
+         rtp_parameters_.encodings[i].codec)) {
       new_param = true;
       break;
     }
@@ -2141,24 +2242,24 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::CreateVideoEncoderConfig(
   // number of negotiated ssrcs but this may be capped below depending on the
   // `legacy_scalability_mode` and codec used.
   encoder_config.number_of_streams = parameters_.config.rtp.ssrcs.size();
-  bool legacy_scalability_mode = true;
-  for (const webrtc::RtpEncodingParameters& encoding :
-       rtp_parameters_.encodings) {
-    if (encoding.scalability_mode.has_value() &&
-        encoding.scale_resolution_down_by.has_value()) {
-      legacy_scalability_mode = false;
-      break;
-    }
-  }
-  // Maybe limit the number of simulcast layers depending on
-  // `legacy_scalability_mode`, codec types (VP9/AV1). This path only exists
-  // for backwards compatibility and will one day be deleted. If you want SVC,
-  // please specify with the `scalability_mode` API instead amd disabling all
-  // but one encoding.
-  if (IsCodecDisabledForSimulcast(legacy_scalability_mode,
-                                  encoder_config.codec_type)) {
-    encoder_config.number_of_streams = 1;
-  }
+  // bool legacy_scalability_mode = true;
+  // for (const webrtc::RtpEncodingParameters& encoding :
+  //      rtp_parameters_.encodings) {
+  //   if (encoding.scalability_mode.has_value() &&
+  //       encoding.scale_resolution_down_by.has_value()) {
+  //     legacy_scalability_mode = false;
+  //     break;
+  //   }
+  // }
+  //  Maybe limit the number of simulcast layers depending on
+  //  `legacy_scalability_mode`, codec types (VP9/AV1). This path only exists
+  //  for backwards compatibility and will one day be deleted. If you want SVC,
+  //  please specify with the `scalability_mode` API instead amd disabling all
+  //  but one encoding.
+  //  if (IsCodecDisabledForSimulcast(legacy_scalability_mode,
+  //                                 encoder_config.codec_type)) {
+  //   encoder_config.number_of_streams = 1;
+  // }
 
   // parameters_.max_bitrate comes from the max bitrate set at the SDP
   // (m-section) level with the attribute "b=AS." Note that stream max bitrate
@@ -2226,6 +2327,11 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::CreateVideoEncoderConfig(
       encoder_config.simulcast_layers[i].num_temporal_layers =
           *rtp_parameters_.encodings[i].num_temporal_layers;
     }
+    if (rtp_parameters_.encodings[i].codec) {
+      encoder_config.simulcast_layers[i].video_format = webrtc::SdpVideoFormat(
+          rtp_parameters_.encodings[i].codec->name,
+          rtp_parameters_.encodings[i].codec->parameters);
+    }
     encoder_config.simulcast_layers[i].requested_resolution =
         rtp_parameters_.encodings[i].requested_resolution;
   }
diff --git a/media/engine/webrtc_video_engine.h b/media/engine/webrtc_video_engine.h
index 14df03a1cc..c68b71b94f 100644
--- a/media/engine/webrtc_video_engine.h
+++ b/media/engine/webrtc_video_engine.h
@@ -292,6 +292,7 @@ class WebRtcVideoSendChannel : public MediaChannelUtil,
     // These optionals are unset if not changed.
     absl::optional<VideoCodecSettings> send_codec;
     absl::optional<std::vector<VideoCodecSettings>> negotiated_codecs;
+    std::optional<std::vector<VideoCodecSettings>> send_codecs;
     absl::optional<std::vector<webrtc::RtpExtension>> rtp_header_extensions;
     absl::optional<std::string> mid;
     absl::optional<bool> extmap_allow_mixed;
@@ -327,6 +328,7 @@ class WebRtcVideoSendChannel : public MediaChannelUtil,
         bool enable_cpu_overuse_detection,
         int max_bitrate_bps,
         const absl::optional<VideoCodecSettings>& codec_settings,
+        const std::vector<VideoCodecSettings>& codec_settings_list,
         const absl::optional<std::vector<webrtc::RtpExtension>>& rtp_extensions,
         const VideoSenderParameters& send_params);
     ~WebRtcVideoSendStream();
@@ -374,12 +376,14 @@ class WebRtcVideoSendChannel : public MediaChannelUtil,
           webrtc::VideoSendStream::Config config,
           const VideoOptions& options,
           int max_bitrate_bps,
-          const absl::optional<VideoCodecSettings>& codec_settings);
+          const absl::optional<VideoCodecSettings>& codec_settings,
+          const std::vector<VideoCodecSettings>& codec_settings_list);
       webrtc::VideoSendStream::Config config;
       VideoOptions options;
       int max_bitrate_bps;
       bool conference_mode;
       absl::optional<VideoCodecSettings> codec_settings;
+      std::vector<VideoCodecSettings> codec_settings_list;
       // Sent resolutions + bitrates etc. by the underlying VideoSendStream,
       // typically changes when setting a new resolution or reconfiguring
       // bitrates.
@@ -388,7 +392,8 @@ class WebRtcVideoSendChannel : public MediaChannelUtil,
 
     rtc::scoped_refptr<webrtc::VideoEncoderConfig::EncoderSpecificSettings>
     ConfigureVideoEncoderSettings(const Codec& codec);
-    void SetCodec(const VideoCodecSettings& codec);
+    void SetCodec(const VideoCodecSettings& codec,
+                  const std::vector<VideoCodecSettings>& codec_settings_list);
     void RecreateWebRtcStream();
     webrtc::VideoEncoderConfig CreateVideoEncoderConfig(
         const Codec& codec) const;
@@ -500,6 +505,7 @@ class WebRtcVideoSendChannel : public MediaChannelUtil,
       RTC_GUARDED_BY(thread_checker_);
   std::vector<VideoCodecSettings> negotiated_codecs_
       RTC_GUARDED_BY(thread_checker_);
+  std::vector<VideoCodecSettings> send_codecs_ RTC_GUARDED_BY(thread_checker_);
 
   std::vector<webrtc::RtpExtension> send_rtp_extensions_
       RTC_GUARDED_BY(thread_checker_);
diff --git a/media/engine/webrtc_video_engine_unittest.cc b/media/engine/webrtc_video_engine_unittest.cc
index 2046f8c1c8..52195af2e8 100644
--- a/media/engine/webrtc_video_engine_unittest.cc
+++ b/media/engine/webrtc_video_engine_unittest.cc
@@ -8793,6 +8793,54 @@ TEST_F(WebRtcVideoChannelTest,
   EXPECT_TRUE(send_channel_->SetVideoSend(last_ssrc_, nullptr, nullptr));
 }
 
+TEST_F(WebRtcVideoChannelTest, SetMixedCodecSimulcastStreamConfig) {
+  webrtc::test::ScopedKeyValueConfig field_trials(
+      field_trials_, "WebRTC-MixedCodecSimulcast/Enabled/");
+
+  StreamParams sp = CreateSimStreamParams("cname", {123, 456, 789});
+
+  std::vector<cricket::RidDescription> rid_descriptions;
+  rid_descriptions.emplace_back("f", cricket::RidDirection::kSend);
+  rid_descriptions.emplace_back("h", cricket::RidDirection::kSend);
+  rid_descriptions.emplace_back("q", cricket::RidDirection::kSend);
+  sp.set_rids(rid_descriptions);
+
+  ASSERT_TRUE(send_channel_->AddSendStream(sp));
+
+  webrtc::RtpParameters rtp_parameters =
+      send_channel_->GetRtpSendParameters(last_ssrc_);
+  EXPECT_EQ(3UL, rtp_parameters.encodings.size());
+  cricket::Codec vp8 = GetEngineCodec("VP8");
+  cricket::Codec vp9 = GetEngineCodec("VP9");
+  rtp_parameters.encodings[0].codec = vp8.ToCodecParameters();
+  rtp_parameters.encodings[1].codec = vp8.ToCodecParameters();
+  rtp_parameters.encodings[2].codec = vp9.ToCodecParameters();
+  EXPECT_TRUE(
+      send_channel_->SetRtpSendParameters(last_ssrc_, rtp_parameters).ok());
+
+  cricket::VideoSenderParameters parameters;
+  parameters.codecs.push_back(vp8);
+  parameters.codecs.push_back(vp9);
+  EXPECT_TRUE(send_channel_->SetSenderParameters(parameters));
+
+  const auto& streams = fake_call_->GetVideoSendStreams();
+  ASSERT_EQ(1u, streams.size());
+  auto stream = streams[0];
+  ASSERT_NE(stream, nullptr);
+  const auto& config = stream->GetConfig();
+  // RtpStreamConfig should have the correct codec name and payload type.
+  ASSERT_THAT(config.rtp.stream_configs, SizeIs(3));
+  EXPECT_EQ(config.rtp.stream_configs[0].rid, "f");
+  EXPECT_EQ(config.rtp.stream_configs[1].rid, "h");
+  EXPECT_EQ(config.rtp.stream_configs[2].rid, "q");
+  EXPECT_EQ(config.rtp.stream_configs[0].payload_name, vp8.name);
+  EXPECT_EQ(config.rtp.stream_configs[1].payload_name, vp8.name);
+  EXPECT_EQ(config.rtp.stream_configs[2].payload_name, vp9.name);
+  EXPECT_EQ(config.rtp.stream_configs[0].payload_type, vp8.id);
+  EXPECT_EQ(config.rtp.stream_configs[1].payload_type, vp8.id);
+  EXPECT_EQ(config.rtp.stream_configs[2].payload_type, vp9.id);
+}
+
 // Test that min and max bitrate values set via RtpParameters are correctly
 // propagated to the underlying encoder for a single stream.
 TEST_F(WebRtcVideoChannelTest, MinAndMaxBitratePropagatedToEncoder) {
diff --git a/modules/video_coding/utility/simulcast_rate_allocator.cc b/modules/video_coding/utility/simulcast_rate_allocator.cc
index 89522e6ca3..62c7d1d7ff 100644
--- a/modules/video_coding/utility/simulcast_rate_allocator.cc
+++ b/modules/video_coding/utility/simulcast_rate_allocator.cc
@@ -171,8 +171,28 @@ void SimulcastRateAllocator::DistributeAllocationToSimulcastLayers(
       min_bitrate = std::min(hysteresis_factor * min_bitrate, target_bitrate);
     }
     if (left_in_stable_allocation < min_bitrate) {
-      allocated_bitrates->set_bw_limited(true);
-      break;
+      bool is_mixed_codec = std::invoke([this]() {
+        if (codec_.numberOfSimulcastStreams >= 2) {
+          for (size_t i = 0; i < codec_.numberOfSimulcastStreams - 1; i++) {
+            for (size_t j = i + 1; j < codec_.numberOfSimulcastStreams; j++) {
+              if (!codec_.simulcastStream[i].format.IsSameCodec(
+                      codec_.simulcastStream[j].format)) {
+                return true;
+              }
+            }
+          }
+        }
+        return false;
+      });
+
+      if (is_mixed_codec) {
+        // トータルのビットレートが低すぎると、高いレイヤーにビットレートを割り当てることができなくなるのだけど、
+        // サイマルキャストマルチコーデックでそれをされると困るので、トータルのビットレートを超えても無理やり出力する
+        left_in_stable_allocation = left_in_total_allocation = min_bitrate;
+      } else {
+        allocated_bitrates->set_bw_limited(true);
+        break;
+      }
     }
 
     // We are allocating to this layer so it is the current active allocation.
@@ -332,10 +352,11 @@ const VideoCodec& webrtc::SimulcastRateAllocator::GetCodec() const {
 
 int SimulcastRateAllocator::NumTemporalStreams(size_t simulcast_id) const {
   return std::max<uint8_t>(
-      1,
-      codec_.codecType == kVideoCodecVP8 && codec_.numberOfSimulcastStreams == 0
-          ? codec_.VP8().numberOfTemporalLayers
-          : codec_.simulcastStream[simulcast_id].numberOfTemporalLayers);
+      1, codec_.simulcastStream[simulcast_id].format.IsSameCodec(
+             webrtc::SdpVideoFormat::VP8()) &&
+                 codec_.numberOfSimulcastStreams == 0
+             ? codec_.VP8().numberOfTemporalLayers
+             : codec_.simulcastStream[simulcast_id].numberOfTemporalLayers);
 }
 
 void SimulcastRateAllocator::SetLegacyConferenceMode(bool enabled) {
diff --git a/modules/video_coding/video_codec_initializer.cc b/modules/video_coding/video_codec_initializer.cc
index 2c6a255355..0279ffcf1f 100644
--- a/modules/video_coding/video_codec_initializer.cc
+++ b/modules/video_coding/video_codec_initializer.cc
@@ -100,6 +100,7 @@ VideoCodec VideoCodecInitializer::SetupCodec(
     sim_stream->targetBitrate = streams[i].target_bitrate_bps / 1000;
     sim_stream->maxBitrate = streams[i].max_bitrate_bps / 1000;
     sim_stream->qpMax = streams[i].max_qp;
+    sim_stream->format = config.GetSimulcastVideoFormat(i);
 
     int num_temporal_layers =
         streams[i].scalability_mode.has_value()
diff --git a/pc/rtp_sender.h b/pc/rtp_sender.h
index bd2cf9df16..48d60dd257 100644
--- a/pc/rtp_sender.h
+++ b/pc/rtp_sender.h
@@ -103,6 +103,7 @@ class RtpSenderInternal : public RtpSenderInterface {
   // Used by the owning transceiver to inform the sender on the currently
   // selected codecs.
   virtual void SetSendCodecs(std::vector<cricket::Codec> send_codecs) = 0;
+  virtual std::vector<cricket::Codec> GetSendCodecs() const = 0;
 };
 
 // Shared implementation for RtpSenderInternal interface.
@@ -223,6 +224,9 @@ class RtpSenderBase : public RtpSenderInternal, public ObserverInterface {
   void SetSendCodecs(std::vector<cricket::Codec> send_codecs) override {
     send_codecs_ = send_codecs;
   }
+  std::vector<cricket::Codec> GetSendCodecs() const override {
+    return send_codecs_;
+  }
 
  protected:
   // If `set_streams_observer` is not null, it is invoked when SetStreams()
diff --git a/pc/sdp_offer_answer.cc b/pc/sdp_offer_answer.cc
index 199d7ecfbe..37f6f5596c 100644
--- a/pc/sdp_offer_answer.cc
+++ b/pc/sdp_offer_answer.cc
@@ -751,7 +751,8 @@ void AddPlanBRtpSenderOptions(
 cricket::MediaDescriptionOptions GetMediaDescriptionOptionsForTransceiver(
     RtpTransceiver* transceiver,
     const std::string& mid,
-    bool is_create_offer) {
+    bool is_create_offer,
+    const std::vector<RidDescription>& receive_rids = {}) {
   // NOTE: a stopping transceiver should be treated as a stopped one in
   // createOffer as specified in
   // https://w3c.github.io/webrtc-pc/#dom-rtcpeerconnection-createoffer.
@@ -793,7 +794,16 @@ cricket::MediaDescriptionOptions GetMediaDescriptionOptionsForTransceiver(
     if (encoding.rid.empty()) {
       continue;
     }
-    send_rids.push_back(RidDescription(encoding.rid, RidDirection::kSend));
+    auto send_rid = RidDescription(encoding.rid, RidDirection::kSend);
+    if (!is_create_offer && encoding.codec) {
+      for (const auto& receive_rid : receive_rids) {
+        if (receive_rid.rid == encoding.rid) {
+          send_rid.payload_types = receive_rid.payload_types;
+          break;
+        }
+      }
+    }
+    send_rids.push_back(send_rid);
     send_layers.AddLayer(SimulcastLayer(encoding.rid, !encoding.active));
   }
 
@@ -4499,7 +4509,8 @@ void SdpOfferAnswerHandler::GetOptionsForUnifiedPlanAnswer(
         session_options->media_description_options.push_back(
             GetMediaDescriptionOptionsForTransceiver(
                 transceiver->internal(), content.name,
-                /*is_create_offer=*/false));
+                /*is_create_offer=*/false,
+                content.media_description()->receive_rids()));
       } else {
         // This should only happen with rejected transceivers.
         RTC_DCHECK(content.rejected);
diff --git a/pc/sdp_offer_answer_unittest.cc b/pc/sdp_offer_answer_unittest.cc
index 1ee5215947..029878ff77 100644
--- a/pc/sdp_offer_answer_unittest.cc
+++ b/pc/sdp_offer_answer_unittest.cc
@@ -41,7 +41,9 @@
 #include "rtc_base/rtc_certificate_generator.h"
 #include "rtc_base/thread.h"
 #include "system_wrappers/include/metrics.h"
+#include "test/gmock.h"
 #include "test/gtest.h"
+#include "test/scoped_key_value_config.h"
 
 // This file contains unit tests that relate to the behavior of the
 // SdpOfferAnswer module.
@@ -87,7 +89,9 @@ class SdpOfferAnswerTest : public ::testing::Test {
                                             OpenH264DecoderTemplateAdapter,
                                             Dav1dDecoderTemplateAdapter>>(),
             nullptr /* audio_mixer */,
-            nullptr /* audio_processing */)) {
+            nullptr /* audio_processing */,
+            nullptr /* audio_frame_processor */,
+            std::make_unique<test::ScopedKeyValueConfig>(field_trials_, ""))) {
     metrics::Reset();
   }
 
@@ -108,7 +112,21 @@ class SdpOfferAnswerTest : public ::testing::Test {
         pc_factory_, result.MoveValue(), std::move(observer));
   }
 
+  std::optional<RtpCodecCapability> FindFirstSendCodecWithName(
+      cricket::MediaType media_type,
+      const std::string& name) const {
+    std::vector<RtpCodecCapability> codecs =
+        pc_factory_->GetRtpSenderCapabilities(media_type).codecs;
+    for (const auto& codec : codecs) {
+      if (absl::EqualsIgnoreCase(codec.name, name)) {
+        return codec;
+      }
+    }
+    return std::nullopt;
+  }
+
  protected:
+  test::ScopedKeyValueConfig field_trials_;
   std::unique_ptr<rtc::Thread> signaling_thread_;
   rtc::scoped_refptr<PeerConnectionFactoryInterface> pc_factory_;
 
@@ -610,6 +628,101 @@ TEST_F(SdpOfferAnswerTest, SimulcastAnswerWithNoRidsIsRejected) {
   EXPECT_TRUE(pc->SetRemoteDescription(std::move(rejected_answer)));
 }
 
+TEST_F(SdpOfferAnswerTest, SimulcastOfferWithMixedCodec) {
+  test::ScopedKeyValueConfig field_trials(
+      field_trials_, "WebRTC-MixedCodecSimulcast/Enabled/");
+
+  auto pc = CreatePeerConnection();
+
+  std::optional<RtpCodecCapability> vp8_codec = FindFirstSendCodecWithName(
+      cricket::MEDIA_TYPE_VIDEO, cricket::kVp8CodecName);
+  ASSERT_TRUE(vp8_codec);
+  std::optional<RtpCodecCapability> vp9_codec = FindFirstSendCodecWithName(
+      cricket::MEDIA_TYPE_VIDEO, cricket::kVp9CodecName);
+  ASSERT_TRUE(vp9_codec);
+
+  RtpTransceiverInit init;
+  RtpEncodingParameters rid1;
+  rid1.rid = "1";
+  rid1.codec = *vp8_codec;
+  init.send_encodings.push_back(rid1);
+  RtpEncodingParameters rid2;
+  rid2.rid = "2";
+  rid2.codec = *vp9_codec;
+  init.send_encodings.push_back(rid2);
+
+  auto transceiver = pc->AddTransceiver(cricket::MEDIA_TYPE_VIDEO, init);
+  auto offer = pc->CreateOffer();
+  auto& offer_contents = offer->description()->contents();
+  auto send_codecs = offer_contents[0].media_description()->codecs();
+  // Verify that the serialized SDP includes pt=.
+  std::string sdp;
+  offer->ToString(&sdp);
+  EXPECT_THAT(sdp, testing::HasSubstr("a=rid:1 send pt=" +
+                                      std::to_string(send_codecs[0].id)));
+  EXPECT_THAT(sdp, testing::HasSubstr("a=rid:2 send pt=" +
+                                      std::to_string(send_codecs[1].id)));
+  // Verify that SDP containing pt= can be parsed correctly.
+  auto offer2 = CreateSessionDescription(SdpType::kOffer, sdp);
+  auto& offer_contents2 = offer2->description()->contents();
+  auto send_rids2 = offer_contents2[0].media_description()->streams()[0].rids();
+  auto send_codecs2 = offer_contents2[0].media_description()->codecs();
+  EXPECT_EQ(send_rids2[0].payload_types.size(), 1u);
+  EXPECT_EQ(send_rids2[0].payload_types[0], send_codecs2[0].id);
+  EXPECT_EQ(send_rids2[1].payload_types.size(), 1u);
+  EXPECT_EQ(send_rids2[1].payload_types[0], send_codecs2[1].id);
+}
+
+TEST_F(SdpOfferAnswerTest, SimulcastAnswerWithPayloadType) {
+  test::ScopedKeyValueConfig field_trials(
+      field_trials_, "WebRTC-MixedCodecSimulcast/Enabled/");
+
+  auto pc = CreatePeerConnection();
+
+  // A SDP offer with recv simulcast with payload type
+  std::string sdp =
+      "v=0\r\n"
+      "o=- 4131505339648218884 3 IN IP4 127.0.0.1\r\n"
+      "s=-\r\n"
+      "t=0 0\r\n"
+      "a=ice-ufrag:zGWFZ+fVXDeN6UoI/136\r\n"
+      "a=ice-pwd:9AUNgUqRNI5LSIrC1qFD2iTR\r\n"
+      "a=fingerprint:sha-256 "
+      "AD:52:52:E0:B1:37:34:21:0E:15:8E:B7:56:56:7B:B4:39:0E:6D:1C:F5:84:A7:EE:"
+      "B5:27:3E:30:B1:7D:69:42\r\n"
+      "a=setup:passive\r\n"
+      "m=video 9 UDP/TLS/RTP/SAVPF 96 97\r\n"
+      "c=IN IP4 0.0.0.0\r\n"
+      "a=rtcp:9 IN IP4 0.0.0.0\r\n"
+      "a=mid:0\r\n"
+      "a=extmap:9 urn:ietf:params:rtp-hdrext:sdes:mid\r\n"
+      "a=extmap:10 urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id\r\n"
+      "a=recvonly\r\n"
+      "a=rtcp-mux\r\n"
+      "a=rtcp-rsize\r\n"
+      "a=rtpmap:96 VP8/90000\r\n"
+      "a=rtpmap:97 VP9/90000\r\n"
+      "a=rid:1 recv pt=96\r\n"
+      "a=rid:2 recv pt=97\r\n"
+      "a=simulcast:recv 1;2\r\n";
+
+  auto offer = CreateSessionDescription(SdpType::kOffer, sdp);
+  EXPECT_TRUE(pc->SetRemoteDescription(std::move(offer)));
+
+  auto transceiver = pc->pc()->GetTransceivers()[0];
+  EXPECT_TRUE(
+      transceiver->SetDirectionWithError(RtpTransceiverDirection::kSendOnly)
+          .ok());
+
+  // Check the generated SDP.
+  auto answer = pc->CreateAnswer();
+  answer->ToString(&sdp);
+  EXPECT_THAT(sdp, testing::HasSubstr("a=rid:1 send pt=96\r\n"));
+  EXPECT_THAT(sdp, testing::HasSubstr("a=rid:2 send pt=97\r\n"));
+
+  EXPECT_TRUE(pc->SetLocalDescription(std::move(answer)));
+}
+
 TEST_F(SdpOfferAnswerTest, ExpectAllSsrcsSpecifiedInSsrcGroupFid) {
   auto pc = CreatePeerConnection();
   std::string sdp =
diff --git a/pc/test/mock_rtp_sender_internal.h b/pc/test/mock_rtp_sender_internal.h
index 925e9ec910..a8ef817ed5 100644
--- a/pc/test/mock_rtp_sender_internal.h
+++ b/pc/test/mock_rtp_sender_internal.h
@@ -69,6 +69,10 @@ class MockRtpSenderInternal : public RtpSenderInternal {
               (const RtpParameters&),
               (override));
   MOCK_METHOD(void, SetSendCodecs, (std::vector<cricket::Codec>), (override));
+  MOCK_METHOD(std::vector<cricket::Codec>,
+              GetSendCodecs,
+              (),
+              (const, override));
   MOCK_METHOD(rtc::scoped_refptr<DtmfSenderInterface>,
               GetDtmfSender,
               (),
diff --git a/video/config/encoder_stream_factory.cc b/video/config/encoder_stream_factory.cc
index 05b897d979..f2417e6687 100644
--- a/video/config/encoder_stream_factory.cc
+++ b/video/config/encoder_stream_factory.cc
@@ -510,7 +510,24 @@ std::vector<webrtc::Resolution> EncoderStreamFactory::GetStreamResolutions(
       resolutions.push_back({.width = width, .height = height});
     }
   } else {
-    size_t min_num_layers = FindRequiredActiveLayers(encoder_config);
+    bool is_mixed_codec = std::invoke([&]() {
+      if (encoder_config.simulcast_layers.size() >= 2) {
+        for (size_t i = 0; i < encoder_config.simulcast_layers.size() - 1;
+             i++) {
+          for (size_t j = i + 1; j < encoder_config.simulcast_layers.size();
+               j++) {
+            if (!encoder_config.GetSimulcastVideoFormat(i).IsSameCodec(
+                    encoder_config.GetSimulcastVideoFormat(j))) {
+              return true;
+            }
+          }
+        }
+      }
+      return false;
+    });
+    size_t min_num_layers = is_mixed_codec
+                                ? encoder_config.number_of_streams
+                                : FindRequiredActiveLayers(encoder_config);
     size_t max_num_layers = LimitSimulcastLayerCount(
         min_num_layers, encoder_config.number_of_streams, width, height, trials,
         encoder_config.codec_type);
diff --git a/video/config/video_encoder_config.cc b/video/config/video_encoder_config.cc
index 5cecc45a5d..9fb1d5d7bd 100644
--- a/video/config/video_encoder_config.cc
+++ b/video/config/video_encoder_config.cc
@@ -146,4 +146,27 @@ void VideoEncoderConfig::Av1EncoderSpecificSettings::FillVideoCodecAv1(
   *av1_settings = specifics_;
 }
 
+VideoCodecType VideoEncoderConfig::GetSimulcastCodecType(
+    size_t stream_index) const {
+  if (stream_index >= simulcast_layers.size()) {
+    return codec_type;
+  }
+  if (!simulcast_layers[stream_index].video_format) {
+    return codec_type;
+  }
+  return PayloadStringToCodecType(
+      simulcast_layers[stream_index].video_format->name);
+}
+
+const SdpVideoFormat& VideoEncoderConfig::GetSimulcastVideoFormat(
+    size_t stream_index) const {
+  if (stream_index >= simulcast_layers.size()) {
+    return video_format;
+  }
+  if (!simulcast_layers[stream_index].video_format) {
+    return video_format;
+  }
+  return *simulcast_layers[stream_index].video_format;
+}
+
 }  // namespace webrtc
diff --git a/video/config/video_encoder_config.h b/video/config/video_encoder_config.h
index d3d0621a1d..bbdbcc7e15 100644
--- a/video/config/video_encoder_config.h
+++ b/video/config/video_encoder_config.h
@@ -83,6 +83,9 @@ struct VideoStream {
   // e.g. if source only provides lower resolution or
   // if resource adaptation is active.
   absl::optional<Resolution> requested_resolution;
+
+  // このビデオストリームが利用するべきビデオフォーマット
+  std::optional<SdpVideoFormat> video_format;
 };
 
 class VideoEncoderConfig {
@@ -166,6 +169,10 @@ class VideoEncoderConfig {
   ~VideoEncoderConfig();
   std::string ToString() const;
 
+  // stream_index 番目のストリームが利用する設定
+  VideoCodecType GetSimulcastCodecType(size_t stream_index) const;
+  const SdpVideoFormat& GetSimulcastVideoFormat(size_t stream_index) const;
+
   // TODO(bugs.webrtc.org/6883): Consolidate on one of these.
   VideoCodecType codec_type;
   SdpVideoFormat video_format;
diff --git a/video/video_stream_encoder.cc b/video/video_stream_encoder.cc
index a9391e0cea..828f296bd6 100644
--- a/video/video_stream_encoder.cc
+++ b/video/video_stream_encoder.cc
@@ -924,8 +924,24 @@ void VideoStreamEncoder::ConfigureEncoder(VideoEncoderConfig config,
       frame_cadence_adapter_->SetZeroHertzModeEnabled(absl::nullopt);
     }
 
+    bool video_format_changed =
+        encoder_config_.video_format != config.video_format;
+    if (!video_format_changed && encoder_config_.simulcast_layers.size() !=
+                                     config.simulcast_layers.size()) {
+      video_format_changed = true;
+    }
+    if (!video_format_changed) {
+      for (size_t i = 0; i < encoder_config_.simulcast_layers.size(); i++) {
+        if (encoder_config_.GetSimulcastVideoFormat(i) !=
+            config.GetSimulcastVideoFormat(i)) {
+          video_format_changed = true;
+          break;
+        }
+      }
+    }
+
     pending_encoder_creation_ =
-        (!encoder_ || encoder_config_.video_format != config.video_format ||
+        (!encoder_ || video_format_changed ||
          max_data_payload_length_ != max_data_payload_length);
     encoder_config_ = std::move(config);
     max_data_payload_length_ = max_data_payload_length;
@@ -958,6 +974,8 @@ void VideoStreamEncoder::ReconfigureEncoder() {
 
   bool encoder_reset_required = false;
   if (pending_encoder_creation_) {
+    ReleaseEncoder();
+
     // Destroy existing encoder instance before creating a new one. Otherwise
     // attempt to create another instance will fail if encoder factory
     // supports only single instance of encoder of given type.
@@ -2072,8 +2090,7 @@ EncodedImage VideoStreamEncoder::AugmentEncodedImage(
   // TODO(https://crbug.com/webrtc/14891): If we want to support a mix of
   // simulcast and SVC we'll also need to consider the case where we have both
   // simulcast and spatial indices.
-  int stream_idx = encoded_image.SpatialIndex().value_or(
-      encoded_image.SimulcastIndex().value_or(0));
+  int stream_idx = encoded_image.SimulcastIndex().value_or(0);
 
   frame_encode_metadata_writer_.FillMetadataAndTimingInfo(stream_idx,
                                                           &image_copy);
@@ -2116,45 +2133,45 @@ EncodedImageCallback::Result VideoStreamEncoder::OnEncodedImage(
   // need to update on quality convergence.
   unsigned int image_width = image_copy._encodedWidth;
   unsigned int image_height = image_copy._encodedHeight;
-  encoder_queue_->PostTask([this, codec_type, image_width, image_height,
-                            simulcast_index, qp = image_copy.qp_,
-                            is_steady_state_refresh_frame =
-                                image_copy.IsSteadyStateRefreshFrame()] {
-    RTC_DCHECK_RUN_ON(encoder_queue_.get());
-
-    // Check if the encoded image has reached target quality.
-    bool at_target_quality =
-        quality_convergence_controller_.AddSampleAndCheckTargetQuality(
-            simulcast_index, qp, is_steady_state_refresh_frame);
-
-    // Let the frame cadence adapter know about quality convergence.
-    if (frame_cadence_adapter_)
-      frame_cadence_adapter_->UpdateLayerQualityConvergence(simulcast_index,
-                                                            at_target_quality);
-
-    // Currently, the internal quality scaler is used for VP9 instead of the
-    // webrtc qp scaler (in the no-svc case or if only a single spatial layer is
-    // encoded). It has to be explicitly detected and reported to adaptation
-    // metrics.
-    if (codec_type == VideoCodecType::kVideoCodecVP9 &&
-        send_codec_.VP9()->automaticResizeOn) {
-      unsigned int expected_width = send_codec_.width;
-      unsigned int expected_height = send_codec_.height;
-      int num_active_layers = 0;
-      for (int i = 0; i < send_codec_.VP9()->numberOfSpatialLayers; ++i) {
-        if (send_codec_.spatialLayers[i].active) {
-          ++num_active_layers;
-          expected_width = send_codec_.spatialLayers[i].width;
-          expected_height = send_codec_.spatialLayers[i].height;
+  encoder_queue_->PostTask(
+      [this, codec_type, image_width, image_height, simulcast_index,
+       qp = image_copy.qp_,
+       is_steady_state_refresh_frame = image_copy.IsSteadyStateRefreshFrame()] {
+        RTC_DCHECK_RUN_ON(encoder_queue_.get());
+
+        // Check if the encoded image has reached target quality.
+        bool at_target_quality =
+            quality_convergence_controller_.AddSampleAndCheckTargetQuality(
+                simulcast_index, qp, is_steady_state_refresh_frame);
+
+        // Let the frame cadence adapter know about quality convergence.
+        if (frame_cadence_adapter_)
+          frame_cadence_adapter_->UpdateLayerQualityConvergence(
+              simulcast_index, at_target_quality);
+
+        // Currently, the internal quality scaler is used for VP9 instead of the
+        // webrtc qp scaler (in the no-svc case or if only a single spatial
+        // layer is encoded). It has to be explicitly detected and reported to
+        // adaptation metrics.
+        if (codec_type == VideoCodecType::kVideoCodecVP9 &&
+            send_codec_.VP9()->automaticResizeOn) {
+          unsigned int expected_width = send_codec_.width;
+          unsigned int expected_height = send_codec_.height;
+          int num_active_layers = 0;
+          for (int i = 0; i < send_codec_.VP9()->numberOfSpatialLayers; ++i) {
+            if (send_codec_.spatialLayers[i].active) {
+              ++num_active_layers;
+              expected_width = send_codec_.spatialLayers[i].width;
+              expected_height = send_codec_.spatialLayers[i].height;
+            }
+          }
+          RTC_DCHECK_LE(num_active_layers, 1)
+              << "VP9 quality scaling is enabled for "
+                 "SVC with several active layers.";
+          encoder_stats_observer_->OnEncoderInternalScalerUpdate(
+              image_width < expected_width || image_height < expected_height);
         }
-      }
-      RTC_DCHECK_LE(num_active_layers, 1)
-          << "VP9 quality scaling is enabled for "
-             "SVC with several active layers.";
-      encoder_stats_observer_->OnEncoderInternalScalerUpdate(
-          image_width < expected_width || image_height < expected_height);
-    }
-  });
+      });
 
   // Encoded is called on whatever thread the real encoder implementation run
   // on. In the case of hardware encoders, there might be several encoders
