diff --git a/api/video_codecs/simulcast_stream.h b/api/video_codecs/simulcast_stream.h
index 4dbee5bd4b..ae12fdb50c 100644
--- a/api/video_codecs/simulcast_stream.h
+++ b/api/video_codecs/simulcast_stream.h
@@ -14,6 +14,7 @@
 #include <optional>
 
 #include "api/video_codecs/scalability_mode.h"
+#include "api/video_codecs/sdp_video_format.h"
 #include "rtc_base/system/rtc_export.h"
 
 namespace webrtc {
@@ -41,6 +42,7 @@ struct RTC_EXPORT SimulcastStream {
   unsigned int minBitrate = 0;     // kilobits/sec.
   unsigned int qpMax = 0;          // minimum quality
   bool active = false;             // encoded and sent.
+  std::optional<SdpVideoFormat> format;
 };
 
 }  // namespace webrtc
diff --git a/media/base/media_engine.cc b/media/base/media_engine.cc
index 3735c50994..f30ed9eb7f 100644
--- a/media/base/media_engine.cc
+++ b/media/base/media_engine.cc
@@ -219,14 +219,14 @@ webrtc::RTCError CheckRtpParametersValues(
       }
     }
 
-    if (!field_trials.IsEnabled("WebRTC-MixedCodecSimulcast")) {
-      if (i > 0 && rtp_parameters.encodings[i - 1].codec !=
-                       rtp_parameters.encodings[i].codec) {
-        LOG_AND_RETURN_ERROR(RTCErrorType::UNSUPPORTED_OPERATION,
-                             "Attempted to use different codec values for "
-                             "different encodings.");
-      }
-    }
+    //if (!field_trials.IsEnabled("WebRTC-MixedCodecSimulcast")) {
+    //  if (i > 0 && rtp_parameters.encodings[i - 1].codec !=
+    //                   rtp_parameters.encodings[i].codec) {
+    //    LOG_AND_RETURN_ERROR(RTCErrorType::UNSUPPORTED_OPERATION,
+    //                         "Attempted to use different codec values for "
+    //                         "different encodings.");
+    //  }
+    //}
   }
 
   if (has_scale_resolution_down_to &&
diff --git a/media/engine/simulcast_encoder_adapter.cc b/media/engine/simulcast_encoder_adapter.cc
index 6770f1399a..208103a225 100644
--- a/media/engine/simulcast_encoder_adapter.cc
+++ b/media/engine/simulcast_encoder_adapter.cc
@@ -156,17 +156,35 @@ std::vector<uint32_t> GetStreamStartBitratesKbps(const Environment& env,
   return start_bitrates;
 }
 
+bool IsMixedCodec(const VideoCodec& codec) {
+  if (codec.numberOfSimulcastStreams >= 2) {
+    for (size_t i = 0; i < codec.numberOfSimulcastStreams - 1; i++) {
+      for (size_t j = i + 1; j < codec.numberOfSimulcastStreams; j++) {
+        if (codec.simulcastStream[i].format &&
+            codec.simulcastStream[j].format &&
+            !codec.simulcastStream[i].format->IsSameCodec(
+                *codec.simulcastStream[j].format)) {
+          return true;
+        }
+      }
+    }
+  }
+  return false;
+}
+
 }  // namespace
 
 SimulcastEncoderAdapter::EncoderContext::EncoderContext(
     std::unique_ptr<VideoEncoder> encoder,
     bool prefer_temporal_support,
     VideoEncoder::EncoderInfo primary_info,
-    VideoEncoder::EncoderInfo fallback_info)
+    VideoEncoder::EncoderInfo fallback_info,
+    SdpVideoFormat video_format)
     : encoder_(std::move(encoder)),
       prefer_temporal_support_(prefer_temporal_support),
       primary_info_(std::move(primary_info)),
-      fallback_info_(std::move(fallback_info)) {}
+      fallback_info_(std::move(fallback_info)),
+      video_format_(std::move(video_format)) {}
 
 void SimulcastEncoderAdapter::EncoderContext::Release() {
   if (encoder_) {
@@ -342,11 +360,16 @@ int SimulcastEncoderAdapter::InitEncode(
   std::unique_ptr<EncoderContext> encoder_context = FetchOrCreateEncoderContext(
       /*is_lowest_quality_stream=*/(
           is_legacy_singlecast ||
-          codec_.simulcastStream[lowest_quality_stream_idx].active));
+          codec_.simulcastStream[lowest_quality_stream_idx].active),
+      /*stream_idx=*/is_legacy_singlecast
+          ? std::nullopt
+          : std::make_optional(lowest_quality_stream_idx));
   if (encoder_context == nullptr) {
     return WEBRTC_VIDEO_CODEC_MEMORY;
   }
 
+  bool is_mixed_codec = IsMixedCodec(codec_);
+
   // Two distinct scenarios:
   // * Singlecast (total_streams_count == 1) or simulcast with simulcast-capable
   //   underlaying encoder implementation if active_streams_count > 1. SEA
@@ -364,6 +387,7 @@ int SimulcastEncoderAdapter::InitEncode(
   // forces the use of SEA with separate encoders to support per-layer
   // handling of PLIs.
   bool separate_encoders_needed =
+      is_mixed_codec ||
       !encoder_context->encoder().GetEncoderInfo().supports_simulcast ||
       active_streams_count == 1 || per_layer_pli_;
   RTC_LOG(LS_INFO) << "[SEA] InitEncode: total_streams_count: "
@@ -409,9 +433,10 @@ int SimulcastEncoderAdapter::InitEncode(
       continue;
     }
 
-    if (encoder_context == nullptr) {
+    if (encoder_context == nullptr || is_mixed_codec) {
       encoder_context = FetchOrCreateEncoderContext(
-          /*is_lowest_quality_stream=*/stream_idx == lowest_quality_stream_idx);
+          /*is_lowest_quality_stream=*/stream_idx == lowest_quality_stream_idx,
+          stream_idx);
     }
     if (encoder_context == nullptr) {
       Release();
@@ -708,6 +733,10 @@ EncodedImageCallback::Result SimulcastEncoderAdapter::OnEncodedImage(
 
   stream_image.SetSimulcastIndex(stream_idx);
 
+  if (IsMixedCodec(codec_)) {
+    stream_image.SetSpatialIndex(std::nullopt);
+  }
+
   return encoded_complete_callback_->OnEncodedImage(stream_image,
                                                     &stream_codec_specific);
 }
@@ -729,20 +758,27 @@ void SimulcastEncoderAdapter::DestroyStoredEncoders() {
 
 std::unique_ptr<SimulcastEncoderAdapter::EncoderContext>
 SimulcastEncoderAdapter::FetchOrCreateEncoderContext(
-    bool is_lowest_quality_stream) const {
+    bool is_lowest_quality_stream,
+    std::optional<int> stream_idx) const {
   RTC_DCHECK_RUN_ON(&encoder_queue_);
+  SdpVideoFormat video_format =
+      stream_idx
+          ? codec_.simulcastStream[*stream_idx].format.value_or(video_format_)
+          : video_format_;
   bool prefer_temporal_support = fallback_encoder_factory_ != nullptr &&
                                  is_lowest_quality_stream &&
                                  prefer_temporal_support_on_base_layer_;
 
   // Toggling of `prefer_temporal_support` requires encoder recreation. Find
-  // and reuse encoder with desired `prefer_temporal_support`. Otherwise, if
-  // there is no such encoder in the cache, create a new instance.
+  // and reuse encoder with desired `prefer_temporal_support` and
+  // `video_format`. Otherwise, if there is no such encoder in the cache, create
+  // a new instance.
   auto encoder_context_iter =
       std::find_if(cached_encoder_contexts_.begin(),
                    cached_encoder_contexts_.end(), [&](auto& encoder_context) {
                      return encoder_context->prefer_temporal_support() ==
-                            prefer_temporal_support;
+                                prefer_temporal_support &&
+                            encoder_context->video_format() == video_format;
                    });
 
   std::unique_ptr<SimulcastEncoderAdapter::EncoderContext> encoder_context;
@@ -751,11 +787,11 @@ SimulcastEncoderAdapter::FetchOrCreateEncoderContext(
     cached_encoder_contexts_.erase(encoder_context_iter);
   } else {
     std::unique_ptr<VideoEncoder> primary_encoder =
-        primary_encoder_factory_->Create(env_, video_format_);
+        primary_encoder_factory_->Create(env_, video_format);
 
     std::unique_ptr<VideoEncoder> fallback_encoder;
     if (fallback_encoder_factory_ != nullptr) {
-      fallback_encoder = fallback_encoder_factory_->Create(env_, video_format_);
+      fallback_encoder = fallback_encoder_factory_->Create(env_, video_format);
     }
 
     std::unique_ptr<VideoEncoder> encoder;
@@ -774,20 +810,20 @@ SimulcastEncoderAdapter::FetchOrCreateEncoderContext(
             prefer_temporal_support);
       }
     } else if (fallback_encoder != nullptr) {
-      RTC_LOG(LS_WARNING) << "Failed to create primary " << video_format_.name
+      RTC_LOG(LS_WARNING) << "Failed to create primary " << video_format.name
                           << " encoder. Use fallback encoder.";
       fallback_info = fallback_encoder->GetEncoderInfo();
       primary_info = fallback_info;
       encoder = std::move(fallback_encoder);
     } else {
       RTC_LOG(LS_ERROR) << "Failed to create primary and fallback "
-                        << video_format_.name << " encoders.";
+                        << video_format.name << " encoders.";
       return nullptr;
     }
 
     encoder_context = std::make_unique<SimulcastEncoderAdapter::EncoderContext>(
         std::move(encoder), prefer_temporal_support, primary_info,
-        fallback_info);
+        fallback_info, std::move(video_format));
   }
 
   encoder_context->encoder().RegisterEncodeCompleteCallback(
@@ -803,7 +839,12 @@ webrtc::VideoCodec SimulcastEncoderAdapter::MakeStreamCodec(
     bool is_highest_quality_stream) {
   webrtc::VideoCodec codec_params = codec;
   const SimulcastStream& stream_params = codec.simulcastStream[stream_idx];
+  webrtc::VideoCodecType codecType =
+      stream_params.format
+          ? PayloadStringToCodecType(stream_params.format->name)
+          : codec.codecType;
 
+  codec_params.codecType = codecType;
   codec_params.numberOfSimulcastStreams = 0;
   codec_params.width = stream_params.width;
   codec_params.height = stream_params.height;
@@ -841,7 +882,7 @@ webrtc::VideoCodec SimulcastEncoderAdapter::MakeStreamCodec(
       codec_params.qpMax = kLowestResMaxQp;
     }
   }
-  if (codec.codecType == webrtc::kVideoCodecVP8) {
+  if (codecType == webrtc::kVideoCodecVP8) {
     codec_params.VP8()->numberOfTemporalLayers =
         stream_params.numberOfTemporalLayers;
     if (!is_highest_quality_stream) {
@@ -855,10 +896,10 @@ webrtc::VideoCodec SimulcastEncoderAdapter::MakeStreamCodec(
       // Turn off denoising for all streams but the highest resolution.
       codec_params.VP8()->denoisingOn = false;
     }
-  } else if (codec.codecType == webrtc::kVideoCodecH264) {
+  } else if (codecType == webrtc::kVideoCodecH264) {
     codec_params.H264()->numberOfTemporalLayers =
         stream_params.numberOfTemporalLayers;
-  } else if (codec.codecType == webrtc::kVideoCodecVP9 &&
+  } else if (codecType == webrtc::kVideoCodecVP9 &&
              scalability_mode.has_value() && !only_active_stream) {
     // If VP9 simulcast then explicitly set a single spatial layer for each
     // simulcast stream.
@@ -921,7 +962,8 @@ VideoEncoder::EncoderInfo SimulcastEncoderAdapter::GetEncoderInfo() const {
     // Create one encoder and query it.
 
     std::unique_ptr<SimulcastEncoderAdapter::EncoderContext> encoder_context =
-        FetchOrCreateEncoderContext(/*is_lowest_quality_stream=*/true);
+        FetchOrCreateEncoderContext(/*is_lowest_quality_stream=*/true,
+                                    std::nullopt);
     if (encoder_context == nullptr) {
       return encoder_info;
     }
diff --git a/media/engine/simulcast_encoder_adapter.h b/media/engine/simulcast_encoder_adapter.h
index 63e1075209..a048e8c1d3 100644
--- a/media/engine/simulcast_encoder_adapter.h
+++ b/media/engine/simulcast_encoder_adapter.h
@@ -81,7 +81,8 @@ class RTC_EXPORT SimulcastEncoderAdapter : public VideoEncoder {
     EncoderContext(std::unique_ptr<VideoEncoder> encoder,
                    bool prefer_temporal_support,
                    VideoEncoder::EncoderInfo primary_info,
-                   VideoEncoder::EncoderInfo fallback_info);
+                   VideoEncoder::EncoderInfo fallback_info,
+                   SdpVideoFormat video_foramt);
     EncoderContext& operator=(EncoderContext&&) = delete;
 
     VideoEncoder& encoder() { return *encoder_; }
@@ -92,11 +93,14 @@ class RTC_EXPORT SimulcastEncoderAdapter : public VideoEncoder {
 
     const VideoEncoder::EncoderInfo& FallbackInfo() { return fallback_info_; }
 
+    const SdpVideoFormat& video_format() { return video_format_; }
+
    private:
     std::unique_ptr<VideoEncoder> encoder_;
     bool prefer_temporal_support_;
     const VideoEncoder::EncoderInfo primary_info_;
     const VideoEncoder::EncoderInfo fallback_info_;
+    const SdpVideoFormat video_format_;
   };
 
   class StreamContext : public EncodedImageCallback {
@@ -156,7 +160,8 @@ class RTC_EXPORT SimulcastEncoderAdapter : public VideoEncoder {
   // `cached_encoder_contexts_`. It's const because it's used from
   // const GetEncoderInfo().
   std::unique_ptr<EncoderContext> FetchOrCreateEncoderContext(
-      bool is_lowest_quality_stream) const;
+      bool is_lowest_quality_stream,
+      std::optional<int> stream_idx) const;
 
   webrtc::VideoCodec MakeStreamCodec(const webrtc::VideoCodec& codec,
                                      int stream_idx,
diff --git a/media/engine/webrtc_video_engine.cc b/media/engine/webrtc_video_engine.cc
index 906ef01ba3..f1b4181df7 100644
--- a/media/engine/webrtc_video_engine.cc
+++ b/media/engine/webrtc_video_engine.cc
@@ -393,15 +393,15 @@ static bool ValidateStreamParams(const StreamParams& sp) {
 }
 
 // Returns true if the given codec is disallowed from doing simulcast.
-bool IsCodecDisabledForSimulcast(bool legacy_scalability_mode,
-                                 webrtc::VideoCodecType codec_type) {
-  if (legacy_scalability_mode && (codec_type == webrtc::kVideoCodecVP9 ||
-                                  codec_type == webrtc::kVideoCodecAV1)) {
-    return true;
-  }
-
-  return false;
-}
+// bool IsCodecDisabledForSimulcast(bool legacy_scalability_mode,
+//                                 webrtc::VideoCodecType codec_type) {
+//  if (legacy_scalability_mode && (codec_type == webrtc::kVideoCodecVP9 ||
+//                                  codec_type == webrtc::kVideoCodecAV1)) {
+//    return true;
+//  }
+//
+//  return false;
+//}
 
 bool IsLayerActive(const webrtc::RtpEncodingParameters& layer) {
   return layer.active &&
@@ -1718,6 +1718,14 @@ void WebRtcVideoSendChannel::FillSendCodecStats(
   // primary codec that is being used to send here.
   video_media_info->send_codecs.insert(std::make_pair(
       send_codec()->codec.id, send_codec()->codec.ToCodecParameters()));
+
+  for (const auto& it : send_codecs_) {
+    auto codec_param_it = video_media_info->send_codecs.find(it.codec.id);
+    if (codec_param_it == video_media_info->send_codecs.end()) {
+      video_media_info->send_codecs.insert(
+          std::make_pair(it.codec.id, it.codec.ToCodecParameters()));
+    }
+  }
 }
 
 void WebRtcVideoSendChannel::OnPacketSent(const rtc::SentPacket& sent_packet) {
@@ -2297,25 +2305,25 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::CreateVideoEncoderConfig(
   // number of negotiated ssrcs but this may be capped below depending on the
   // `legacy_scalability_mode` and codec used.
   encoder_config.number_of_streams = parameters_.config.rtp.ssrcs.size();
-  bool legacy_scalability_mode = true;
-  for (const webrtc::RtpEncodingParameters& encoding :
-       rtp_parameters_.encodings) {
-    if (encoding.scalability_mode.has_value() &&
-        (encoding.scale_resolution_down_by.has_value() ||
-         encoding.scale_resolution_down_to.has_value())) {
-      legacy_scalability_mode = false;
-      break;
-    }
-  }
+  // bool legacy_scalability_mode = true;
+  // for (const webrtc::RtpEncodingParameters& encoding :
+  //      rtp_parameters_.encodings) {
+  //   if (encoding.scalability_mode.has_value() &&
+  //       (encoding.scale_resolution_down_by.has_value() ||
+  //        encoding.scale_resolution_down_to.has_value())) {
+  //     legacy_scalability_mode = false;
+  //     break;
+  //   }
+  // }
   // Maybe limit the number of simulcast layers depending on
   // `legacy_scalability_mode`, codec types (VP9/AV1). This path only exists
   // for backwards compatibility and will one day be deleted. If you want SVC,
   // please specify with the `scalability_mode` API instead amd disabling all
   // but one encoding.
-  if (IsCodecDisabledForSimulcast(legacy_scalability_mode,
-                                  encoder_config.codec_type)) {
-    encoder_config.number_of_streams = 1;
-  }
+  // if (IsCodecDisabledForSimulcast(legacy_scalability_mode,
+  //                                 encoder_config.codec_type)) {
+  //   encoder_config.number_of_streams = 1;
+  // }
 
   // parameters_.max_bitrate comes from the max bitrate set at the SDP
   // (m-section) level with the attribute "b=AS." Note that stream max bitrate
@@ -2383,6 +2391,11 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::CreateVideoEncoderConfig(
       encoder_config.simulcast_layers[i].num_temporal_layers =
           *rtp_parameters_.encodings[i].num_temporal_layers;
     }
+    if (rtp_parameters_.encodings[i].codec) {
+      encoder_config.simulcast_layers[i].video_format = webrtc::SdpVideoFormat(
+          rtp_parameters_.encodings[i].codec->name,
+          rtp_parameters_.encodings[i].codec->parameters);
+    }
     encoder_config.simulcast_layers[i].scale_resolution_down_to =
         rtp_parameters_.encodings[i].scale_resolution_down_to;
   }
@@ -2553,6 +2566,14 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::GetPerLayerVideoSenderInfos(
     if (encoding_index_by_ssrc.find(ssrc) != encoding_index_by_ssrc.end()) {
       info.encoding_index = encoding_index_by_ssrc[ssrc];
     }
+    auto stream_config = std::find_if(
+        parameters_.config.rtp.stream_configs.begin(),
+        parameters_.config.rtp.stream_configs.end(),
+        [ssrc](auto stream_config) { return stream_config.ssrc == ssrc; });
+    if (stream_config != parameters_.config.rtp.stream_configs.end()) {
+      info.codec_name = stream_config->payload_name;
+      info.codec_payload_type = stream_config->payload_type;
+    }
     info.active = IsActiveFromEncodings(
         !is_svc ? std::optional<uint32_t>(ssrc) : std::nullopt,
         rtp_parameters_.encodings);
diff --git a/modules/video_coding/utility/simulcast_rate_allocator.cc b/modules/video_coding/utility/simulcast_rate_allocator.cc
index 1157d1a76f..3c096831f0 100644
--- a/modules/video_coding/utility/simulcast_rate_allocator.cc
+++ b/modules/video_coding/utility/simulcast_rate_allocator.cc
@@ -175,8 +175,30 @@ void SimulcastRateAllocator::DistributeAllocationToSimulcastLayers(
       min_bitrate = std::min(hysteresis_factor * min_bitrate, target_bitrate);
     }
     if (left_in_stable_allocation < min_bitrate) {
-      allocated_bitrates->set_bw_limited(true);
-      break;
+      bool is_mixed_codec = std::invoke([this]() {
+        if (codec_.numberOfSimulcastStreams >= 2) {
+          for (size_t i = 0; i < codec_.numberOfSimulcastStreams - 1; i++) {
+            for (size_t j = i + 1; j < codec_.numberOfSimulcastStreams; j++) {
+              if (codec_.simulcastStream[i].format &&
+                  codec_.simulcastStream[j].format &&
+                  !codec_.simulcastStream[i].format->IsSameCodec(
+                      *codec_.simulcastStream[j].format)) {
+                return true;
+              }
+            }
+          }
+        }
+        return false;
+      });
+
+      if (is_mixed_codec) {
+        // トータルのビットレートが低すぎると、高いレイヤーにビットレートを割り当てることができなくなるのだけど、
+        // サイマルキャストマルチコーデックでそれをされると困るので、トータルのビットレートを超えても無理やり出力する
+        left_in_stable_allocation = left_in_total_allocation = min_bitrate;
+      } else {
+        allocated_bitrates->set_bw_limited(true);
+        break;
+      }
     }
 
     // We are allocating to this layer so it is the current active allocation.
@@ -335,11 +357,14 @@ const VideoCodec& webrtc::SimulcastRateAllocator::GetCodec() const {
 }
 
 int SimulcastRateAllocator::NumTemporalStreams(size_t simulcast_id) const {
+  bool is_vp8 = codec_.simulcastStream[simulcast_id].format
+                    ? codec_.simulcastStream[simulcast_id].format->IsSameCodec(
+                          webrtc::SdpVideoFormat::VP8())
+                    : codec_.codecType == kVideoCodecVP8;
   return std::max<uint8_t>(
-      1,
-      codec_.codecType == kVideoCodecVP8 && codec_.numberOfSimulcastStreams == 0
-          ? codec_.VP8().numberOfTemporalLayers
-          : codec_.simulcastStream[simulcast_id].numberOfTemporalLayers);
+      1, is_vp8 && codec_.numberOfSimulcastStreams == 0
+             ? codec_.VP8().numberOfTemporalLayers
+             : codec_.simulcastStream[simulcast_id].numberOfTemporalLayers);
 }
 
 void SimulcastRateAllocator::SetLegacyConferenceMode(bool enabled) {
diff --git a/modules/video_coding/video_codec_initializer.cc b/modules/video_coding/video_codec_initializer.cc
index fbcf579a21..4ed402b45c 100644
--- a/modules/video_coding/video_codec_initializer.cc
+++ b/modules/video_coding/video_codec_initializer.cc
@@ -114,6 +114,7 @@ VideoCodec VideoCodecInitializer::SetupCodec(
     sim_stream->targetBitrate = streams[i].target_bitrate_bps / 1000;
     sim_stream->maxBitrate = streams[i].max_bitrate_bps / 1000;
     sim_stream->qpMax = streams[i].max_qp;
+    sim_stream->format = config.GetSimulcastVideoFormat(i);
 
     int num_temporal_layers =
         streams[i].scalability_mode.has_value()
diff --git a/video/config/encoder_stream_factory.cc b/video/config/encoder_stream_factory.cc
index 010954430d..afbf97f318 100644
--- a/video/config/encoder_stream_factory.cc
+++ b/video/config/encoder_stream_factory.cc
@@ -528,7 +528,24 @@ std::vector<Resolution> EncoderStreamFactory::GetStreamResolutions(
       resolutions.push_back({.width = width, .height = height});
     }
   } else {
-    size_t min_num_layers = FindRequiredActiveLayers(encoder_config);
+    bool is_mixed_codec = std::invoke([&]() {
+      if (encoder_config.simulcast_layers.size() >= 2) {
+        for (size_t i = 0; i < encoder_config.simulcast_layers.size() - 1;
+             i++) {
+          for (size_t j = i + 1; j < encoder_config.simulcast_layers.size();
+               j++) {
+            if (!encoder_config.GetSimulcastVideoFormat(i).IsSameCodec(
+                    encoder_config.GetSimulcastVideoFormat(j))) {
+              return true;
+            }
+          }
+        }
+      }
+      return false;
+    });
+    size_t min_num_layers = is_mixed_codec
+                                ? encoder_config.number_of_streams
+                                : FindRequiredActiveLayers(encoder_config);
     size_t max_num_layers =
         !encoder_config.HasScaleResolutionDownTo()
             ? webrtc::LimitSimulcastLayerCount(
diff --git a/video/config/video_encoder_config.cc b/video/config/video_encoder_config.cc
index ca3b20e436..e712945eb5 100644
--- a/video/config/video_encoder_config.cc
+++ b/video/config/video_encoder_config.cc
@@ -161,4 +161,27 @@ void VideoEncoderConfig::Av1EncoderSpecificSettings::FillVideoCodecAv1(
   *av1_settings = specifics_;
 }
 
+VideoCodecType VideoEncoderConfig::GetSimulcastCodecType(
+    size_t stream_index) const {
+  if (stream_index >= simulcast_layers.size()) {
+    return codec_type;
+  }
+  if (!simulcast_layers[stream_index].video_format) {
+    return codec_type;
+  }
+  return PayloadStringToCodecType(
+      simulcast_layers[stream_index].video_format->name);
+}
+
+const SdpVideoFormat& VideoEncoderConfig::GetSimulcastVideoFormat(
+    size_t stream_index) const {
+  if (stream_index >= simulcast_layers.size()) {
+    return video_format;
+  }
+  if (!simulcast_layers[stream_index].video_format) {
+    return video_format;
+  }
+  return *simulcast_layers[stream_index].video_format;
+}
+
 }  // namespace webrtc
diff --git a/video/config/video_encoder_config.h b/video/config/video_encoder_config.h
index 59ee866f53..bff797130e 100644
--- a/video/config/video_encoder_config.h
+++ b/video/config/video_encoder_config.h
@@ -83,6 +83,9 @@ struct VideoStream {
   // e.g. if source only provides lower resolution or
   // if resource adaptation is active.
   std::optional<Resolution> scale_resolution_down_to;
+
+  // このビデオストリームが利用するべきビデオフォーマット
+  std::optional<SdpVideoFormat> video_format;
 };
 
 class VideoEncoderConfig {
@@ -168,6 +171,10 @@ class VideoEncoderConfig {
 
   bool HasScaleResolutionDownTo() const;
 
+  // stream_index 番目のストリームが利用する設定
+  VideoCodecType GetSimulcastCodecType(size_t stream_index) const;
+  const SdpVideoFormat& GetSimulcastVideoFormat(size_t stream_index) const;
+
   // TODO(bugs.webrtc.org/6883): Consolidate on one of these.
   VideoCodecType codec_type;
   SdpVideoFormat video_format;
diff --git a/video/video_stream_encoder.cc b/video/video_stream_encoder.cc
index 7fdd9946d8..4ec3f2f38a 100644
--- a/video/video_stream_encoder.cc
+++ b/video/video_stream_encoder.cc
@@ -994,8 +994,24 @@ void VideoStreamEncoder::ConfigureEncoder(VideoEncoderConfig config,
       frame_cadence_adapter_->SetZeroHertzModeEnabled(std::nullopt);
     }
 
+    bool video_format_changed =
+        encoder_config_.video_format != config.video_format;
+    if (!video_format_changed && encoder_config_.simulcast_layers.size() !=
+                                     config.simulcast_layers.size()) {
+      video_format_changed = true;
+    }
+    if (!video_format_changed) {
+      for (size_t i = 0; i < encoder_config_.simulcast_layers.size(); i++) {
+        if (encoder_config_.GetSimulcastVideoFormat(i) !=
+            config.GetSimulcastVideoFormat(i)) {
+          video_format_changed = true;
+          break;
+        }
+      }
+    }
+
     pending_encoder_creation_ =
-        (!encoder_ || encoder_config_.video_format != config.video_format ||
+        (!encoder_ || video_format_changed ||
          max_data_payload_length_ != max_data_payload_length);
     encoder_config_ = std::move(config);
     max_data_payload_length_ = max_data_payload_length;
@@ -2232,7 +2248,7 @@ EncodedImageCallback::Result VideoStreamEncoder::OnEncodedImage(
         // webrtc qp scaler (in the no-svc case or if only a single spatial
         // layer is encoded). It has to be explicitly detected and reported to
         // adaptation metrics.
-        if (codec_type == VideoCodecType::kVideoCodecVP9 &&
+        if (codec_type == VideoCodecType::kVideoCodecVP9 && false &&
             send_codec_.VP9()->automaticResizeOn) {
           unsigned int expected_width = send_codec_.width;
           unsigned int expected_height = send_codec_.height;
