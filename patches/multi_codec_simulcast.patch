diff --git a/api/video_codecs/simulcast_stream.h b/api/video_codecs/simulcast_stream.h
index 4dbee5bd4b..ae12fdb50c 100644
--- a/api/video_codecs/simulcast_stream.h
+++ b/api/video_codecs/simulcast_stream.h
@@ -14,6 +14,7 @@
 #include <optional>
 
 #include "api/video_codecs/scalability_mode.h"
+#include "api/video_codecs/sdp_video_format.h"
 #include "rtc_base/system/rtc_export.h"
 
 namespace webrtc {
@@ -41,6 +42,7 @@ struct RTC_EXPORT SimulcastStream {
   unsigned int minBitrate = 0;     // kilobits/sec.
   unsigned int qpMax = 0;          // minimum quality
   bool active = false;             // encoded and sent.
+  std::optional<SdpVideoFormat> format;
 };
 
 }  // namespace webrtc
diff --git a/call/rtp_config.cc b/call/rtp_config.cc
index 02cc0f40b1..16911297ef 100644
--- a/call/rtp_config.cc
+++ b/call/rtp_config.cc
@@ -239,4 +239,31 @@ std::optional<std::string> RtpConfig::GetRidForSsrc(uint32_t ssrc) const {
   return std::nullopt;
 }
 
+RtpStreamConfig RtpConfig::GetStreamConfig(size_t index) const {
+  // GetStreamConfig function usually returns stream_configs[index], but if
+  // stream_configs is not initialized (i.e., index >= stream_configs.size()),
+  // it creates and returns an RtpStreamConfig using fields such as ssrcs, rids,
+  // payload_name, and payload_type from RtpConfig.
+  RTC_DCHECK_LT(index, ssrcs.size());
+  if (index < stream_configs.size()) {
+    return stream_configs[index];
+  }
+  RtpStreamConfig stream_config;
+  stream_config.ssrc = ssrcs[index];
+  if (index < rids.size()) {
+    stream_config.rid = rids[index];
+  }
+  stream_config.payload_name = payload_name;
+  stream_config.payload_type = payload_type;
+  stream_config.raw_payload = raw_payload;
+  if (!rtx.ssrcs.empty()) {
+    RTC_DCHECK_EQ(ssrcs.size(), rtx.ssrcs.size());
+    auto& stream_config_rtx = stream_config.rtx.emplace();
+    stream_config_rtx.ssrc = rtx.ssrcs[index];
+    stream_config_rtx.payload_type = rtx.payload_type;
+  }
+
+  return stream_config;
+}
+
 }  // namespace webrtc
diff --git a/call/rtp_config.h b/call/rtp_config.h
index 6b79e55f40..d77289febc 100644
--- a/call/rtp_config.h
+++ b/call/rtp_config.h
@@ -193,6 +193,9 @@ struct RtpConfig {
   uint32_t GetMediaSsrcAssociatedWithRtxSsrc(uint32_t rtx_ssrc) const;
   uint32_t GetMediaSsrcAssociatedWithFlexfecSsrc(uint32_t flexfec_ssrc) const;
   std::optional<std::string> GetRidForSsrc(uint32_t ssrc) const;
+
+  // Returns send config for RTP stream by provided simulcast `index`.
+  RtpStreamConfig GetStreamConfig(size_t index) const;
 };
 }  // namespace webrtc
 #endif  // CALL_RTP_CONFIG_H_
diff --git a/call/rtp_video_sender.cc b/call/rtp_video_sender.cc
index 37cab225b7..8964e4b6bc 100644
--- a/call/rtp_video_sender.cc
+++ b/call/rtp_video_sender.cc
@@ -330,11 +330,13 @@ std::vector<RtpStreamSender> CreateRtpStreamSenders(
   return rtp_streams;
 }
 
-std::optional<VideoCodecType> GetVideoCodecType(const RtpConfig& config) {
-  if (config.raw_payload) {
+std::optional<VideoCodecType> GetVideoCodecType(const RtpConfig& config,
+                                                size_t simulcast_index) {
+  auto stream_config = config.GetStreamConfig(simulcast_index);
+  if (stream_config.raw_payload) {
     return std::nullopt;
   }
-  return PayloadStringToCodecType(config.payload_name);
+  return PayloadStringToCodecType(stream_config.payload_name);
 }
 bool TransportSeqNumExtensionConfigured(const RtpConfig& config) {
   return absl::c_any_of(config.extensions, [](const RtpExtension& ext) {
@@ -421,7 +423,6 @@ RtpVideoSender::RtpVideoSender(
                                           crypto_options,
                                           std::move(frame_transformer))),
       rtp_config_(rtp_config),
-      codec_type_(GetVideoCodecType(rtp_config)),
       transport_(transport),
       independent_frame_ids_(
           !env.field_trials().IsDisabled(
@@ -470,12 +471,14 @@ RtpVideoSender::RtpVideoSender(
   }
 
   bool fec_enabled = false;
-  for (const RtpStreamSender& stream : rtp_streams_) {
+  for (size_t i = 0; i < rtp_streams_.size(); i++) {
+    const RtpStreamSender& stream = rtp_streams_[i];
     // Simulcast has one module for each layer. Set the CNAME on all modules.
     stream.rtp_rtcp->SetCNAME(rtp_config_.c_name.c_str());
     stream.rtp_rtcp->SetMaxRtpPacketSize(rtp_config_.max_packet_size);
-    stream.rtp_rtcp->RegisterSendPayloadFrequency(rtp_config_.payload_type,
-                                                  kVideoPayloadTypeFrequency);
+    stream.rtp_rtcp->RegisterSendPayloadFrequency(
+        rtp_config_.GetStreamConfig(i).payload_type,
+        kVideoPayloadTypeFrequency);
     if (stream.fec_generator != nullptr) {
       fec_enabled = true;
     }
@@ -576,7 +579,7 @@ EncodedImageCallback::Result RtpVideoSender::OnEncodedImage(
   // knowledge of the offset to a single place.
   if (!rtp_streams_[simulcast_index].rtp_rtcp->OnSendingRtpFrame(
           encoded_image.RtpTimestamp(), encoded_image.capture_time_ms_,
-          rtp_config_.payload_type,
+          rtp_config_.GetStreamConfig(simulcast_index).payload_type,
           encoded_image._frameType == VideoFrameType::kVideoFrameKey)) {
     // The payload router could be active but this module isn't sending.
     return Result(Result::ERROR_SEND_FAILED);
@@ -616,7 +619,9 @@ EncodedImageCallback::Result RtpVideoSender::OnEncodedImage(
 
   bool send_result =
       rtp_streams_[simulcast_index].sender_video->SendEncodedImage(
-          rtp_config_.payload_type, codec_type_, rtp_timestamp, encoded_image,
+          rtp_config_.GetStreamConfig(simulcast_index).payload_type,
+          GetVideoCodecType(rtp_config_, simulcast_index), rtp_timestamp,
+          encoded_image,
           params_[simulcast_index].GetRtpVideoHeader(
               encoded_image, codec_specific_info, frame_id),
           expected_retransmission_time);
@@ -754,9 +759,12 @@ void RtpVideoSender::ConfigureSsrcs(
 
   // Configure RTX payload types.
   RTC_DCHECK_GE(rtp_config_.rtx.payload_type, 0);
-  for (const RtpStreamSender& stream : rtp_streams_) {
-    stream.rtp_rtcp->SetRtxSendPayloadType(rtp_config_.rtx.payload_type,
-                                           rtp_config_.payload_type);
+  for (size_t i = 0; i < rtp_streams_.size(); ++i) {
+    const RtpStreamSender& stream = rtp_streams_[i];
+    RtpStreamConfig stream_config = rtp_config_.GetStreamConfig(i);
+    RTC_DCHECK(stream_config.rtx);
+    stream.rtp_rtcp->SetRtxSendPayloadType(stream_config.rtx->payload_type,
+                                           stream_config.payload_type);
     stream.rtp_rtcp->SetRtxSendStatus(kRtxRetransmitted |
                                       kRtxRedundantPayloads);
   }
diff --git a/call/rtp_video_sender_unittest.cc b/call/rtp_video_sender_unittest.cc
index 936f2937a1..8fc744fe74 100644
--- a/call/rtp_video_sender_unittest.cc
+++ b/call/rtp_video_sender_unittest.cc
@@ -84,6 +84,7 @@ using ::testing::SaveArg;
 using ::testing::SizeIs;
 
 const int8_t kPayloadType = 96;
+const int8_t kPayloadType2 = 98;
 const uint32_t kSsrc1 = 12345;
 const uint32_t kSsrc2 = 23456;
 const uint32_t kRtxSsrc1 = 34567;
@@ -133,7 +134,8 @@ VideoSendStream::Config CreateVideoSendStreamConfig(
     Transport* transport,
     const std::vector<uint32_t>& ssrcs,
     const std::vector<uint32_t>& rtx_ssrcs,
-    int payload_type) {
+    int payload_type,
+    rtc::ArrayView<const int> payload_types) {
   VideoSendStream::Config config(transport);
   config.rtp.ssrcs = ssrcs;
   config.rtp.rtx.ssrcs = rtx_ssrcs;
@@ -145,6 +147,20 @@ VideoSendStream::Config CreateVideoSendStreamConfig(
   config.rtp.extensions.emplace_back(RtpDependencyDescriptorExtension::Uri(),
                                      kDependencyDescriptorExtensionId);
   config.rtp.extmap_allow_mixed = true;
+
+  if (!payload_types.empty()) {
+    RTC_CHECK_EQ(payload_types.size(), ssrcs.size());
+    for (size_t i = 0; i < ssrcs.size(); ++i) {
+      auto& stream_config = config.rtp.stream_configs.emplace_back();
+      stream_config.ssrc = ssrcs[i];
+      stream_config.payload_type = payload_types[i];
+      if (i < rtx_ssrcs.size()) {
+        auto& rtx = stream_config.rtx.emplace();
+        rtx.ssrc = rtx_ssrcs[i];
+        rtx.payload_type = payload_types[i] + 1;
+      }
+    }
+  }
   return config;
 }
 
@@ -157,6 +173,7 @@ class RtpVideoSenderTestFixture {
       const std::map<uint32_t, RtpPayloadState>& suspended_payload_states,
       FrameCountObserver* frame_count_observer,
       rtc::scoped_refptr<FrameTransformerInterface> frame_transformer,
+      const std::vector<int>& payload_types,
       const FieldTrialsView* field_trials = nullptr)
       : time_controller_(Timestamp::Millis(1000000)),
         env_(CreateEnvironment(&field_trials_,
@@ -166,7 +183,8 @@ class RtpVideoSenderTestFixture {
         config_(CreateVideoSendStreamConfig(&transport_,
                                             ssrcs,
                                             rtx_ssrcs,
-                                            payload_type)),
+                                            payload_type,
+                                            payload_types)),
         bitrate_config_(GetBitrateConfig()),
         transport_controller_(
             RtpTransportConfig{.env = env_, .bitrate_config = bitrate_config_}),
@@ -188,6 +206,22 @@ class RtpVideoSenderTestFixture {
         std::make_unique<FecControllerDefault>(env_), nullptr, CryptoOptions{},
         frame_transformer);
   }
+  RtpVideoSenderTestFixture(
+      const std::vector<uint32_t>& ssrcs,
+      const std::vector<uint32_t>& rtx_ssrcs,
+      int payload_type,
+      const std::map<uint32_t, RtpPayloadState>& suspended_payload_states,
+      FrameCountObserver* frame_count_observer,
+      rtc::scoped_refptr<FrameTransformerInterface> frame_transformer,
+      const FieldTrialsView* field_trials = nullptr)
+      : RtpVideoSenderTestFixture(ssrcs,
+                                  rtx_ssrcs,
+                                  payload_type,
+                                  suspended_payload_states,
+                                  frame_count_observer,
+                                  frame_transformer,
+                                  /*payload_types=*/{},
+                                  field_trials) {}
 
   RtpVideoSenderTestFixture(
       const std::vector<uint32_t>& ssrcs,
@@ -202,6 +236,7 @@ class RtpVideoSenderTestFixture {
                                   suspended_payload_states,
                                   frame_count_observer,
                                   /*frame_transformer=*/nullptr,
+                                  /*payload_types=*/{},
                                   field_trials) {}
 
   RtpVideoSenderTestFixture(
@@ -216,6 +251,7 @@ class RtpVideoSenderTestFixture {
                                   suspended_payload_states,
                                   /*frame_count_observer=*/nullptr,
                                   /*frame_transformer=*/nullptr,
+                                  /*payload_types=*/{},
                                   field_trials) {}
 
   ~RtpVideoSenderTestFixture() { SetSending(false); }
@@ -953,6 +989,79 @@ TEST(RtpVideoSenderTest,
   EXPECT_EQ(dd_s1.frame_number(), 1002);
 }
 
+TEST(RtpVideoSenderTest, MixedCodecSimulcastPayloadType) {
+  // When multiple payload types are set, verify that the payload type switches
+  // corresponding to the simulcast index.
+  RtpVideoSenderTestFixture test({kSsrc1, kSsrc2}, {kRtxSsrc1, kRtxSsrc2},
+                                 kPayloadType, {}, nullptr, nullptr,
+                                 {kPayloadType, kPayloadType2});
+  test.SetSending(true);
+
+  std::vector<uint16_t> rtp_sequence_numbers;
+  std::vector<RtpPacket> sent_packets;
+  EXPECT_CALL(test.transport(), SendRtp)
+      .Times(3)
+      .WillRepeatedly([&](rtc::ArrayView<const uint8_t> packet,
+                          const PacketOptions& options) -> bool {
+        RtpPacket& rtp_packet = sent_packets.emplace_back();
+        EXPECT_TRUE(rtp_packet.Parse(packet));
+        rtp_sequence_numbers.push_back(rtp_packet.SequenceNumber());
+        return true;
+      });
+
+  const uint8_t kPayload[1] = {'a'};
+  EncodedImage encoded_image;
+  encoded_image.SetEncodedData(
+      EncodedImageBuffer::Create(kPayload, sizeof(kPayload)));
+
+  CodecSpecificInfo codec_specific;
+  codec_specific.codecType = VideoCodecType::kVideoCodecVP8;
+
+  encoded_image.SetSimulcastIndex(0);
+  ASSERT_EQ(test.router()->OnEncodedImage(encoded_image, &codec_specific).error,
+            EncodedImageCallback::Result::OK);
+  ASSERT_EQ(test.router()->OnEncodedImage(encoded_image, &codec_specific).error,
+            EncodedImageCallback::Result::OK);
+  encoded_image.SetSimulcastIndex(1);
+  ASSERT_EQ(test.router()->OnEncodedImage(encoded_image, &codec_specific).error,
+            EncodedImageCallback::Result::OK);
+
+  test.AdvanceTime(TimeDelta::Millis(33));
+  ASSERT_THAT(sent_packets, SizeIs(3));
+  EXPECT_EQ(sent_packets[0].PayloadType(), kPayloadType);
+  EXPECT_EQ(sent_packets[1].PayloadType(), kPayloadType);
+  EXPECT_EQ(sent_packets[2].PayloadType(), kPayloadType2);
+
+  // Verify that NACK is sent to the RTX payload type corresponding to the
+  // payload type.
+  rtcp::Nack nack1, nack2;
+  nack1.SetMediaSsrc(kSsrc1);
+  nack2.SetMediaSsrc(kSsrc2);
+  nack1.SetPacketIds({rtp_sequence_numbers[0], rtp_sequence_numbers[1]});
+  nack2.SetPacketIds({rtp_sequence_numbers[2]});
+  rtc::Buffer nack_buffer1 = nack1.Build();
+  rtc::Buffer nack_buffer2 = nack2.Build();
+
+  std::vector<RtpPacket> sent_rtx_packets;
+  EXPECT_CALL(test.transport(), SendRtp)
+      .Times(3)
+      .WillRepeatedly([&](rtc::ArrayView<const uint8_t> packet,
+                          const PacketOptions& options) {
+        RtpPacket& rtp_packet = sent_rtx_packets.emplace_back();
+        EXPECT_TRUE(rtp_packet.Parse(packet));
+        return true;
+      });
+  test.router()->DeliverRtcp(nack_buffer1.data(), nack_buffer1.size());
+  test.router()->DeliverRtcp(nack_buffer2.data(), nack_buffer2.size());
+
+  test.AdvanceTime(TimeDelta::Millis(33));
+
+  ASSERT_THAT(sent_rtx_packets, SizeIs(3));
+  EXPECT_EQ(sent_rtx_packets[0].PayloadType(), kPayloadType + 1);
+  EXPECT_EQ(sent_rtx_packets[1].PayloadType(), kPayloadType + 1);
+  EXPECT_EQ(sent_rtx_packets[2].PayloadType(), kPayloadType2 + 1);
+}
+
 TEST(RtpVideoSenderTest,
      SupportsDependencyDescriptorForVp8NotProvidedByEncoder) {
   constexpr uint8_t kPayload[1] = {'a'};
diff --git a/media/base/media_engine.cc b/media/base/media_engine.cc
index eb7446623c..35ff897d38 100644
--- a/media/base/media_engine.cc
+++ b/media/base/media_engine.cc
@@ -209,14 +209,14 @@ webrtc::RTCError CheckRtpParametersValues(
       }
     }
 
-    if (!field_trials.IsEnabled("WebRTC-MixedCodecSimulcast")) {
-      if (i > 0 && rtp_parameters.encodings[i - 1].codec !=
-                       rtp_parameters.encodings[i].codec) {
-        LOG_AND_RETURN_ERROR(RTCErrorType::UNSUPPORTED_OPERATION,
-                             "Attempted to use different codec values for "
-                             "different encodings.");
-      }
-    }
+    //if (!field_trials.IsEnabled("WebRTC-MixedCodecSimulcast")) {
+    //  if (i > 0 && rtp_parameters.encodings[i - 1].codec !=
+    //                   rtp_parameters.encodings[i].codec) {
+    //    LOG_AND_RETURN_ERROR(RTCErrorType::UNSUPPORTED_OPERATION,
+    //                         "Attempted to use different codec values for "
+    //                         "different encodings.");
+    //  }
+    //}
   }
 
   if (has_scale_resolution_down_to &&
diff --git a/media/engine/simulcast_encoder_adapter.cc b/media/engine/simulcast_encoder_adapter.cc
index f0d7bf9fd1..fdb6ef5f22 100644
--- a/media/engine/simulcast_encoder_adapter.cc
+++ b/media/engine/simulcast_encoder_adapter.cc
@@ -156,17 +156,35 @@ std::vector<uint32_t> GetStreamStartBitratesKbps(const Environment& env,
   return start_bitrates;
 }
 
+bool IsMixedCodec(const VideoCodec& codec) {
+  if (codec.numberOfSimulcastStreams >= 2) {
+    for (size_t i = 0; i < codec.numberOfSimulcastStreams - 1; i++) {
+      for (size_t j = i + 1; j < codec.numberOfSimulcastStreams; j++) {
+        if (codec.simulcastStream[i].format &&
+            codec.simulcastStream[j].format &&
+            !codec.simulcastStream[i].format->IsSameCodec(
+                *codec.simulcastStream[j].format)) {
+          return true;
+        }
+      }
+    }
+  }
+  return false;
+}
+
 }  // namespace
 
 SimulcastEncoderAdapter::EncoderContext::EncoderContext(
     std::unique_ptr<VideoEncoder> encoder,
     bool prefer_temporal_support,
     VideoEncoder::EncoderInfo primary_info,
-    VideoEncoder::EncoderInfo fallback_info)
+    VideoEncoder::EncoderInfo fallback_info,
+    SdpVideoFormat video_format)
     : encoder_(std::move(encoder)),
       prefer_temporal_support_(prefer_temporal_support),
       primary_info_(std::move(primary_info)),
-      fallback_info_(std::move(fallback_info)) {}
+      fallback_info_(std::move(fallback_info)),
+      video_format_(std::move(video_format)) {}
 
 void SimulcastEncoderAdapter::EncoderContext::Release() {
   if (encoder_) {
@@ -342,11 +360,16 @@ int SimulcastEncoderAdapter::InitEncode(
   std::unique_ptr<EncoderContext> encoder_context = FetchOrCreateEncoderContext(
       /*is_lowest_quality_stream=*/(
           is_legacy_singlecast ||
-          codec_.simulcastStream[lowest_quality_stream_idx].active));
+          codec_.simulcastStream[lowest_quality_stream_idx].active),
+      /*stream_idx=*/is_legacy_singlecast
+          ? std::nullopt
+          : std::make_optional(lowest_quality_stream_idx));
   if (encoder_context == nullptr) {
     return WEBRTC_VIDEO_CODEC_MEMORY;
   }
 
+  bool is_mixed_codec = IsMixedCodec(codec_);
+
   // Two distinct scenarios:
   // * Singlecast (total_streams_count == 1) or simulcast with simulcast-capable
   //   underlaying encoder implementation if active_streams_count > 1. SEA
@@ -364,6 +387,7 @@ int SimulcastEncoderAdapter::InitEncode(
   // forces the use of SEA with separate encoders to support per-layer
   // handling of PLIs.
   bool separate_encoders_needed =
+      is_mixed_codec ||
       !encoder_context->encoder().GetEncoderInfo().supports_simulcast ||
       active_streams_count == 1 || per_layer_pli_;
   RTC_LOG(LS_INFO) << "[SEA] InitEncode: total_streams_count: "
@@ -409,9 +433,10 @@ int SimulcastEncoderAdapter::InitEncode(
       continue;
     }
 
-    if (encoder_context == nullptr) {
+    if (encoder_context == nullptr || is_mixed_codec) {
       encoder_context = FetchOrCreateEncoderContext(
-          /*is_lowest_quality_stream=*/stream_idx == lowest_quality_stream_idx);
+          /*is_lowest_quality_stream=*/stream_idx == lowest_quality_stream_idx,
+          stream_idx);
     }
     if (encoder_context == nullptr) {
       Release();
@@ -708,6 +733,10 @@ EncodedImageCallback::Result SimulcastEncoderAdapter::OnEncodedImage(
 
   stream_image.SetSimulcastIndex(stream_idx);
 
+  if (IsMixedCodec(codec_)) {
+    stream_image.SetSpatialIndex(std::nullopt);
+  }
+
   return encoded_complete_callback_->OnEncodedImage(stream_image,
                                                     &stream_codec_specific);
 }
@@ -729,20 +758,27 @@ void SimulcastEncoderAdapter::DestroyStoredEncoders() {
 
 std::unique_ptr<SimulcastEncoderAdapter::EncoderContext>
 SimulcastEncoderAdapter::FetchOrCreateEncoderContext(
-    bool is_lowest_quality_stream) const {
+    bool is_lowest_quality_stream,
+    std::optional<int> stream_idx) const {
   RTC_DCHECK_RUN_ON(&encoder_queue_);
+  SdpVideoFormat video_format =
+      stream_idx
+          ? codec_.simulcastStream[*stream_idx].format.value_or(video_format_)
+          : video_format_;
   bool prefer_temporal_support = fallback_encoder_factory_ != nullptr &&
                                  is_lowest_quality_stream &&
                                  prefer_temporal_support_on_base_layer_;
 
   // Toggling of `prefer_temporal_support` requires encoder recreation. Find
-  // and reuse encoder with desired `prefer_temporal_support`. Otherwise, if
-  // there is no such encoder in the cache, create a new instance.
+  // and reuse encoder with desired `prefer_temporal_support` and
+  // `video_format`. Otherwise, if there is no such encoder in the cache, create
+  // a new instance.
   auto encoder_context_iter =
       std::find_if(cached_encoder_contexts_.begin(),
                    cached_encoder_contexts_.end(), [&](auto& encoder_context) {
                      return encoder_context->prefer_temporal_support() ==
-                            prefer_temporal_support;
+                                prefer_temporal_support &&
+                            encoder_context->video_format() == video_format;
                    });
 
   std::unique_ptr<SimulcastEncoderAdapter::EncoderContext> encoder_context;
@@ -751,11 +787,11 @@ SimulcastEncoderAdapter::FetchOrCreateEncoderContext(
     cached_encoder_contexts_.erase(encoder_context_iter);
   } else {
     std::unique_ptr<VideoEncoder> primary_encoder =
-        primary_encoder_factory_->Create(env_, video_format_);
+        primary_encoder_factory_->Create(env_, video_format);
 
     std::unique_ptr<VideoEncoder> fallback_encoder;
     if (fallback_encoder_factory_ != nullptr) {
-      fallback_encoder = fallback_encoder_factory_->Create(env_, video_format_);
+      fallback_encoder = fallback_encoder_factory_->Create(env_, video_format);
     }
 
     std::unique_ptr<VideoEncoder> encoder;
@@ -774,20 +810,20 @@ SimulcastEncoderAdapter::FetchOrCreateEncoderContext(
             prefer_temporal_support);
       }
     } else if (fallback_encoder != nullptr) {
-      RTC_LOG(LS_WARNING) << "Failed to create primary " << video_format_.name
+      RTC_LOG(LS_WARNING) << "Failed to create primary " << video_format.name
                           << " encoder. Use fallback encoder.";
       fallback_info = fallback_encoder->GetEncoderInfo();
       primary_info = fallback_info;
       encoder = std::move(fallback_encoder);
     } else {
       RTC_LOG(LS_ERROR) << "Failed to create primary and fallback "
-                        << video_format_.name << " encoders.";
+                        << video_format.name << " encoders.";
       return nullptr;
     }
 
     encoder_context = std::make_unique<SimulcastEncoderAdapter::EncoderContext>(
         std::move(encoder), prefer_temporal_support, primary_info,
-        fallback_info);
+        fallback_info, std::move(video_format));
   }
 
   encoder_context->encoder().RegisterEncodeCompleteCallback(
@@ -803,7 +839,12 @@ webrtc::VideoCodec SimulcastEncoderAdapter::MakeStreamCodec(
     bool is_highest_quality_stream) {
   webrtc::VideoCodec codec_params = codec;
   const SimulcastStream& stream_params = codec.simulcastStream[stream_idx];
+  webrtc::VideoCodecType codecType =
+      stream_params.format
+          ? PayloadStringToCodecType(stream_params.format->name)
+          : codec.codecType;
 
+  codec_params.codecType = codecType;
   codec_params.numberOfSimulcastStreams = 0;
   codec_params.width = stream_params.width;
   codec_params.height = stream_params.height;
@@ -841,7 +882,7 @@ webrtc::VideoCodec SimulcastEncoderAdapter::MakeStreamCodec(
       codec_params.qpMax = kLowestResMaxQp;
     }
   }
-  if (codec.codecType == webrtc::kVideoCodecVP8) {
+  if (codecType == webrtc::kVideoCodecVP8) {
     codec_params.VP8()->numberOfTemporalLayers =
         stream_params.numberOfTemporalLayers;
     if (!is_highest_quality_stream) {
@@ -855,10 +896,10 @@ webrtc::VideoCodec SimulcastEncoderAdapter::MakeStreamCodec(
       // Turn off denoising for all streams but the highest resolution.
       codec_params.VP8()->denoisingOn = false;
     }
-  } else if (codec.codecType == webrtc::kVideoCodecH264) {
+  } else if (codecType == webrtc::kVideoCodecH264) {
     codec_params.H264()->numberOfTemporalLayers =
         stream_params.numberOfTemporalLayers;
-  } else if (codec.codecType == webrtc::kVideoCodecVP9 &&
+  } else if (codecType == webrtc::kVideoCodecVP9 &&
              scalability_mode.has_value() && !only_active_stream) {
     // If VP9 simulcast then explicitly set a single spatial layer for each
     // simulcast stream.
@@ -921,7 +962,8 @@ VideoEncoder::EncoderInfo SimulcastEncoderAdapter::GetEncoderInfo() const {
     // Create one encoder and query it.
 
     std::unique_ptr<SimulcastEncoderAdapter::EncoderContext> encoder_context =
-        FetchOrCreateEncoderContext(/*is_lowest_quality_stream=*/true);
+        FetchOrCreateEncoderContext(/*is_lowest_quality_stream=*/true,
+                                    std::nullopt);
     if (encoder_context == nullptr) {
       return encoder_info;
     }
diff --git a/media/engine/simulcast_encoder_adapter.h b/media/engine/simulcast_encoder_adapter.h
index 92d10a4ab8..e9ae77cb9c 100644
--- a/media/engine/simulcast_encoder_adapter.h
+++ b/media/engine/simulcast_encoder_adapter.h
@@ -78,7 +78,8 @@ class RTC_EXPORT SimulcastEncoderAdapter : public VideoEncoder {
     EncoderContext(std::unique_ptr<VideoEncoder> encoder,
                    bool prefer_temporal_support,
                    VideoEncoder::EncoderInfo primary_info,
-                   VideoEncoder::EncoderInfo fallback_info);
+                   VideoEncoder::EncoderInfo fallback_info,
+                   SdpVideoFormat video_foramt);
     EncoderContext& operator=(EncoderContext&&) = delete;
 
     VideoEncoder& encoder() { return *encoder_; }
@@ -89,11 +90,14 @@ class RTC_EXPORT SimulcastEncoderAdapter : public VideoEncoder {
 
     const VideoEncoder::EncoderInfo& FallbackInfo() { return fallback_info_; }
 
+    const SdpVideoFormat& video_format() { return video_format_; }
+
    private:
     std::unique_ptr<VideoEncoder> encoder_;
     bool prefer_temporal_support_;
     const VideoEncoder::EncoderInfo primary_info_;
     const VideoEncoder::EncoderInfo fallback_info_;
+    const SdpVideoFormat video_format_;
   };
 
   class StreamContext : public EncodedImageCallback {
@@ -153,7 +157,8 @@ class RTC_EXPORT SimulcastEncoderAdapter : public VideoEncoder {
   // `cached_encoder_contexts_`. It's const because it's used from
   // const GetEncoderInfo().
   std::unique_ptr<EncoderContext> FetchOrCreateEncoderContext(
-      bool is_lowest_quality_stream) const;
+      bool is_lowest_quality_stream,
+      std::optional<int> stream_idx) const;
 
   webrtc::VideoCodec MakeStreamCodec(const webrtc::VideoCodec& codec,
                                      int stream_idx,
diff --git a/media/engine/webrtc_video_engine.cc b/media/engine/webrtc_video_engine.cc
index b3e25c6c5b..8bbc4c257b 100644
--- a/media/engine/webrtc_video_engine.cc
+++ b/media/engine/webrtc_video_engine.cc
@@ -396,15 +396,15 @@ static bool ValidateStreamParams(const StreamParams& sp) {
 }
 
 // Returns true if the given codec is disallowed from doing simulcast.
-bool IsCodecDisabledForSimulcast(bool legacy_scalability_mode,
-                                 webrtc::VideoCodecType codec_type) {
-  if (legacy_scalability_mode && (codec_type == webrtc::kVideoCodecVP9 ||
-                                  codec_type == webrtc::kVideoCodecAV1)) {
-    return true;
-  }
-
-  return false;
-}
+// bool IsCodecDisabledForSimulcast(bool legacy_scalability_mode,
+//                                 webrtc::VideoCodecType codec_type) {
+//  if (legacy_scalability_mode && (codec_type == webrtc::kVideoCodecVP9 ||
+//                                  codec_type == webrtc::kVideoCodecAV1)) {
+//    return true;
+//  }
+//
+//  return false;
+//}
 
 bool IsLayerActive(const webrtc::RtpEncodingParameters& layer) {
   return layer.active &&
@@ -1310,6 +1310,12 @@ bool WebRtcVideoSendChannel::ApplyChangedParams(
   if (changed_params.send_codecs)
     send_codecs_ = *changed_params.send_codecs;
 
+  if (changed_params.send_codecs) {
+    send_codecs_ = *changed_params.send_codecs;
+  } else {
+    send_codecs_.clear();
+  }
+
   if (changed_params.extmap_allow_mixed) {
     SetExtmapAllowMixed(*changed_params.extmap_allow_mixed);
   }
@@ -1444,28 +1450,49 @@ webrtc::RTCError WebRtcVideoSendChannel::SetRtpSendParameters(
     // Since we validate that all layers have the same value, we can just check
     // the first layer.
     // TODO: https://issues.webrtc.org/362277533 - Support mixed-codec simulcast
-    if (parameters.encodings[0].codec && send_codec_ &&
-        !IsSameRtpCodecIgnoringLevel(send_codec_->codec,
-                                     *parameters.encodings[0].codec)) {
-      RTC_LOG(LS_VERBOSE) << "Trying to change codec to "
-                          << parameters.encodings[0].codec->name;
-      // Ignore level when matching negotiated codecs against the requested
-      // codec.
-      auto matched_codec =
-          absl::c_find_if(negotiated_codecs_, [&](auto negotiated_codec) {
-            return IsSameRtpCodecIgnoringLevel(negotiated_codec.codec,
-                                               *parameters.encodings[0].codec);
-          });
-      if (matched_codec == negotiated_codecs_.end()) {
-        return webrtc::InvokeSetParametersCallback(
-            callback, webrtc::RTCError(
-                          webrtc::RTCErrorType::INVALID_MODIFICATION,
-                          "Attempted to use an unsupported codec for layer 0"));
+    if (send_codec_ &&
+        std::any_of(parameters.encodings.begin(), parameters.encodings.end(),
+                    [](const auto& e) { return e.codec; })) {
+      std::vector<VideoCodecSettings> send_codecs;
+
+      for (size_t i = 0; i < parameters.encodings.size(); i++) {
+        const auto& codec = parameters.encodings[i].codec;
+        std::optional<VideoCodecSettings> found_codec;
+        if (!codec) {
+          found_codec = *send_codec_;
+        } else if (i < send_codecs_.size()) {
+          const auto& send_codec = send_codecs_[i];
+          if (IsSameRtpCodec(send_codec.codec, *codec)) {
+            found_codec = send_codec;
+          }
+        }
+        if (!found_codec) {
+          RTC_DCHECK(codec);
+          auto matched_codec =
+              absl::c_find_if(negotiated_codecs_, [&](auto negotiated_codec) {
+                return IsSameRtpCodec(negotiated_codec.codec, *codec);
+              });
+          if (matched_codec == negotiated_codecs_.end()) {
+            return webrtc::InvokeSetParametersCallback(
+                callback,
+                webrtc::RTCError(
+                    webrtc::RTCErrorType::INVALID_MODIFICATION,
+                    "Attempted to use an unsupported codec for layer " +
+                        std::to_string(i)));
+          }
+          found_codec = *matched_codec;
+        }
+        RTC_DCHECK(found_codec);
+        send_codecs.push_back(*found_codec);
+      }
+      if (send_codecs_ != send_codecs) {
+        ChangedSenderParameters params;
+        if (!send_codecs.empty()) {
+          params.send_codec = send_codecs[0];
+        }
+        params.send_codecs = send_codecs;
+        ApplyChangedParams(params);
       }
-
-      ChangedSenderParameters params;
-      params.send_codec = *matched_codec;
-      ApplyChangedParams(params);
     }
 
     SetPreferredDscp(new_dscp);
@@ -2005,7 +2032,9 @@ void WebRtcVideoSendChannel::WebRtcVideoSendStream::SetCodec(
   parameters_.codec_settings = codec_settings;
 
   // Settings for mixed-codec simulcast.
-  if (!codec_settings_list.empty()) {
+  if (codec_settings_list.empty()) {
+    parameters_.config.rtp.stream_configs.clear();
+  } else {
     if (parameters_.config.rtp.ssrcs.size() == codec_settings_list.size()) {
       parameters_.config.rtp.stream_configs.resize(
           parameters_.config.rtp.ssrcs.size());
@@ -2084,7 +2113,8 @@ void WebRtcVideoSendChannel::WebRtcVideoSendStream::SetSenderParameters(
   // Set codecs and options.
   if (params.send_codec) {
     SetCodec(*params.send_codec,
-             params.send_codecs.value_or(parameters_.codec_settings_list));
+             params.send_codecs.value_or(
+                 std::vector<cricket::VideoCodecSettings>()));
     recreate_stream = false;  // SetCodec has already recreated the stream.
   } else if (params.conference_mode && parameters_.codec_settings) {
     SetCodec(*parameters_.codec_settings, parameters_.codec_settings_list);
@@ -2260,25 +2290,25 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::CreateVideoEncoderConfig(
   // number of negotiated ssrcs but this may be capped below depending on the
   // `legacy_scalability_mode` and codec used.
   encoder_config.number_of_streams = parameters_.config.rtp.ssrcs.size();
-  bool legacy_scalability_mode = true;
-  for (const webrtc::RtpEncodingParameters& encoding :
-       rtp_parameters_.encodings) {
-    if (encoding.scalability_mode.has_value() &&
-        (encoding.scale_resolution_down_by.has_value() ||
-         encoding.scale_resolution_down_to.has_value())) {
-      legacy_scalability_mode = false;
-      break;
-    }
-  }
+  // bool legacy_scalability_mode = true;
+  // for (const webrtc::RtpEncodingParameters& encoding :
+  //      rtp_parameters_.encodings) {
+  //   if (encoding.scalability_mode.has_value() &&
+  //       (encoding.scale_resolution_down_by.has_value() ||
+  //        encoding.scale_resolution_down_to.has_value())) {
+  //     legacy_scalability_mode = false;
+  //     break;
+  //   }
+  // }
   // Maybe limit the number of simulcast layers depending on
   // `legacy_scalability_mode`, codec types (VP9/AV1). This path only exists
   // for backwards compatibility and will one day be deleted. If you want SVC,
   // please specify with the `scalability_mode` API instead amd disabling all
   // but one encoding.
-  if (IsCodecDisabledForSimulcast(legacy_scalability_mode,
-                                  encoder_config.codec_type)) {
-    encoder_config.number_of_streams = 1;
-  }
+  // if (IsCodecDisabledForSimulcast(legacy_scalability_mode,
+  //                                 encoder_config.codec_type)) {
+  //   encoder_config.number_of_streams = 1;
+  // }
 
   // parameters_.max_bitrate comes from the max bitrate set at the SDP
   // (m-section) level with the attribute "b=AS." Note that stream max bitrate
@@ -2346,6 +2376,11 @@ WebRtcVideoSendChannel::WebRtcVideoSendStream::CreateVideoEncoderConfig(
       encoder_config.simulcast_layers[i].num_temporal_layers =
           *rtp_parameters_.encodings[i].num_temporal_layers;
     }
+    if (rtp_parameters_.encodings[i].codec) {
+      encoder_config.simulcast_layers[i].video_format = webrtc::SdpVideoFormat(
+          rtp_parameters_.encodings[i].codec->name,
+          rtp_parameters_.encodings[i].codec->parameters);
+    }
     encoder_config.simulcast_layers[i].scale_resolution_down_to =
         rtp_parameters_.encodings[i].scale_resolution_down_to;
   }
diff --git a/modules/video_coding/utility/simulcast_rate_allocator.cc b/modules/video_coding/utility/simulcast_rate_allocator.cc
index 1157d1a76f..3c096831f0 100644
--- a/modules/video_coding/utility/simulcast_rate_allocator.cc
+++ b/modules/video_coding/utility/simulcast_rate_allocator.cc
@@ -175,8 +175,30 @@ void SimulcastRateAllocator::DistributeAllocationToSimulcastLayers(
       min_bitrate = std::min(hysteresis_factor * min_bitrate, target_bitrate);
     }
     if (left_in_stable_allocation < min_bitrate) {
-      allocated_bitrates->set_bw_limited(true);
-      break;
+      bool is_mixed_codec = std::invoke([this]() {
+        if (codec_.numberOfSimulcastStreams >= 2) {
+          for (size_t i = 0; i < codec_.numberOfSimulcastStreams - 1; i++) {
+            for (size_t j = i + 1; j < codec_.numberOfSimulcastStreams; j++) {
+              if (codec_.simulcastStream[i].format &&
+                  codec_.simulcastStream[j].format &&
+                  !codec_.simulcastStream[i].format->IsSameCodec(
+                      *codec_.simulcastStream[j].format)) {
+                return true;
+              }
+            }
+          }
+        }
+        return false;
+      });
+
+      if (is_mixed_codec) {
+        // トータルのビットレートが低すぎると、高いレイヤーにビットレートを割り当てることができなくなるのだけど、
+        // サイマルキャストマルチコーデックでそれをされると困るので、トータルのビットレートを超えても無理やり出力する
+        left_in_stable_allocation = left_in_total_allocation = min_bitrate;
+      } else {
+        allocated_bitrates->set_bw_limited(true);
+        break;
+      }
     }
 
     // We are allocating to this layer so it is the current active allocation.
@@ -335,11 +357,14 @@ const VideoCodec& webrtc::SimulcastRateAllocator::GetCodec() const {
 }
 
 int SimulcastRateAllocator::NumTemporalStreams(size_t simulcast_id) const {
+  bool is_vp8 = codec_.simulcastStream[simulcast_id].format
+                    ? codec_.simulcastStream[simulcast_id].format->IsSameCodec(
+                          webrtc::SdpVideoFormat::VP8())
+                    : codec_.codecType == kVideoCodecVP8;
   return std::max<uint8_t>(
-      1,
-      codec_.codecType == kVideoCodecVP8 && codec_.numberOfSimulcastStreams == 0
-          ? codec_.VP8().numberOfTemporalLayers
-          : codec_.simulcastStream[simulcast_id].numberOfTemporalLayers);
+      1, is_vp8 && codec_.numberOfSimulcastStreams == 0
+             ? codec_.VP8().numberOfTemporalLayers
+             : codec_.simulcastStream[simulcast_id].numberOfTemporalLayers);
 }
 
 void SimulcastRateAllocator::SetLegacyConferenceMode(bool enabled) {
diff --git a/modules/video_coding/video_codec_initializer.cc b/modules/video_coding/video_codec_initializer.cc
index 9c2cdc62b8..f30043e54d 100644
--- a/modules/video_coding/video_codec_initializer.cc
+++ b/modules/video_coding/video_codec_initializer.cc
@@ -114,6 +114,7 @@ VideoCodec VideoCodecInitializer::SetupCodec(
     sim_stream->targetBitrate = streams[i].target_bitrate_bps / 1000;
     sim_stream->maxBitrate = streams[i].max_bitrate_bps / 1000;
     sim_stream->qpMax = streams[i].max_qp;
+    sim_stream->format = config.GetSimulcastVideoFormat(i);
 
     int num_temporal_layers =
         streams[i].scalability_mode.has_value()
diff --git a/pc/peer_connection_integrationtest.cc b/pc/peer_connection_integrationtest.cc
index 20b91f6892..4c28cf4f72 100644
--- a/pc/peer_connection_integrationtest.cc
+++ b/pc/peer_connection_integrationtest.cc
@@ -4201,6 +4201,46 @@ TEST_P(PeerConnectionIntegrationTest, EndToEndRtpSenderVideoEncoderSelector) {
   EXPECT_TRUE(ExpectNewFrames(media_expectations));
 }
 
+TEST_P(PeerConnectionIntegrationTest, EndToEndRtpSenderVideoEncoderSelectorSwitchCodec) {
+  ASSERT_TRUE(
+      CreateOneDirectionalPeerConnectionWrappers(/*caller_to_callee=*/true));
+  ConnectFakeSignaling();
+  // Add one-directional video, from caller to callee.
+  rtc::scoped_refptr<VideoTrackInterface> caller_track =
+      caller()->CreateLocalVideoTrack();
+  auto sender = caller()->AddTrack(caller_track);
+  PeerConnectionInterface::RTCOfferAnswerOptions options;
+  options.offer_to_receive_video = 0;
+  caller()->SetOfferAnswerOptions(options);
+  caller()->CreateAndSetAndSignalOffer();
+  ASSERT_THAT(
+      WaitUntil([&] { return SignalingStateStable(); }, ::testing::IsTrue()),
+      IsRtcOk());
+  ASSERT_EQ(callee()->pc()->GetReceivers().size(), 1u);
+
+  std::unique_ptr<MockEncoderSelector> encoder_selector =
+      std::make_unique<MockEncoderSelector>();
+  std::optional<SdpVideoFormat> next_format;
+  EXPECT_CALL(*encoder_selector, OnCurrentEncoder).WillOnce(::testing::Invoke([&](const SdpVideoFormat& format) {
+    EXPECT_EQ(format.name, "VP8");
+    next_format = SdpVideoFormat::VP9Profile0();
+  })).WillOnce(::testing::Invoke([&](const SdpVideoFormat& format) {
+    EXPECT_EQ(format.name, "VP9");
+  }));
+  EXPECT_CALL(*encoder_selector, OnAvailableBitrate).WillRepeatedly(::testing::Invoke([&](const DataRate& rate) {
+    return next_format;
+  }));
+
+  sender->SetEncoderSelector(std::move(encoder_selector));
+
+  // Expect video to be received in one direction.
+  MediaExpectations media_expectations;
+  media_expectations.CallerExpectsNoVideo();
+  media_expectations.CalleeExpectsSomeVideo();
+
+  EXPECT_TRUE(ExpectNewFrames(media_expectations));
+}
+
 int NacksReceivedCount(PeerConnectionIntegrationWrapper& pc) {
   rtc::scoped_refptr<const RTCStatsReport> report = pc.NewGetStats();
   auto sender_stats = report->GetStatsOfType<RTCOutboundRtpStreamStats>();
diff --git a/video/config/encoder_stream_factory.cc b/video/config/encoder_stream_factory.cc
index a3ad7a3992..ad3a937d66 100644
--- a/video/config/encoder_stream_factory.cc
+++ b/video/config/encoder_stream_factory.cc
@@ -530,7 +530,24 @@ std::vector<webrtc::Resolution> EncoderStreamFactory::GetStreamResolutions(
       resolutions.push_back({.width = width, .height = height});
     }
   } else {
-    size_t min_num_layers = FindRequiredActiveLayers(encoder_config);
+    bool is_mixed_codec = std::invoke([&]() {
+      if (encoder_config.simulcast_layers.size() >= 2) {
+        for (size_t i = 0; i < encoder_config.simulcast_layers.size() - 1;
+             i++) {
+          for (size_t j = i + 1; j < encoder_config.simulcast_layers.size();
+               j++) {
+            if (!encoder_config.GetSimulcastVideoFormat(i).IsSameCodec(
+                    encoder_config.GetSimulcastVideoFormat(j))) {
+              return true;
+            }
+          }
+        }
+      }
+      return false;
+    });
+    size_t min_num_layers = is_mixed_codec
+                                ? encoder_config.number_of_streams
+                                : FindRequiredActiveLayers(encoder_config);
     size_t max_num_layers =
         !encoder_config.HasScaleResolutionDownTo()
             ? LimitSimulcastLayerCount(
diff --git a/video/config/video_encoder_config.cc b/video/config/video_encoder_config.cc
index 9dc9a52c89..80f72bad99 100644
--- a/video/config/video_encoder_config.cc
+++ b/video/config/video_encoder_config.cc
@@ -155,4 +155,27 @@ void VideoEncoderConfig::Av1EncoderSpecificSettings::FillVideoCodecAv1(
   *av1_settings = specifics_;
 }
 
+VideoCodecType VideoEncoderConfig::GetSimulcastCodecType(
+    size_t stream_index) const {
+  if (stream_index >= simulcast_layers.size()) {
+    return codec_type;
+  }
+  if (!simulcast_layers[stream_index].video_format) {
+    return codec_type;
+  }
+  return PayloadStringToCodecType(
+      simulcast_layers[stream_index].video_format->name);
+}
+
+const SdpVideoFormat& VideoEncoderConfig::GetSimulcastVideoFormat(
+    size_t stream_index) const {
+  if (stream_index >= simulcast_layers.size()) {
+    return video_format;
+  }
+  if (!simulcast_layers[stream_index].video_format) {
+    return video_format;
+  }
+  return *simulcast_layers[stream_index].video_format;
+}
+
 }  // namespace webrtc
diff --git a/video/config/video_encoder_config.h b/video/config/video_encoder_config.h
index 59ee866f53..bff797130e 100644
--- a/video/config/video_encoder_config.h
+++ b/video/config/video_encoder_config.h
@@ -83,6 +83,9 @@ struct VideoStream {
   // e.g. if source only provides lower resolution or
   // if resource adaptation is active.
   std::optional<Resolution> scale_resolution_down_to;
+
+  // このビデオストリームが利用するべきビデオフォーマット
+  std::optional<SdpVideoFormat> video_format;
 };
 
 class VideoEncoderConfig {
@@ -168,6 +171,10 @@ class VideoEncoderConfig {
 
   bool HasScaleResolutionDownTo() const;
 
+  // stream_index 番目のストリームが利用する設定
+  VideoCodecType GetSimulcastCodecType(size_t stream_index) const;
+  const SdpVideoFormat& GetSimulcastVideoFormat(size_t stream_index) const;
+
   // TODO(bugs.webrtc.org/6883): Consolidate on one of these.
   VideoCodecType codec_type;
   SdpVideoFormat video_format;
diff --git a/video/video_stream_encoder.cc b/video/video_stream_encoder.cc
index a7e24400fb..cd6599f68a 100644
--- a/video/video_stream_encoder.cc
+++ b/video/video_stream_encoder.cc
@@ -945,8 +945,24 @@ void VideoStreamEncoder::ConfigureEncoder(VideoEncoderConfig config,
       frame_cadence_adapter_->SetZeroHertzModeEnabled(std::nullopt);
     }
 
+    bool video_format_changed =
+        encoder_config_.video_format != config.video_format;
+    if (!video_format_changed && encoder_config_.simulcast_layers.size() !=
+                                     config.simulcast_layers.size()) {
+      video_format_changed = true;
+    }
+    if (!video_format_changed) {
+      for (size_t i = 0; i < encoder_config_.simulcast_layers.size(); i++) {
+        if (encoder_config_.GetSimulcastVideoFormat(i) !=
+            config.GetSimulcastVideoFormat(i)) {
+          video_format_changed = true;
+          break;
+        }
+      }
+    }
+
     pending_encoder_creation_ =
-        (!encoder_ || encoder_config_.video_format != config.video_format ||
+        (!encoder_ || video_format_changed ||
          max_data_payload_length_ != max_data_payload_length);
     encoder_config_ = std::move(config);
     max_data_payload_length_ = max_data_payload_length;
@@ -2177,7 +2193,7 @@ EncodedImageCallback::Result VideoStreamEncoder::OnEncodedImage(
         // webrtc qp scaler (in the no-svc case or if only a single spatial
         // layer is encoded). It has to be explicitly detected and reported to
         // adaptation metrics.
-        if (codec_type == VideoCodecType::kVideoCodecVP9 &&
+        if (codec_type == VideoCodecType::kVideoCodecVP9 && false &&
             send_codec_.VP9()->automaticResizeOn) {
           unsigned int expected_width = send_codec_.width;
           unsigned int expected_height = send_codec_.height;
