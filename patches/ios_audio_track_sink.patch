diff --git a/sdk/BUILD.gn b/sdk/BUILD.gn
index 7b8a02462c..da1c97cc74 100644
--- a/sdk/BUILD.gn
+++ b/sdk/BUILD.gn
@@ -997,6 +997,7 @@ if (is_ios || is_mac) {
         "objc/api/peerconnection/RTCAudioTrack+Private.h",
         "objc/api/peerconnection/RTCAudioTrack.h",
         "objc/api/peerconnection/RTCAudioTrack.mm",
+        "objc/api/peerconnection/RTCAudioTrackSink.h",
         "objc/api/peerconnection/RTCCertificate.h",
         "objc/api/peerconnection/RTCCertificate.mm",
         "objc/api/peerconnection/RTCConfiguration+Native.h",
@@ -1389,6 +1390,7 @@ if (is_ios || is_mac) {
           "objc/helpers/UIDevice+RTCDevice.h",
           "objc/api/peerconnection/RTCAudioSource.h",
           "objc/api/peerconnection/RTCAudioTrack.h",
+          "objc/api/peerconnection/RTCAudioTrackSink.h",
           "objc/api/peerconnection/RTCConfiguration.h",
           "objc/api/peerconnection/RTCDataChannel.h",
           "objc/api/peerconnection/RTCDataChannelConfiguration.h",
diff --git a/sdk/objc/api/peerconnection/RTCAudioTrack.h b/sdk/objc/api/peerconnection/RTCAudioTrack.h
index db8afb50fc..60ea646ec4 100644
--- a/sdk/objc/api/peerconnection/RTCAudioTrack.h
+++ b/sdk/objc/api/peerconnection/RTCAudioTrack.h
@@ -9,6 +9,7 @@
  */
 
 #import "RTCMediaStreamTrack.h"
+#import "RTCAudioTrackSink.h"
 #import "sdk/objc/base/RTCMacros.h"
 
 NS_ASSUME_NONNULL_BEGIN
@@ -23,6 +24,20 @@ RTC_OBJC_EXPORT
 /** The audio source for this audio track. */
 @property(nonatomic, readonly) RTC_OBJC_TYPE(RTCAudioSource) * source;
 
+/**
+ * AudioTrackSink を関連付ける
+ *
+ * @param sink 関連付ける AudioTrackSink
+ */
+- (void)addSink:(id<RTC_OBJC_TYPE(RTCAudioTrackSink)>)sink;
+
+/**
+ * AudioTrackSink の関連付けを解除する
+ *
+ * @param sink 関連付けを解除する AudioTrackSink
+ */
+- (void)removeSink:(id<RTC_OBJC_TYPE(RTCAudioTrackSink)>)sink;
+
 @end
 
 NS_ASSUME_NONNULL_END
diff --git a/sdk/objc/api/peerconnection/RTCAudioTrack.mm b/sdk/objc/api/peerconnection/RTCAudioTrack.mm
index 5ba53c84e9..803d9dfd39 100644
--- a/sdk/objc/api/peerconnection/RTCAudioTrack.mm
+++ b/sdk/objc/api/peerconnection/RTCAudioTrack.mm
@@ -9,15 +9,114 @@
  */
 
 #import "RTCAudioTrack+Private.h"
+#import "RTCAudioTrackSink.h"
 
 #import "RTCAudioSource+Private.h"
 #import "RTCMediaStreamTrack+Private.h"
 #import "RTCPeerConnectionFactory+Private.h"
+#import "base/RTCLogging.h"
 #import "helpers/NSString+StdString.h"
 
 #include "rtc_base/checks.h"
+#include "rtc_base/thread.h"
 
-@implementation RTC_OBJC_TYPE (RTCAudioTrack)
+#include <memory>
+
+namespace webrtc {
+namespace objc {
+
+/**
+ * C++ wrapper for Objective-C audio sink
+ * スレッドセーフな実装でObjective-CのAudioSinkをブリッジ
+ */
+class RTCAudioTrackSinkAdapter : public webrtc::AudioTrackSinkInterface {
+ public:
+  RTCAudioTrackSinkAdapter(id<RTC_OBJC_TYPE(RTCAudioTrackSink)> sink,
+                           RTC_OBJC_TYPE(RTCAudioTrack)* track)
+      : sink_(sink), track_(track) {}
+
+  void OnData(const void* audio_data,
+              int bits_per_sample,
+              int sample_rate,
+              size_t number_of_channels,
+              size_t number_of_frames) override {
+    // 注意: このメソッドはWebRTCのオーディオスレッドから呼ばれる
+    // 高頻度（10-20ms間隔）で呼ばれるため、処理は最小限に
+
+    // OnData の呼び出しごとに生成される ObjC オブジェクトを即時解放し、
+    // オーディオスレッド上の長寿命ループでのメモリ膨張を防ぐ。
+    // 特に __weak から strong を取り出す際には ARC が retain→autorelease を
+    // 内部的に挿入するため、明示的な pool でその一時オブジェクトを毎回 drain する。
+    @autoreleasepool {
+      // weak参照のチェック（スレッドセーフ）
+      id<RTC_OBJC_TYPE(RTCAudioTrackSink)> strongSink = sink_;
+      RTC_OBJC_TYPE(RTCAudioTrack)* strongTrack = track_;
+
+      if (!strongSink || !strongTrack) {
+        return;
+      }
+
+      size_t bytes_per_sample = bits_per_sample / 8;
+      size_t data_size = number_of_frames * number_of_channels * bytes_per_sample;
+      NSData* audioData = [[NSData alloc] initWithBytes:audio_data length:data_size];
+
+      [strongSink didReceiveData:audioData
+          bitsPerSample:bits_per_sample
+              sampleRate:sample_rate
+        numberOfChannels:number_of_channels
+          numberOfFrames:number_of_frames];
+    }
+  }
+
+  int NumPreferredChannels() const override {
+    id<RTC_OBJC_TYPE(RTCAudioTrackSink)> strongSink = sink_;
+    if (strongSink && [strongSink respondsToSelector:@selector(preferredNumberOfChannels)]) {
+      return static_cast<int>([strongSink preferredNumberOfChannels]);
+    }
+    return -1;
+  }
+
+ private:
+  __weak id<RTC_OBJC_TYPE(RTCAudioTrackSink)> sink_;
+  __weak RTC_OBJC_TYPE(RTCAudioTrack)* track_;
+};
+
+}  // namespace objc
+}  // namespace webrtc
+
+@interface RTCAudioTrackSinkAdapterBox : NSObject
+@property(nonatomic, readonly) id<RTC_OBJC_TYPE(RTCAudioTrackSink)> sink;
+@property(nonatomic, readonly) webrtc::objc::RTCAudioTrackSinkAdapter* nativeAdapter;
+- (instancetype)initWithSink:(id<RTC_OBJC_TYPE(RTCAudioTrackSink)>)sink
+                       track:(RTC_OBJC_TYPE(RTCAudioTrack)*)track;
+@end
+
+@implementation RTCAudioTrackSinkAdapterBox {
+  std::unique_ptr<webrtc::objc::RTCAudioTrackSinkAdapter> _adapter;
+}
+
+- (instancetype)initWithSink:(id<RTC_OBJC_TYPE(RTCAudioTrackSink)>)sink
+                       track:(RTC_OBJC_TYPE(RTCAudioTrack)*)track {
+  NSParameterAssert(sink);
+  NSParameterAssert(track);
+  self = [super init];
+  if (self) {
+    _sink = sink;
+    _adapter = std::make_unique<webrtc::objc::RTCAudioTrackSinkAdapter>(sink, track);
+  }
+  return self;
+}
+
+- (webrtc::objc::RTCAudioTrackSinkAdapter*)nativeAdapter {
+  return _adapter.get();
+}
+
+@end
+
+@implementation RTC_OBJC_TYPE (RTCAudioTrack) {
+  webrtc::Thread *_workerThread;
+  NSMutableArray<RTCAudioTrackSinkAdapterBox *> *_audioSinkAdapters;
+}
 
 @synthesize source = _source;
 
@@ -38,6 +137,8 @@
                           type:RTCMediaStreamTrackTypeAudio];
   if (self) {
     _source = source;
+    _workerThread = factory.workerThread;
+    _audioSinkAdapters = [NSMutableArray array];
   }
   return self;
 }
@@ -50,7 +151,12 @@
   NSParameterAssert(factory);
   NSParameterAssert(nativeTrack);
   NSParameterAssert(type == RTCMediaStreamTrackTypeAudio);
-  return [super initWithFactory:factory nativeTrack:nativeTrack type:type];
+  self = [super initWithFactory:factory nativeTrack:nativeTrack type:type];
+  if (self) {
+    _workerThread = factory.workerThread;
+    _audioSinkAdapters = [NSMutableArray array];
+  }
+  return self;
 }
 
 - (RTC_OBJC_TYPE(RTCAudioSource) *)source {
@@ -66,6 +172,79 @@
   return _source;
 }
 
+- (void)addSink:(id<RTC_OBJC_TYPE(RTCAudioTrackSink)>)sink {
+  if (!sink) {
+    return;
+  }
+
+  if (_workerThread && !_workerThread->IsCurrent()) {
+    _workerThread->PostTask([sink, self] { [self addSink:sink]; });
+    return;
+  }
+
+  for (RTCAudioTrackSinkAdapterBox* adapterBox in _audioSinkAdapters) {
+    if (adapterBox.sink == sink) {
+      RTCLogWarning(@"RTCAudioTrack sink already added: %@", sink);
+      return;
+    }
+  }
+
+  RTCAudioTrackSinkAdapterBox* adapterBox =
+      [[RTCAudioTrackSinkAdapterBox alloc] initWithSink:sink track:self];
+  [_audioSinkAdapters addObject:adapterBox];
+
+  // ネイティブトラックに追加（WebRTC側でスレッドセーフ）
+  self.nativeAudioTrack->AddSink(adapterBox.nativeAdapter);
+}
+
+- (void)removeSink:(id<RTC_OBJC_TYPE(RTCAudioTrackSink)>)sink {
+  if (!sink) {
+    return;
+  }
+
+  if (_workerThread && !_workerThread->IsCurrent()) {
+    _workerThread->PostTask([sink, self] { [self removeSink:sink]; });
+    return;
+  }
+
+  __block NSUInteger indexToRemove = NSNotFound;
+  [_audioSinkAdapters
+      enumerateObjectsUsingBlock:^(RTCAudioTrackSinkAdapterBox* adapterBox,
+                                   NSUInteger idx, BOOL* stop) {
+        if (adapterBox.sink == sink) {
+          indexToRemove = idx;
+          *stop = YES;
+        }
+      }];
+  if (indexToRemove == NSNotFound) {
+    RTCLogWarning(@"removeSink called with a sink that has not been previously added");
+    return;
+  }
+
+  RTCAudioTrackSinkAdapterBox* adapterBox =
+      [_audioSinkAdapters objectAtIndex:indexToRemove];
+  self.nativeAudioTrack->RemoveSink(adapterBox.nativeAdapter);
+  [_audioSinkAdapters removeObjectAtIndex:indexToRemove];
+}
+
+- (void)dealloc {
+  if (_workerThread && !_workerThread->IsCurrent()) {
+    // Worker スレッド側でクリーンアップを実施
+    _workerThread->BlockingCall([self] {
+      for (RTCAudioTrackSinkAdapterBox* adapterBox in self->_audioSinkAdapters) {
+        self.nativeAudioTrack->RemoveSink(adapterBox.nativeAdapter);
+      }
+      [self->_audioSinkAdapters removeAllObjects];
+    });
+    return;
+  }
+
+  for (RTCAudioTrackSinkAdapterBox* adapterBox in _audioSinkAdapters) {
+    self.nativeAudioTrack->RemoveSink(adapterBox.nativeAdapter);
+  }
+  [_audioSinkAdapters removeAllObjects];
+}
+
 #pragma mark - Private
 
 - (webrtc::scoped_refptr<webrtc::AudioTrackInterface>)nativeAudioTrack {
diff --git a/sdk/objc/api/peerconnection/RTCAudioTrackSink.h b/sdk/objc/api/peerconnection/RTCAudioTrackSink.h
new file mode 100644
index 0000000000..1999a5169f
--- /dev/null
+++ b/sdk/objc/api/peerconnection/RTCAudioTrackSink.h
@@ -0,0 +1,44 @@
+#import <Foundation/Foundation.h>
+#import "sdk/objc/base/RTCMacros.h"
+
+NS_ASSUME_NONNULL_BEGIN
+
+@class RTC_OBJC_TYPE(RTCAudioTrack);
+
+/**
+ * RTCAudioTrackSink プロトコル
+ * 音声データを受信するためのインターフェース
+ */
+RTC_OBJC_EXPORT
+@protocol RTC_OBJC_TYPE(RTCAudioTrackSink) <NSObject>
+
+/**
+ * 音声データ受信コールバック
+ *
+ * @param audioData PCM 形式の音声データ。
+ * @param bitsPerSample 1 サンプルあたりのビット数。
+ *                      libwebrtc では PCM 形式の音声データは 16 bit 固定のため、常に 16 が渡されます。
+ * @param sampleRate サンプルレート (単位: Hz)
+ * @param numberOfChannels 音声データのチャンネル数。
+ *                         モノラルなら 1、ステレオなら 2 が渡されます。
+ * @param numberOfFrames audioData に含まれるフレーム数。
+ */
+- (void) didReceiveData:(NSData *)audioData
+    bitsPerSample:(NSInteger)bitsPerSample
+        sampleRate:(NSInteger)sampleRate
+  numberOfChannels:(NSInteger)numberOfChannels
+    numberOfFrames:(NSInteger)numberOfFrames;
+
+@optional
+/**
+ * onData で受け取る音声データのチャンネル数を指定するためのメソッドです。
+ * `-1` を指定した場合は音声データ規定のチャンネル数になります。
+ *
+ * @return チャンネル数（-1の場合は指定なし）
+ */
+- (NSInteger)preferredNumberOfChannels;
+
+@end
+
+NS_ASSUME_NONNULL_END
+
